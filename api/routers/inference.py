# ì¶”ë¡ /íƒì§€ API ë¼ìš°í„° - yolo_infer_to_gps.py ê¸°ë°˜
# YOLO ëª¨ë¸ë¡œ í”¼í•´ëª© íƒì§€ + GPS ì¢Œí‘œ ë³€í™˜ + CSV ì €ì¥

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import os
import tempfile
import shutil
import pandas as pd
import cv2
import rasterio
from rasterio.transform import from_bounds
from rasterio import Affine
from ultralytics import YOLO
import datetime
import json
from pathlib import Path
import sys
import numpy as np
import zipfile

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (scripts í´ë” ì ‘ê·¼ìš©)
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from .. import config

router = APIRouter()

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class DetectionResult(BaseModel):
    filename: str
    class_id: int
    center_x: float
    center_y: float
    width: float
    height: float
    confidence: Optional[float] = None
    tm_x: Optional[float] = None  # TM ì¢Œí‘œ X
    tm_y: Optional[float] = None  # TM ì¢Œí‘œ Y

class BatchInferenceResponse(BaseModel):
    success: bool
    message: str
    total_images: int
    total_detections: int
    processed_images: List[str]
    failed_images: List[str]
    csv_file_url: Optional[str] = None
    results_zip_url: Optional[str] = None
    merged_visualization: Optional[str] = None  # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ íŒŒì¼ëª…

def extract_tile_position(filename: str) -> tuple:
    """íƒ€ì¼ íŒŒì¼ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (prefix_tile_x_y.tif -> (x, y))"""
    try:
        # ë‹¤ì–‘í•œ íŒŒì¼ëª… í˜•ì‹ ì§€ì›
        name_without_ext = filename.replace('.tif', '').replace('.tiff', '').replace('.jpg', '').replace('.jpeg', '').replace('.png', '')
        
        # í˜•ì‹ 1: A20250917_tile_2_1 -> ['A20250917', 'tile', '2', '1']
        parts = name_without_ext.split('_')
        
        # tileì´ í¬í•¨ëœ ê²½ìš°
        if 'tile' in parts:
            tile_idx = parts.index('tile')
            if len(parts) > tile_idx + 2:
                x = int(parts[tile_idx + 1])
                y = int(parts[tile_idx + 2])
                return (x, y)
        
        # í˜•ì‹ 2: prefix_x_y (ë§ˆì§€ë§‰ ë‘ ê°œê°€ ìˆ«ìì¸ ê²½ìš°)
        if len(parts) >= 3:
            try:
                x = int(parts[-2])
                y = int(parts[-1])
                return (x, y)
            except ValueError:
                pass
        
        # í˜•ì‹ 3: ì •ê·œì‹ìœ¼ë¡œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
        import re
        pattern = r'(\d+)_(\d+)(?:\.|$)'
        match = re.search(pattern, filename)
        if match:
            x = int(match.group(1))
            y = int(match.group(2))
            return (x, y)
            
    except (ValueError, IndexError, AttributeError):
        pass
    
    # íŒŒì‹± ì‹¤íŒ¨ì‹œ íŒŒì¼ëª…ì— _0_0ì´ ìˆëŠ”ì§€ í™•ì¸
    if '_0_0' in filename:
        return (0, 0)
    
    print(f"âš ï¸ íƒ€ì¼ ìœ„ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
    return (0, 0)  # ê¸°ë³¸ê°’


def create_merged_visualization(all_results: List[DetectionResult], output_base: str, 
                               timestamp: str, extract_dir: str, tile_size: int = config.DEFAULT_TILE_SIZE) -> Optional[str]:
    """íƒ€ì¼ë³„ íƒì§€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™” ìƒì„±"""
    
    if not all_results:
        return None
    
    try:
        print("ğŸ–¼ï¸ í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # ëª¨ë“  íƒ€ì¼ íŒŒì¼ ë¨¼ì € ìˆ˜ì§‘ (íƒì§€ ê²°ê³¼ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´)
        all_tile_files = {}
        tile_positions = {}
        
        # extract_dirì—ì„œ ëª¨ë“  íƒ€ì¼ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
        for root, dirs, files in os.walk(extract_dir):
            # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
            if '__MACOSX' in root:
                continue
            for file in files:
                # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                if file.startswith('.') or file.startswith('._'):
                    continue
                if file.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png')):
                    x, y = extract_tile_position(file)
                    if (x, y) != (0, 0) or '_0_0' in file:  # (0,0)ì€ ì‹¤ì œ ì¢Œí‘œì´ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨
                        tile_path = os.path.join(root, file)
                        all_tile_files[(x, y)] = tile_path
                        
                        # íƒì§€ ê²°ê³¼ê°€ ìˆëŠ” íƒ€ì¼ ì²´í¬
                        if (x, y) not in tile_positions:
                            tile_positions[(x, y)] = []
        
        # íƒì§€ ê²°ê³¼ë¥¼ í•´ë‹¹ íƒ€ì¼ ìœ„ì¹˜ì— í• ë‹¹
        for result in all_results:
            x, y = extract_tile_position(result.filename)
            if (x, y) in tile_positions:
                tile_positions[(x, y)].append(result)
        
        if not all_tile_files:
            print("âš ï¸ íƒ€ì¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì¼ë“¤ë¡œë¶€í„° ê²©ì ë²”ìœ„ ê³„ì‚°
        existing_positions = list(all_tile_files.keys())
        min_x = min(pos[0] for pos in existing_positions)
        max_x = max(pos[0] for pos in existing_positions)
        min_y = min(pos[1] for pos in existing_positions)
        max_y = max(pos[1] for pos in existing_positions)
        
        print(f"ğŸ“Š íƒ€ì¼ ê²©ì ë²”ìœ„: X({min_x}~{max_x}), Y({min_y}~{max_y})")
        print(f"ğŸ“Š ì „ì²´ íƒ€ì¼ ìˆ˜: {len(all_tile_files)}ê°œ")
        
        # ê° í–‰/ì—´ë³„ ì‹¤ì œ í¬ê¸° ê³„ì‚° (ì‹¤ì œ íƒ€ì¼ ì´ë¯¸ì§€ ê¸°ë°˜)
        row_heights = {}  # ty -> height
        col_widths = {}   # tx -> width
        
        # ëª¨ë“  íƒ€ì¼ì˜ í¬ê¸° ë¯¸ë¦¬ ì¸¡ì •
        print("ğŸ“ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì¤‘...")
        for (tx, ty), tile_path in all_tile_files.items():
            try:
                tile_img = cv2.imread(tile_path)
                if tile_img is not None:
                    h, w = tile_img.shape[:2]
                    
                    # í•´ë‹¹ í–‰/ì—´ì˜ ìµœëŒ€ í¬ê¸° ì €ì¥
                    if ty not in row_heights:
                        row_heights[ty] = h
                    else:
                        row_heights[ty] = max(row_heights[ty], h)
                    
                    if tx not in col_widths:
                        col_widths[tx] = w
                    else:
                        col_widths[tx] = max(col_widths[tx], w)
                else:
                    print(f"âš ï¸ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
            except Exception as e:
                print(f"âš ï¸ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì‹¤íŒ¨ {tile_path}: {e}")
        
        # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
        total_width = sum(col_widths.get(tx, tile_size) for tx in range(min_x, max_x + 1))
        total_height = sum(row_heights.get(ty, tile_size) for ty in range(min_y, max_y + 1))
        
        print(f"ğŸ“ ê³„ì‚°ëœ ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°: {total_width}x{total_height}")
        print(f"ğŸ“ í–‰ë³„ ë†’ì´: {row_heights}")
        print(f"ğŸ“ ì—´ë³„ ë„ˆë¹„: {col_widths}")
        
        # ì „ì²´ ì´ë¯¸ì§€ ìƒì„± (íšŒìƒ‰ ë°°ê²½ìœ¼ë¡œ ì‹œì‘ - ëˆ„ë½ ì˜ì—­ ì‹ë³„ìš©)
        merged_image = np.full((total_height, total_width, 3), (128, 128, 128), dtype=np.uint8)
        
        # íƒ€ì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ í•©ì¹˜ê¸°
        current_y = 0
        for ty in range(min_y, max_y + 1):
            current_x = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                if (tx, ty) in all_tile_files:
                    tile_path = all_tile_files[(tx, ty)]
                    try:
                        # íƒ€ì¼ ì´ë¯¸ì§€ ë¡œë“œ
                        tile_img = cv2.imread(tile_path)
                        if tile_img is not None:
                            h, w = tile_img.shape[:2]
                            
                            # ë°°ì¹˜ ì˜ì—­ ê³„ì‚°
                            end_x = min(current_x + w, total_width)
                            end_y = min(current_y + h, total_height)
                            
                            actual_w = end_x - current_x
                            actual_h = end_y - current_y
                            
                            if actual_w > 0 and actual_h > 0:
                                merged_image[current_y:end_y, current_x:end_x] = tile_img[:actual_h, :actual_w]
                                print(f"âœ… íƒ€ì¼ ë°°ì¹˜: ({tx},{ty}) at ({current_x},{current_y}) size={actual_w}x{actual_h}")
                        else:
                            print(f"âŒ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
                    except Exception as e:
                        print(f"âš ï¸ íƒ€ì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {tile_path}: {e}")
                else:
                    print(f"âš ï¸ íƒ€ì¼ ëˆ„ë½: ({tx},{ty}) at ({current_x},{current_y})")
                
                current_x += col_width
            
            current_y += row_height
        
        print("ğŸ¯ íƒ€ì¼ í•©ì¹˜ê¸° ì™„ë£Œ, íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì‹œì‘...")
        
        # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ê°œì„ ëœ ì¢Œí‘œ ê³„ì‚°)
        detection_count = 0
        current_y_offset = 0
        
        for ty in range(min_y, max_y + 1):
            current_x_offset = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                # í•´ë‹¹ íƒ€ì¼ì˜ íƒì§€ ê²°ê³¼ë“¤ ê·¸ë¦¬ê¸°
                if (tx, ty) in tile_positions:
                    for detection in tile_positions[(tx, ty)]:
                        # íƒ€ì¼ ë‚´ ì¢Œí‘œë¥¼ ì „ì²´ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                        global_x = current_x_offset + detection.center_x
                        global_y = current_y_offset + detection.center_y
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                        x1 = int(global_x - detection.width / 2)
                        y1 = int(global_y - detection.height / 2)
                        x2 = int(global_x + detection.width / 2)
                        y2 = int(global_y + detection.height / 2)
                        
                        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
                        x1 = max(0, min(x1, total_width))
                        y1 = max(0, min(y1, total_height))
                        x2 = max(0, min(x2, total_width))
                        y2 = max(0, min(y2, total_height))
                        
                        if x2 > x1 and y2 > y1:  # ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ê·¸ë¦¬ê¸°
                            # ğŸ¨ ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì½”ë”© (ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±°)
                            confidence = detection.confidence if detection.confidence else 0.5
                            if confidence >= 0.7:
                                color = (0, 255, 0)      # ì´ˆë¡ìƒ‰: ë†’ì€ ì‹ ë¢°ë„ (70%+)
                            elif confidence >= 0.4:
                                color = (0, 165, 255)    # ì£¼í™©ìƒ‰: ì¤‘ê°„ ì‹ ë¢°ë„ (40-70%)
                            else:
                                color = (0, 0, 255)      # ë¹¨ê°„ìƒ‰: ë‚®ì€ ì‹ ë¢°ë„ (40% ë¯¸ë§Œ)
                            
                            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì‹ ë¢°ë„ë³„ ìƒ‰ìƒ)
                            cv2.rectangle(merged_image, (x1, y1), (x2, y2), color, 3)
                            
                            detection_count += 1
                
                current_x_offset += col_width
            
            current_y_offset += row_height
        
        print(f"âœ… íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì™„ë£Œ: {detection_count}ê°œ ë°”ìš´ë”© ë°•ìŠ¤")
        
        # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
        merged_filename = f"merged_detection_{timestamp}.jpg"
        merged_path = os.path.join(output_base, merged_filename)
        
        # í° ì´ë¯¸ì§€ì¸ ê²½ìš° í¬ê¸° ì¡°ì • (ë©”ëª¨ë¦¬ ì ˆì•½ ë° íŒŒì¼ í¬ê¸° ìµœì í™”)
        if total_width > 8192 or total_height > 8192:
            scale = min(8192 / total_width, 8192 / total_height)
            new_width = int(total_width * scale)
            new_height = int(total_height * scale)
            print(f"ğŸ”§ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {total_width}x{total_height} â†’ {new_width}x{new_height}")
            merged_image = cv2.resize(merged_image, (new_width, new_height))
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ì„¤ì •ìœ¼ë¡œ ì €ì¥
        cv2.imwrite(merged_path, merged_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
        
        print(f"âœ… í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {merged_filename}")
        return merged_filename
        
    except Exception as e:
        print(f"âš ï¸ í•©ì³ì§„ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ê¸°ë³¸ ì„¤ì •
DEFAULT_WEIGHTS = str(config.DEFAULT_MODEL_PATH)
DEFAULT_OUTPUT_DIR = str(config.API_RESULTS_DIR)

def pixel_to_tm(px: float, py: float, tfw: List[float]) -> tuple:
    """í”½ì…€ ì¢Œí‘œë¥¼ TM ì¢Œí‘œë¡œ ë³€í™˜
    
    Args:
        px, py: í”½ì…€ ì¢Œí‘œ
        tfw: TFW íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸ [A, D, B, E, C, F]
    
    Returns:
        tuple: (tm_x, tm_y) TM ì¢Œí‘œ
    """
    A, D, B, E, C, F = tfw
    tm_x = A * px + B * py + C
    tm_y = D * px + E * py + F
    return tm_x, tm_y

def get_tfw_from_tiff(image_path: str) -> Optional[List[float]]:
    """TIFF íŒŒì¼ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œí•˜ì—¬ TFW íŒŒë¼ë¯¸í„° ìƒì„±
    
    Args:
        image_path: TIFF ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with rasterio.open(image_path) as src:
            if src.transform:
                # Affine ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ TFW íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                transform = src.transform
                # Affine ë§¤íŠ¸ë¦­ìŠ¤: [a, b, c, d, e, f]
                # TFW í˜•ì‹: [A=a, D=d, B=b, E=e, C=c, F=f]
                tfw_params = [
                    transform.a,  # A: X í”½ì…€ í¬ê¸°
                    transform.d,  # D: Y í”½ì…€ í¬ê¸° (ë³´í†µ ìŒìˆ˜)
                    transform.b,  # B: íšŒì „/ê¸°ìš¸ê¸°
                    transform.e,  # E: íšŒì „/ê¸°ìš¸ê¸°
                    transform.c,  # C: ì¢Œìƒë‹¨ X ì¢Œí‘œ
                    transform.f   # F: ì¢Œìƒë‹¨ Y ì¢Œí‘œ
                ]
                return tfw_params
    except Exception as e:
        print(f"âš ï¸ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

def load_tfw_file(tfw_path: str) -> Optional[List[float]]:
    """TFW íŒŒì¼ì—ì„œ ë³€í™˜ íŒŒë¼ë¯¸í„° ë¡œë“œ
    
    Args:
        tfw_path: TFW íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with open(tfw_path, 'r') as f:
            lines = f.readlines()
            if len(lines) >= 6:
                return [float(line.strip()) for line in lines[:6]]
    except Exception as e:
        print(f"âš ï¸ TFW íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return None

def draw_bounding_boxes_on_image(image, results):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜ - ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™”"""
    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    img_height, img_width = image.shape[:2]
    
    for result in results:
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                # ï¿½ YOLO ì›ë³¸ ì˜ˆì¸¡ ì¢Œí‘œ ì‚¬ìš© (ì •í™•í•œ ìœ„ì¹˜ í‘œì‹œ)
                # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì¡°ì • ì—†ì´ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì •í™•í•œ ìœ„ì¹˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                new_x1 = int(x1)
                new_y1 = int(y1)
                new_x2 = int(x2)
                new_y2 = int(y2)
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì • (ë‚®ì€ ì‹ ë¢°ë„ëŠ” ì£¼í™©ìƒ‰ìœ¼ë¡œ)
                if confidence >= 0.7:
                    bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                elif confidence >= 0.4:
                    bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                else:
                    bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                
                # ìµœì í™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë” ì–‡ì€ ì„ )
                cv2.rectangle(image, (new_x1, new_y1), (new_x2, new_y2), 
                            bbox_color, 2)  # ë‘ê»˜ë¥¼ 2ë¡œ ì¤„ì„
                
                # ğŸ¨ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±° (ê¹”ë”í•œ ì‹œê°í™”ë¥¼ ìœ„í•´)
                # ìƒ‰ìƒë§Œìœ¼ë¡œ ì‹ ë¢°ë„ë¥¼ í‘œí˜„: ì´ˆë¡(ë†’ìŒ) â†’ ì£¼í™©(ì¤‘ê°„) â†’ ë¹¨ê°•(ë‚®ìŒ)

@router.get("/download/{filename}")
async def download_csv_result(filename: str):
    """
    íƒì§€ ê²°ê³¼ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(DEFAULT_OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )


@router.get("/visualization/{filename}")
async def download_visualization_image(filename: str):
    """
    íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(str(config.API_VISUALIZATION_DIR), filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='image/jpeg'
    )


@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ YOLO ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    models_dir = "models"
    results_dir = "results"
    
    available_models = []
    
    # models ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    if os.path.exists(models_dir):
        for root, dirs, files in os.walk(models_dir):
            for file in files:
                if file.endswith('.pt'):
                    model_path = os.path.join(root, file)
                    available_models.append({
                        "name": file,
                        "path": model_path,
                        "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                    })
    
    # results ë””ë ‰í† ë¦¬ì˜ weights í´ë”ë„ ìŠ¤ìº”
    if os.path.exists(results_dir):
        for root, dirs, files in os.walk(results_dir):
            if "weights" in root:
                for file in files:
                    if file.endswith('.pt'):
                        model_path = os.path.join(root, file)
                        available_models.append({
                            "name": f"{os.path.basename(os.path.dirname(root))}_{file}",
                            "path": model_path,
                            "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                        })
    
    return {
        "available_models": available_models,
        "total_count": len(available_models)
    }


@router.post("/detect", response_model=BatchInferenceResponse)
async def detect_damaged_trees(
    images_zip: UploadFile = File(..., description="ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼"),
    model_path: str = Form(default=DEFAULT_WEIGHTS, description="ì‚¬ìš©í•  YOLO ëª¨ë¸ ê²½ë¡œ"),
    confidence: float = Form(default=config.DEFAULT_CONFIDENCE, description="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.16)"),
    iou_threshold: float = Form(default=config.DEFAULT_IOU_THRESHOLD, description="IoU ì„ê³„ê°’ (ì¤‘ë³µ íƒì§€ ì œê±°ìš©)"),
    save_visualization: bool = Form(default=True, description="íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€"),
    output_tm_coordinates: bool = Form(default=True, description="TM ì¢Œí‘œ ë³€í™˜ ì—¬ë¶€")
):
    """
    ğŸš€ **ì†Œë‚˜ë¬´ì¬ì„ ì¶©ë³‘ í”¼í•´ëª© íƒì§€ API**
    
    ZIP íŒŒì¼ë¡œ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤(ë˜ëŠ” íƒ€ì¼ë“¤)ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ í”¼í•´ëª©ì„ íƒì§€í•©ë‹ˆë‹¤.
    
    **ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:**
    - ğŸ–¼ï¸ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ íƒ€ì¼ ì¼ê´„ ì²˜ë¦¬
    - ğŸ” YOLO ëª¨ë¸ ê¸°ë°˜ í”¼í•´ëª© ìë™ íƒì§€
    - ğŸ—ºï¸ TM ì¢Œí‘œ ë³€í™˜ (ì§€ë¦¬ì°¸ì¡° ì •ë³´ í¬í•¨ ì‹œ)
    - ğŸ“Š CSV ê²°ê³¼ íŒŒì¼ ìƒì„±
    - ğŸ¨ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)
    - ğŸ–¼ï¸ ì „ì²´ ì´ë¯¸ì§€ ë³‘í•© ì‹œê°í™”
    
    **ğŸ“‹ ë§¤ê°œë³€ìˆ˜:**
    - **images_zip**: ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼ (.zip)
    - **model_path**: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ìµœì í™”ëœ ì†Œë‚˜ë¬´ ëª¨ë¸)
    - **confidence**: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0, ê¸°ë³¸ê°’: 0.28)
    - **iou_threshold**: IoU ì„ê³„ê°’ (0.0-1.0, ì¤‘ë³µ íƒì§€ ì œê±°ìš©, ê¸°ë³¸ê°’: 0.6)
    - **save_visualization**: íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    - **output_tm_coordinates**: TM ì¢Œí‘œ ë³€í™˜ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    
    **ğŸ¯ ì¶œë ¥:**
    - ğŸ“Š íƒì§€ í†µê³„ ì •ë³´
    - ğŸ“ ê²°ê³¼ ZIP íŒŒì¼ (CSV + ì‹œê°í™” ì´ë¯¸ì§€ë“¤)
    - ğŸ–¼ï¸ ë³‘í•©ëœ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™”
    - ğŸ—ºï¸ TM ì¢Œí‘œê°€ í¬í•¨ëœ CSV íŒŒì¼
    """
    
    try:
        # íŒŒì¼ëª… ê²€ì¦
        if not images_zip.filename:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì— íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ZIP íŒŒì¼ í™•ì¥ì ê²€ì¦
        if not images_zip.filename.lower().endswith('.zip'):
            raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ëª¨ë¸ ê²½ë¡œ ê²€ì¦
        if not os.path.exists(model_path):
            raise HTTPException(status_code=400, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # YOLO ëª¨ë¸ ë¡œë“œ (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
        print(f"ğŸ¤– ëª¨ë¸ ë¡œë”©: {model_path}")
        model = YOLO(model_path)
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        print(f"  ğŸ“‹ ëª¨ë¸ ì •ë³´:")
        print(f"    - í´ë˜ìŠ¤ ìˆ˜: {len(model.names) if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - í´ë˜ìŠ¤ ëª…: {model.names if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - ëª¨ë¸ í¬ê¸°: {os.path.getsize(model_path) / 1024 / 1024:.1f}MB")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            
            # ZIP íŒŒì¼ ì €ì¥ ë° ì••ì¶• í•´ì œ
            zip_path = os.path.join(temp_dir, images_zip.filename)
            with open(zip_path, "wb") as f:
                shutil.copyfileobj(images_zip.file, f)
            
            # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
            extract_dir = os.path.join(temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
            image_files = []
            for root, dirs, files in os.walk(extract_dir):
                # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
                if '__MACOSX' in root:
                    continue
                for file in files:
                    # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                    if file.startswith('.') or file.startswith('._'):
                        continue
                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                        image_files.append(os.path.join(root, file))
            
            if not image_files:
                raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_base = os.path.join(DEFAULT_OUTPUT_DIR, f"batch_inference_{timestamp}")
            
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            os.makedirs(output_base, exist_ok=True)
            
            viz_dir = None
            if save_visualization:
                viz_dir = os.path.join(output_base, "visualizations")
                os.makedirs(viz_dir, exist_ok=True)
            
            # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
            all_results = []
            processed_images = []
            failed_images = []
            
            print(f"ğŸ“Š ë°°ì¹˜ ì¶”ë¡  ì‹œì‘: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì •")
            
            for idx, image_path in enumerate(image_files, 1):
                try:
                    image_name = os.path.basename(image_path)
                    print(f"ğŸ” ì²˜ë¦¬ ì¤‘ ({idx}/{len(image_files)}): {image_name}")
                    
                    # ğŸ¯ ì´˜ì´˜í•œ í”¼í•´ëª© íŠ¹í™” ìµœì í™”ëœ 3ë‹¨ê³„ ì¶”ë¡ 
                    print(f"  ğŸ” ì´˜ì´˜í•œ í”¼í•´ëª© íŠ¹í™” ì¶”ë¡  ì‹œì‘...")
                    
                    # 1ë‹¨ê³„: í‘œì¤€ íƒì§€ (ì¼ë°˜ì ì¸ í”¼í•´ëª©)
                    print(f"    ğŸ“Š 640px í‘œì¤€: conf=0.15, iou=0.35")
                    results_640 = model(image_path, imgsz=640, conf=0.15, iou=0.35)
                    
                    # 2ë‹¨ê³„: ê³ í•´ìƒë„ ì¤‘ë°€ë„ (ì‘ì€ í”¼í•´ëª©)
                    print(f"    ğŸ“Š 832px ê³ í•´ìƒë„: conf=0.13, iou=0.2")  
                    results_832 = model(image_path, imgsz=832, conf=0.13, iou=0.2)
                    
                    # 3ë‹¨ê³„: ì´ˆê³ í•´ìƒë„ ì´ˆë°€ì§‘ (ì´˜ì´˜í•œ í”¼í•´ëª© ì „ìš©) â­ ë”ìš± ê°•í™”!
                    print(f"    ğŸ“Š 1024px ì´ˆë°€ì§‘: conf=0.10, iou=0.05 (ê·¹í•œ ë°€ì§‘)")
                    results_1024 = model(image_path, imgsz=1024, conf=0.10, iou=0.05)
                    
                    # ê¸°ì¡´ ë³€ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€ (ê²°ê³¼ í†µí•©)
                    primary_results = results_640
                    dense_results = results_832  
                    fine_results = results_1024  # ì´˜ì´˜í•œ ì§€ì—­ìš©
                    
                    # TFW ì •ë³´ ì¶”ì¶œ (TM ì¢Œí‘œ ë³€í™˜ìš©)
                    tfw_params = None
                    if output_tm_coordinates:
                        tfw_params = get_tfw_from_tiff(image_path)
                        if not tfw_params:
                            # ë™ì¼ ë””ë ‰í† ë¦¬ì—ì„œ TFW íŒŒì¼ ì°¾ê¸°
                            tfw_file_path = image_path.replace('.tif', '.tfw').replace('.tiff', '.tfw')
                            if os.path.exists(tfw_file_path):
                                tfw_params = load_tfw_file(tfw_file_path)
                    
                    # YOLOv11s ë‚´ì¥ NMSë§Œ ì‚¬ìš© (ì¶”ê°€ NMS ë¶ˆí•„ìš”)
                    
                    # ğŸ§© 3ë‹¨ê³„ ê²°ê³¼ í†µí•© ë° ì§€ëŠ¥í˜• ì¤‘ë³µ ì œê±°
                    all_detections_raw = []
                    
                    # 1ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ë†’ì€ ìš°ì„ ìˆœìœ„)
                    stage1_count = 0
                    for result in primary_results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                conf = float(box.conf[0].cpu().numpy())
                                all_detections_raw.append({
                                    'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                    'box': box, 'stage': 1, 'priority': 3
                                })
                                stage1_count += 1
                    
                    # 2ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ì¤‘ê°„ ìš°ì„ ìˆœìœ„)
                    stage2_count = 0
                    for result in dense_results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                conf = float(box.conf[0].cpu().numpy())
                                all_detections_raw.append({
                                    'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                    'box': box, 'stage': 2, 'priority': 2
                                })
                                stage2_count += 1
                    
                    # 3ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ë‚®ì€ ìš°ì„ ìˆœìœ„)
                    stage3_count = 0
                    for result in fine_results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                conf = float(box.conf[0].cpu().numpy())
                                all_detections_raw.append({
                                    'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                    'box': box, 'stage': 3, 'priority': 1
                                })
                                stage3_count += 1
                    
                    print(f"  ğŸ“Š ë‹¨ê³„ë³„ ì›ì‹œ íƒì§€: 1ë‹¨ê³„={stage1_count}ê°œ, 2ë‹¨ê³„={stage2_count}ê°œ, 3ë‹¨ê³„={stage3_count}ê°œ")
                    
                    # ğŸ¯ ì§€ëŠ¥í˜• ì¤‘ë³µ ì œê±° (ìš°ì„ ìˆœìœ„ + ê±°ë¦¬ ê¸°ë°˜)
                    # ë†’ì€ ìš°ì„ ìˆœìœ„(stage1) > ë†’ì€ ì‹ ë¢°ë„ > ë‚®ì€ stage ìˆœìœ¼ë¡œ ì •ë ¬
                    all_detections_raw.sort(key=lambda x: (x['priority'], x['conf']), reverse=True)
                    
                    filtered_detections = []
                    MIN_DISTANCE = 15  # 15í”½ì…€ ì´ë‚´ëŠ” ì¤‘ë³µ (ê¸°ì¡´ 25ì—ì„œ ì¤„ì„)
                    
                    for detection in all_detections_raw:
                        is_duplicate = False
                        for existing in filtered_detections:
                            dist = ((detection['center_x'] - existing['center_x']) ** 2 + 
                                   (detection['center_y'] - existing['center_y']) ** 2) ** 0.5
                            if dist < MIN_DISTANCE:
                                is_duplicate = True
                                break
                        
                        if not is_duplicate:
                            filtered_detections.append(detection)
                    
                    print(f"  ğŸ§¹ ì¤‘ë³µ ì œê±° í›„: {len(filtered_detections)}ê°œ (ê±°ë¦¬ {MIN_DISTANCE}px ê¸°ì¤€)")
                    
                    # ê²°ê³¼ ì²˜ë¦¬ ë° ë°€ë„ ê¸°ë°˜ ë™ì  ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ìµœì í™”
                    image_results = []
                    all_boxes = [(det['center_x'], det['center_y'], det['conf']) for det in filtered_detections]
                        # ê° íƒì§€ì— ëŒ€í•´ ë°€ë„ ê¸°ë°˜ í¬ê¸° ì¡°ì •
                    for i, detection_info in enumerate(filtered_detections):
                        center_x = detection_info['center_x']
                        center_y = detection_info['center_y']
                        box = detection_info['box']
                        stage = detection_info['stage']
                        
                        conf_value = detection_info['conf']
                        print(f"    íƒì§€ {i+1}: ì‹ ë¢°ë„ {conf_value:.4f} (ë‹¨ê³„{stage})")
                        
                        # ì›ë³¸ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        orig_width = x2 - x1
                        orig_height = y2 - y1
                        
                        # ğŸŒ² ì£¼ë³€ ë°€ë„ ê¸°ë°˜ ë™ì  í¬ê¸° ì¡°ì •
                        SEARCH_RADIUS = 80  # 80í”½ì…€ ë°˜ê²½ ë‚´ ë°€ë„ í™•ì¸
                        nearby_count = 0
                        
                        # í˜„ì¬ íƒì§€ ì£¼ë³€ì˜ ë‹¤ë¥¸ íƒì§€ë“¤ ê°œìˆ˜ ì„¸ê¸°
                        for other_x, other_y, _ in all_boxes:
                            if other_x != center_x or other_y != center_y:  # ìê¸° ìì‹  ì œì™¸
                                distance = ((center_x - other_x) ** 2 + (center_y - other_y) ** 2) ** 0.5
                                if distance <= SEARCH_RADIUS:
                                    nearby_count += 1
                        
                        # ğŸ¯ ì‹¤ìš©ì  ì ‘ê·¼: YOLO ì˜ˆì¸¡ í¬ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‹œê°í™”ë§Œ ê°œì„ )
                        # ì‹¤ì œ íƒì§€ ì„±ëŠ¥ì€ ë©€í‹°ìŠ¤ì¼€ì¼ í•´ìƒë„ê°€ ë‹´ë‹¹
                        
                        # ë°€ë„ ë ˆë²¨ ê³„ì‚° (ì‹œê°í™”ìš©)
                        if nearby_count >= 5:
                            density_level = "ë§¤ìš°ì´˜ì´˜"
                        elif nearby_count >= 3:
                            density_level = "ì´˜ì´˜"
                        elif nearby_count >= 1:
                            density_level = "ë³´í†µ"
                        else:
                            density_level = "ì™¸ë”´"
                        
                        print(f"      ğŸ¯ ì£¼ë³€ ë°€ë„: {nearby_count}ê°œ â†’ ë°€ë„ ë ˆë²¨: {density_level}")
                        print(f"      ğŸ“ YOLO ì˜ˆì¸¡ í¬ê¸°: {orig_width:.1f}x{orig_height:.1f}px")
                        
                        # ğŸŒ² ì†Œë‚˜ë¬´ í”¼í•´ëª© ì‹¤ìš©ì  í¬ê¸°: ë°€ë„ ê¸°ë°˜ ì ì‘ì  ì œí•œ
                        if density_level == "ë§ì´ ë°€ì§‘ëœ ê³³":
                            MAX_SIZE = 20   # ì´˜ì´˜í•œ ì§€ì—­ì€ ì‘ê²Œ
                            TARGET_SIZE = 16
                        elif density_level == "ì ë‹¹íˆ ë°€ì§‘ëœ ê³³":
                            MAX_SIZE = 30   # ì ë‹¹íˆ ì‘ê²Œ
                            TARGET_SIZE = 22
                        elif density_level == "ë³´í†µ":
                            MAX_SIZE = 40   # ë³´í†µ í¬ê¸°
                            TARGET_SIZE = 28
                        else:  # ì™¸ë”´
                            MAX_SIZE = 50   # ì™¸ë”´ ì§€ì—­ì€ í¬ê²Œ (ëª…í™• í‘œì‹œ)
                            TARGET_SIZE = 35
                            
                        MIN_SIZE = 8    # ìµœì†Œ í¬ê¸° ë³´ì¥
                        
                        # ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì œí•œ, ë‚˜ë¨¸ì§€ëŠ” YOLO ì˜ˆì¸¡ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        if orig_width > MAX_SIZE or orig_height > MAX_SIZE:
                            # ë„ˆë¬´ í° ê²½ìš°ë§Œ ì œí•œ (ë¹„ìœ¨ ìœ ì§€í•˜ë©° ì¶•ì†Œ)
                            scale_factor = min(MAX_SIZE / orig_width, MAX_SIZE / orig_height)
                            new_width = orig_width * scale_factor
                            new_height = orig_height * scale_factor
                            print(f"      ğŸ“ ëŒ€í˜•ëª© í¬ê¸° ì¡°ì •: {orig_width:.1f}x{orig_height:.1f} â†’ {new_width:.1f}x{new_height:.1f}px")
                        elif orig_width < MIN_SIZE or orig_height < MIN_SIZE:
                            # ë„ˆë¬´ ì‘ì€ ê²½ìš°ë§Œ ìµœì†Œ í¬ê¸° ë³´ì¥
                            new_width = max(orig_width, MIN_SIZE)
                            new_height = max(orig_height, MIN_SIZE)
                            print(f"      ğŸ“ ìµœì†Œ í¬ê¸° ë³´ì¥: {orig_width:.1f}x{orig_height:.1f} â†’ {new_width:.1f}x{new_height:.1f}px")
                        else:
                            # TARGET_SIZE ê¸°ì¤€ìœ¼ë¡œ ì ì ˆíˆ ì¡°ì •
                            avg_size = (orig_width + orig_height) / 2
                            if avg_size > TARGET_SIZE * 1.2:  # 20% ì´ìƒ í¬ë©´ ì¡°ì •
                                scale = TARGET_SIZE / avg_size
                                new_width = orig_width * scale
                                new_height = orig_height * scale
                                print(f"      ğŸ“ ì ì • í¬ê¸° ì¡°ì •: {orig_width:.1f}x{orig_height:.1f} â†’ {new_width:.1f}x{new_height:.1f}px")
                            else:
                                # ì ì • ë²”ìœ„ëŠ” ì›ë³¸ ì‚¬ìš©
                                new_width = orig_width
                                new_height = orig_height
                                print(f"      âœ… ì ì • í¬ê¸°: {new_width:.1f}x{new_height:.1f}px")
                        
                        conf = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # TM ì¢Œí‘œ ë³€í™˜
                        tm_x, tm_y = None, None
                        if tfw_params:
                            tm_x, tm_y = pixel_to_tm(center_x, center_y, tfw_params)
                        
                        detection = DetectionResult(
                            filename=image_name,
                            class_id=class_id,
                            center_x=center_x,
                            center_y=center_y,
                            width=new_width,  # ë°€ë„ ê¸°ë°˜ ì¡°ì •ëœ í¬ê¸°
                            height=new_height,  # ë°€ë„ ê¸°ë°˜ ì¡°ì •ëœ í¬ê¸°
                            confidence=conf,
                            tm_x=tm_x,
                            tm_y=tm_y
                        )
                        
                        image_results.append(detection)
                        all_results.append(detection)
                    
                    processed_images.append(image_name)
                    raw_detections = stage1_count + stage2_count + stage3_count
                    print(f"âœ… ì™„ë£Œ: {image_name} (ì›ì‹œ: {raw_detections}ê°œ, ìµœì¢…: {len(image_results)}ê°œ íƒì§€)")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ (ë™ì  ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ë°˜ì˜)
                    if save_visualization and viz_dir and image_results:
                        viz_filename = f"{os.path.splitext(image_name)[0]}_detected_{timestamp}.jpg"
                        viz_path = os.path.join(viz_dir, viz_filename)
                        try:
                            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                            image = cv2.imread(image_path)
                            if image is not None:
                                # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ë™ì  í¬ê¸° ë°˜ì˜)
                                for detection in image_results:
                                    x1 = int(detection.center_x - detection.width / 2)
                                    y1 = int(detection.center_y - detection.height / 2)
                                    x2 = int(detection.center_x + detection.width / 2)
                                    y2 = int(detection.center_y + detection.height / 2)
                                    
                                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì •
                                    if detection.confidence >= 0.7:
                                        bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                                    elif detection.confidence >= 0.4:
                                        bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                                    else:
                                        bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                                    
                                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í¬ê¸°ì— ë”°ë¥¸ ì„  ë‘ê»˜ ì¡°ì •)
                                    thickness = 2 if detection.width >= 24 else 1
                                    cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, thickness)
                                    
                                    # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±° (ì‹œì¸ì„± í–¥ìƒì„ ìœ„í•´)
                                
                                # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                                cv2.imwrite(viz_path, image)
                                print(f"  ğŸ–¼ï¸ ì‹œê°í™” ì €ì¥: {viz_filename}")
                        except Exception as e:
                            print(f"âš ï¸ ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨ ({image_name}): {e}")
                    elif save_visualization and viz_dir:
                        # íƒì§€ ê²°ê³¼ê°€ ì—†ì–´ë„ ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (íšŒìƒ‰ í…Œë‘ë¦¬ë¡œ í‘œì‹œ)
                        original_img = cv2.imread(image_path)
                        if original_img is not None:
                            h, w = original_img.shape[:2]
                            cv2.rectangle(original_img, (0, 0), (w-1, h-1), (128, 128, 128), 10)
                            
                            viz_filename = f"{os.path.splitext(image_name)[0]}_no_detection_{timestamp}.jpg"
                            viz_path = os.path.join(viz_dir, viz_filename)
                            cv2.imwrite(viz_path, original_img)
                            print(f"  ğŸ–¼ï¸ íƒì§€ì—†ìŒ ì‹œê°í™” ì €ì¥: {viz_filename}")
                    
                    # ì¶”ë¡  ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ
                    del primary_results, dense_results, fine_results
                    
                    # íƒì§€ê°€ ë§¤ìš° ì ìœ¼ë©´ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
                    if len(image_results) < 3:
                        print(f"  ğŸ” íƒì§€ ìˆ˜ê°€ ì ìŒ - ê·¹í•œ ë””ë²„ê·¸")
                        # ê·¹í•œ ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¬ì‹œë„
                        extreme_results = model(image_path, conf=0.01, iou=0.1)
                        extreme_count = sum(len(r.boxes) if r.boxes is not None else 0 for r in extreme_results)
                        print(f"  ğŸ” ê·¹í•œ ë””ë²„ê·¸ (conf=0.01, iou=0.1): {extreme_count}ê°œ íƒì§€")
                        del extreme_results
                    
                except Exception as e:
                    failed_images.append(f"{os.path.basename(image_path)}: {str(e)}")
                    print(f"âŒ ì‹¤íŒ¨: {os.path.basename(image_path)} - {e}")
            
            # CSV íŒŒì¼ ìƒì„±
            csv_file_url = None
            if all_results:
                csv_filename = f"batch_detections_{timestamp}.csv"
                csv_path = os.path.join(output_base, csv_filename)
                
                # íƒì§€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                results_data = []
                for idx, detection in enumerate(all_results, 1):
                    row = {
                        'no': idx,
                        'filename': detection.filename,
                        'class_id': detection.class_id,
                        'center_x': detection.center_x,
                        'center_y': detection.center_y,
                        'width': detection.width,
                        'height': detection.height,
                        'confidence': detection.confidence
                    }
                    
                    # TM ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                    if detection.tm_x is not None and detection.tm_y is not None:
                        row['tm_x'] = detection.tm_x
                        row['tm_y'] = detection.tm_y
                    
                    results_data.append(row)
                
                # CSV ì €ì¥
                df = pd.DataFrame(results_data)
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                csv_file_url = f"/api/v1/inference/download/{csv_filename}"
            
            # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            merged_viz_filename = None
            if save_visualization and all_results:
                merged_viz_filename = create_merged_visualization(
                    all_results, output_base, timestamp, extract_dir, tile_size=config.DEFAULT_TILE_SIZE
                )
            
            # ê²°ê³¼ ZIP íŒŒì¼ ìƒì„±
            results_zip_url = None
            if all_results or (save_visualization and viz_dir and os.path.exists(viz_dir) and os.listdir(viz_dir)):
                zip_filename = f"batch_results_{timestamp}.zip"
                zip_path = os.path.join(DEFAULT_OUTPUT_DIR, zip_filename)
                
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # CSV íŒŒì¼ ì¶”ê°€
                    if all_results:
                        csv_path = os.path.join(output_base, f"batch_detections_{timestamp}.csv")
                        if os.path.exists(csv_path):
                            zipf.write(csv_path, f"batch_detections_{timestamp}.csv")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
                    if save_visualization and viz_dir and os.path.exists(viz_dir):
                        for file in os.listdir(viz_dir):
                            file_path = os.path.join(viz_dir, file)
                            if os.path.isfile(file_path):  # íŒŒì¼ì¸ì§€ í™•ì¸
                                zipf.write(file_path, f"visualizations/{file}")
                    
                    # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì¶”ê°€
                    if merged_viz_filename:
                        merged_path = os.path.join(output_base, merged_viz_filename)
                        if os.path.exists(merged_path):
                            zipf.write(merged_path, merged_viz_filename)
                
                results_zip_url = f"/api/v1/inference/download/{zip_filename}"
            
            return BatchInferenceResponse(
                success=True,
                message=f"ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ: {len(processed_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬, {len(all_results)}ê°œ ê°ì²´ íƒì§€",
                total_images=len(image_files),
                total_detections=len(all_results),
                processed_images=processed_images,
                failed_images=failed_images,
                csv_file_url=csv_file_url,
                results_zip_url=results_zip_url,
                merged_visualization=merged_viz_filename
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
