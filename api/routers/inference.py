# ì¶”ë¡ /íƒì§€ API ë¼ìš°í„° - yolo_infer_to_gps.py ê¸°ë°˜
# YOLO ëª¨ë¸ë¡œ í”¼í•´ëª© íƒì§€ + GPS ì¢Œí‘œ ë³€í™˜ + CSV ì €ì¥

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import os
import tempfile
import shutil
import pandas as pd
import cv2
import rasterio
from rasterio.transform import from_bounds
from rasterio import Affine
from ultralytics import YOLO
import datetime
import json
from pathlib import Path
import sys
import numpy as np
import zipfile

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (scripts í´ë” ì ‘ê·¼ìš©)
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from .. import config

router = APIRouter()

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class DetectionResult(BaseModel):
    filename: str
    class_id: int
    center_x: float
    center_y: float
    width: float
    height: float
    confidence: Optional[float] = None
    tm_x: Optional[float] = None  # TM ì¢Œí‘œ X
    tm_y: Optional[float] = None  # TM ì¢Œí‘œ Y

class BatchInferenceResponse(BaseModel):
    success: bool
    message: str
    total_images: int
    total_detections: int
    processed_images: List[str]
    failed_images: List[str]
    csv_file_url: Optional[str] = None
    results_zip_url: Optional[str] = None
    merged_visualization: Optional[str] = None  # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ íŒŒì¼ëª…

def extract_tile_position(filename: str) -> tuple:
    """íƒ€ì¼ íŒŒì¼ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (prefix_tile_x_y.tif -> (x, y))"""
    try:
        # ë‹¤ì–‘í•œ íŒŒì¼ëª… í˜•ì‹ ì§€ì›
        name_without_ext = filename.replace('.tif', '').replace('.tiff', '').replace('.jpg', '').replace('.jpeg', '').replace('.png', '')
        
        # í˜•ì‹ 1: A20250917_tile_2_1 -> ['A20250917', 'tile', '2', '1']
        parts = name_without_ext.split('_')
        
        # tileì´ í¬í•¨ëœ ê²½ìš°
        if 'tile' in parts:
            tile_idx = parts.index('tile')
            if len(parts) > tile_idx + 2:
                x = int(parts[tile_idx + 1])
                y = int(parts[tile_idx + 2])
                return (x, y)
        
        # í˜•ì‹ 2: prefix_x_y (ë§ˆì§€ë§‰ ë‘ ê°œê°€ ìˆ«ìì¸ ê²½ìš°)
        if len(parts) >= 3:
            try:
                x = int(parts[-2])
                y = int(parts[-1])
                return (x, y)
            except ValueError:
                pass
        
        # í˜•ì‹ 3: ì •ê·œì‹ìœ¼ë¡œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
        import re
        pattern = r'(\d+)_(\d+)(?:\.|$)'
        match = re.search(pattern, filename)
        if match:
            x = int(match.group(1))
            y = int(match.group(2))
            return (x, y)
            
    except (ValueError, IndexError, AttributeError):
        pass
    
    # íŒŒì‹± ì‹¤íŒ¨ì‹œ íŒŒì¼ëª…ì— _0_0ì´ ìˆëŠ”ì§€ í™•ì¸
    if '_0_0' in filename:
        return (0, 0)
    
    print(f"âš ï¸ íƒ€ì¼ ìœ„ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
    return (0, 0)  # ê¸°ë³¸ê°’


def create_merged_visualization(all_results: List[DetectionResult], output_base: str, 
                               timestamp: str, extract_dir: str, tile_size: int = config.DEFAULT_TILE_SIZE) -> Optional[str]:
    """íƒ€ì¼ë³„ íƒì§€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™” ìƒì„±"""
    
    if not all_results:
        return None
    
    try:
        print("ğŸ–¼ï¸ í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # ëª¨ë“  íƒ€ì¼ íŒŒì¼ ë¨¼ì € ìˆ˜ì§‘ (íƒì§€ ê²°ê³¼ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´)
        all_tile_files = {}
        tile_positions = {}
        
        # extract_dirì—ì„œ ëª¨ë“  íƒ€ì¼ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
        for root, dirs, files in os.walk(extract_dir):
            # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
            if '__MACOSX' in root:
                continue
            for file in files:
                # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                if file.startswith('.') or file.startswith('._'):
                    continue
                if file.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png')):
                    x, y = extract_tile_position(file)
                    if (x, y) != (0, 0) or '_0_0' in file:  # (0,0)ì€ ì‹¤ì œ ì¢Œí‘œì´ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨
                        tile_path = os.path.join(root, file)
                        all_tile_files[(x, y)] = tile_path
                        
                        # íƒì§€ ê²°ê³¼ê°€ ìˆëŠ” íƒ€ì¼ ì²´í¬
                        if (x, y) not in tile_positions:
                            tile_positions[(x, y)] = []
        
        # íƒì§€ ê²°ê³¼ë¥¼ í•´ë‹¹ íƒ€ì¼ ìœ„ì¹˜ì— í• ë‹¹
        for result in all_results:
            x, y = extract_tile_position(result.filename)
            if (x, y) in tile_positions:
                tile_positions[(x, y)].append(result)
        
        if not all_tile_files:
            print("âš ï¸ íƒ€ì¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì¼ë“¤ë¡œë¶€í„° ê²©ì ë²”ìœ„ ê³„ì‚°
        existing_positions = list(all_tile_files.keys())
        min_x = min(pos[0] for pos in existing_positions)
        max_x = max(pos[0] for pos in existing_positions)
        min_y = min(pos[1] for pos in existing_positions)
        max_y = max(pos[1] for pos in existing_positions)
        
        print(f"ğŸ“Š íƒ€ì¼ ê²©ì ë²”ìœ„: X({min_x}~{max_x}), Y({min_y}~{max_y})")
        print(f"ğŸ“Š ì „ì²´ íƒ€ì¼ ìˆ˜: {len(all_tile_files)}ê°œ")
        
        # ê° í–‰/ì—´ë³„ ì‹¤ì œ í¬ê¸° ê³„ì‚° (ì‹¤ì œ íƒ€ì¼ ì´ë¯¸ì§€ ê¸°ë°˜)
        row_heights = {}  # ty -> height
        col_widths = {}   # tx -> width
        
        # ëª¨ë“  íƒ€ì¼ì˜ í¬ê¸° ë¯¸ë¦¬ ì¸¡ì •
        print("ğŸ“ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì¤‘...")
        for (tx, ty), tile_path in all_tile_files.items():
            try:
                tile_img = cv2.imread(tile_path)
                if tile_img is not None:
                    h, w = tile_img.shape[:2]
                    
                    # í•´ë‹¹ í–‰/ì—´ì˜ ìµœëŒ€ í¬ê¸° ì €ì¥
                    if ty not in row_heights:
                        row_heights[ty] = h
                    else:
                        row_heights[ty] = max(row_heights[ty], h)
                    
                    if tx not in col_widths:
                        col_widths[tx] = w
                    else:
                        col_widths[tx] = max(col_widths[tx], w)
                else:
                    print(f"âš ï¸ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
            except Exception as e:
                print(f"âš ï¸ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì‹¤íŒ¨ {tile_path}: {e}")
        
        # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
        total_width = sum(col_widths.get(tx, tile_size) for tx in range(min_x, max_x + 1))
        total_height = sum(row_heights.get(ty, tile_size) for ty in range(min_y, max_y + 1))
        
        print(f"ğŸ“ ê³„ì‚°ëœ ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°: {total_width}x{total_height}")
        print(f"ğŸ“ í–‰ë³„ ë†’ì´: {row_heights}")
        print(f"ğŸ“ ì—´ë³„ ë„ˆë¹„: {col_widths}")
        
        # ì „ì²´ ì´ë¯¸ì§€ ìƒì„± (íšŒìƒ‰ ë°°ê²½ìœ¼ë¡œ ì‹œì‘ - ëˆ„ë½ ì˜ì—­ ì‹ë³„ìš©)
        merged_image = np.full((total_height, total_width, 3), (128, 128, 128), dtype=np.uint8)
        
        # íƒ€ì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ í•©ì¹˜ê¸°
        current_y = 0
        for ty in range(min_y, max_y + 1):
            current_x = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                if (tx, ty) in all_tile_files:
                    tile_path = all_tile_files[(tx, ty)]
                    try:
                        # íƒ€ì¼ ì´ë¯¸ì§€ ë¡œë“œ
                        tile_img = cv2.imread(tile_path)
                        if tile_img is not None:
                            h, w = tile_img.shape[:2]
                            
                            # ë°°ì¹˜ ì˜ì—­ ê³„ì‚°
                            end_x = min(current_x + w, total_width)
                            end_y = min(current_y + h, total_height)
                            
                            actual_w = end_x - current_x
                            actual_h = end_y - current_y
                            
                            if actual_w > 0 and actual_h > 0:
                                merged_image[current_y:end_y, current_x:end_x] = tile_img[:actual_h, :actual_w]
                                print(f"âœ… íƒ€ì¼ ë°°ì¹˜: ({tx},{ty}) at ({current_x},{current_y}) size={actual_w}x{actual_h}")
                        else:
                            print(f"âŒ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
                    except Exception as e:
                        print(f"âš ï¸ íƒ€ì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {tile_path}: {e}")
                else:
                    print(f"âš ï¸ íƒ€ì¼ ëˆ„ë½: ({tx},{ty}) at ({current_x},{current_y})")
                
                current_x += col_width
            
            current_y += row_height
        
        print("ğŸ¯ íƒ€ì¼ í•©ì¹˜ê¸° ì™„ë£Œ, íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì‹œì‘...")
        
        # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ê°œì„ ëœ ì¢Œí‘œ ê³„ì‚°)
        detection_count = 0
        current_y_offset = 0
        
        for ty in range(min_y, max_y + 1):
            current_x_offset = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                # í•´ë‹¹ íƒ€ì¼ì˜ íƒì§€ ê²°ê³¼ë“¤ ê·¸ë¦¬ê¸°
                if (tx, ty) in tile_positions:
                    for detection in tile_positions[(tx, ty)]:
                        # íƒ€ì¼ ë‚´ ì¢Œí‘œë¥¼ ì „ì²´ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                        global_x = current_x_offset + detection.center_x
                        global_y = current_y_offset + detection.center_y
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                        x1 = int(global_x - detection.width / 2)
                        y1 = int(global_y - detection.height / 2)
                        x2 = int(global_x + detection.width / 2)
                        y2 = int(global_y + detection.height / 2)
                        
                        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
                        x1 = max(0, min(x1, total_width))
                        y1 = max(0, min(y1, total_height))
                        x2 = max(0, min(x2, total_width))
                        y2 = max(0, min(y2, total_height))
                        
                        if x2 > x1 and y2 > y1:  # ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ê·¸ë¦¬ê¸°
                            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘êº¼ìš´ ì´ˆë¡ìƒ‰)
                            cv2.rectangle(merged_image, (x1, y1), (x2, y2), (0, 255, 0), 3)
                            
                            # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì¶”ê°€
                            if detection.confidence:
                                text = f"{detection.confidence:.3f}"
                                # í…ìŠ¤íŠ¸ ë°°ê²½ ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
                                font_scale = 0.6
                                font_thickness = 2
                                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]
                                
                                # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¡°ì • (ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ìª½)
                                text_y = max(y1 - 5, text_size[1] + 5)
                                bg_y1 = text_y - text_size[1] - 5
                                bg_y2 = text_y + 5
                                bg_x1 = x1
                                bg_x2 = min(x1 + text_size[0] + 10, total_width)
                                
                                # ë°°ê²½ ê·¸ë¦¬ê¸°
                                cv2.rectangle(merged_image, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 255, 0), -1)
                                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                                cv2.putText(merged_image, text, (x1 + 5, text_y), 
                                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness)
                            
                            detection_count += 1
                
                current_x_offset += col_width
            
            current_y_offset += row_height
        
        print(f"âœ… íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì™„ë£Œ: {detection_count}ê°œ ë°”ìš´ë”© ë°•ìŠ¤")
        
        # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
        merged_filename = f"merged_detection_{timestamp}.jpg"
        merged_path = os.path.join(output_base, merged_filename)
        
        # í° ì´ë¯¸ì§€ì¸ ê²½ìš° í¬ê¸° ì¡°ì • (ë©”ëª¨ë¦¬ ì ˆì•½ ë° íŒŒì¼ í¬ê¸° ìµœì í™”)
        if total_width > 8192 or total_height > 8192:
            scale = min(8192 / total_width, 8192 / total_height)
            new_width = int(total_width * scale)
            new_height = int(total_height * scale)
            print(f"ğŸ”§ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {total_width}x{total_height} â†’ {new_width}x{new_height}")
            merged_image = cv2.resize(merged_image, (new_width, new_height))
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ì„¤ì •ìœ¼ë¡œ ì €ì¥
        cv2.imwrite(merged_path, merged_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
        
        print(f"âœ… í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {merged_filename}")
        return merged_filename
        
    except Exception as e:
        print(f"âš ï¸ í•©ì³ì§„ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ê¸°ë³¸ ì„¤ì •
DEFAULT_WEIGHTS = str(config.DEFAULT_MODEL_PATH)
DEFAULT_OUTPUT_DIR = str(config.API_RESULTS_DIR)

def pixel_to_tm(px: float, py: float, tfw: List[float]) -> tuple:
    """í”½ì…€ ì¢Œí‘œë¥¼ TM ì¢Œí‘œë¡œ ë³€í™˜
    
    Args:
        px, py: í”½ì…€ ì¢Œí‘œ
        tfw: TFW íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸ [A, D, B, E, C, F]
    
    Returns:
        tuple: (tm_x, tm_y) TM ì¢Œí‘œ
    """
    A, D, B, E, C, F = tfw
    tm_x = A * px + B * py + C
    tm_y = D * px + E * py + F
    return tm_x, tm_y

def get_tfw_from_tiff(image_path: str) -> Optional[List[float]]:
    """TIFF íŒŒì¼ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œí•˜ì—¬ TFW íŒŒë¼ë¯¸í„° ìƒì„±
    
    Args:
        image_path: TIFF ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with rasterio.open(image_path) as src:
            if src.transform:
                # Affine ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ TFW íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                transform = src.transform
                # Affine ë§¤íŠ¸ë¦­ìŠ¤: [a, b, c, d, e, f]
                # TFW í˜•ì‹: [A=a, D=d, B=b, E=e, C=c, F=f]
                tfw_params = [
                    transform.a,  # A: X í”½ì…€ í¬ê¸°
                    transform.d,  # D: Y í”½ì…€ í¬ê¸° (ë³´í†µ ìŒìˆ˜)
                    transform.b,  # B: íšŒì „/ê¸°ìš¸ê¸°
                    transform.e,  # E: íšŒì „/ê¸°ìš¸ê¸°
                    transform.c,  # C: ì¢Œìƒë‹¨ X ì¢Œí‘œ
                    transform.f   # F: ì¢Œìƒë‹¨ Y ì¢Œí‘œ
                ]
                return tfw_params
    except Exception as e:
        print(f"âš ï¸ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

def load_tfw_file(tfw_path: str) -> Optional[List[float]]:
    """TFW íŒŒì¼ì—ì„œ ë³€í™˜ íŒŒë¼ë¯¸í„° ë¡œë“œ
    
    Args:
        tfw_path: TFW íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with open(tfw_path, 'r') as f:
            lines = f.readlines()
            if len(lines) >= 6:
                return [float(line.strip()) for line in lines[:6]]
    except Exception as e:
        print(f"âš ï¸ TFW íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return None

def draw_bounding_boxes_on_image(image, results):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜ - ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™”"""
    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    img_height, img_width = image.shape[:2]
    
    for result in results:
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                # ğŸŒ² ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ìš© ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ìµœì í™”
                # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ 15% ì¶•ì†Œí•˜ì—¬ ë” ì •í™•í•œ ì˜ì—­ë§Œ í‘œì‹œ
                width = x2 - x1
                height = y2 - y1
                center_x = x1 + width / 2
                center_y = y1 + height / 2
                
                # ğŸ¯ ë™ì  ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì¡°ì •
                if config.DYNAMIC_BBOX_SIZING:
                    # ì‹ ë¢°ë„ì™€ í¬ê¸°ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚°
                    confidence_factor = min(1.0, confidence * 2)  # ì‹ ë¢°ë„ê°€ ë†’ì„ìˆ˜ë¡ ë” ì •í™•
                    
                    # ì›ë³¸ í¬ê¸°ì— ë”°ë¥¸ ì¡°ì •
                    box_area = width * height
                    img_area = img_width * img_height
                    area_ratio = box_area / img_area if img_area > 0 else 0
                    
                    if area_ratio > 0.1:  # í° ê°ì²´ (10% ì´ìƒ)
                        scale_factor = 0.75 * confidence_factor  # ë” ì¶•ì†Œ
                    elif area_ratio > 0.01:  # ì¤‘ê°„ ê°ì²´ (1-10%)
                        scale_factor = 0.85 * confidence_factor  # ì ë‹¹íˆ ì¶•ì†Œ  
                    else:  # ì‘ì€ ê°ì²´ (1% ë¯¸ë§Œ)
                        scale_factor = 0.95 * confidence_factor  # ì•½ê°„ë§Œ ì¶•ì†Œ
                        
                    new_width = width * scale_factor
                    new_height = height * scale_factor
                else:
                    # ê¸°ì¡´ ê³ ì • ìŠ¤ì¼€ì¼ íŒ©í„° (85% í¬ê¸°ë¡œ ì¶•ì†Œ)
                    scale_factor = 0.85
                    new_width = width * scale_factor
                    new_height = height * scale_factor
                
                # ìƒˆë¡œìš´ ì¢Œí‘œ ê³„ì‚°
                new_x1 = int(center_x - new_width / 2)
                new_y1 = int(center_y - new_height / 2)
                new_x2 = int(center_x + new_width / 2)
                new_y2 = int(center_y + new_height / 2)
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì • (ë‚®ì€ ì‹ ë¢°ë„ëŠ” ì£¼í™©ìƒ‰ìœ¼ë¡œ)
                if confidence >= 0.7:
                    bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                elif confidence >= 0.4:
                    bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                else:
                    bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                
                # ìµœì í™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë” ì–‡ì€ ì„ )
                cv2.rectangle(image, (new_x1, new_y1), (new_x2, new_y2), 
                            bbox_color, 2)  # ë‘ê»˜ë¥¼ 2ë¡œ ì¤„ì„
                
                # ë” ì‘ì€ í°íŠ¸ë¡œ ë ˆì´ë¸” í‘œì‹œ
                label = f"Pine Damage: {confidence:.2f}"
                font_scale = 0.5  # í°íŠ¸ í¬ê¸° ì¶•ì†Œ
                font_thickness = 1  # í°íŠ¸ ë‘ê»˜ ì¶•ì†Œ
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 
                                           font_scale, font_thickness)[0]
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ë” ì‘ê²Œ)
                cv2.rectangle(image, (new_x1, new_y1 - label_size[1] - 5), 
                            (new_x1 + label_size[0], new_y1), 
                            bbox_color, -1)
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ë” ì‘ê²Œ)
                cv2.putText(image, label, (new_x1, new_y1 - 3), 
                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, 
                          (255, 255, 255), font_thickness)

@router.get("/download/{filename}")
async def download_csv_result(filename: str):
    """
    íƒì§€ ê²°ê³¼ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(DEFAULT_OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )


@router.get("/visualization/{filename}")
async def download_visualization_image(filename: str):
    """
    íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(str(config.API_VISUALIZATION_DIR), filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='image/jpeg'
    )


@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ YOLO ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    models_dir = "models"
    results_dir = "results"
    
    available_models = []
    
    # models ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    if os.path.exists(models_dir):
        for root, dirs, files in os.walk(models_dir):
            for file in files:
                if file.endswith('.pt'):
                    model_path = os.path.join(root, file)
                    available_models.append({
                        "name": file,
                        "path": model_path,
                        "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                    })
    
    # results ë””ë ‰í† ë¦¬ì˜ weights í´ë”ë„ ìŠ¤ìº”
    if os.path.exists(results_dir):
        for root, dirs, files in os.walk(results_dir):
            if "weights" in root:
                for file in files:
                    if file.endswith('.pt'):
                        model_path = os.path.join(root, file)
                        available_models.append({
                            "name": f"{os.path.basename(os.path.dirname(root))}_{file}",
                            "path": model_path,
                            "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                        })
    
    return {
        "available_models": available_models,
        "total_count": len(available_models)
    }


@router.post("/detect", response_model=BatchInferenceResponse)
async def detect_damaged_trees(
    images_zip: UploadFile = File(..., description="ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼"),
    model_path: str = Form(default=DEFAULT_WEIGHTS, description="ì‚¬ìš©í•  YOLO ëª¨ë¸ ê²½ë¡œ"),
    confidence: float = Form(default=config.DEFAULT_CONFIDENCE, description="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.16)"),
    iou_threshold: float = Form(default=config.DEFAULT_IOU_THRESHOLD, description="IoU ì„ê³„ê°’ (ì¤‘ë³µ íƒì§€ ì œê±°ìš©)"),
    save_visualization: bool = Form(default=True, description="íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€"),
    output_tm_coordinates: bool = Form(default=True, description="TM ì¢Œí‘œ ë³€í™˜ ì—¬ë¶€")
):
    """
    ğŸš€ **ì†Œë‚˜ë¬´ì¬ì„ ì¶©ë³‘ í”¼í•´ëª© íƒì§€ API**
    
    ZIP íŒŒì¼ë¡œ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤(ë˜ëŠ” íƒ€ì¼ë“¤)ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ í”¼í•´ëª©ì„ íƒì§€í•©ë‹ˆë‹¤.
    
    **ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:**
    - ğŸ–¼ï¸ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ íƒ€ì¼ ì¼ê´„ ì²˜ë¦¬
    - ğŸ” YOLO ëª¨ë¸ ê¸°ë°˜ í”¼í•´ëª© ìë™ íƒì§€
    - ğŸ—ºï¸ TM ì¢Œí‘œ ë³€í™˜ (ì§€ë¦¬ì°¸ì¡° ì •ë³´ í¬í•¨ ì‹œ)
    - ğŸ“Š CSV ê²°ê³¼ íŒŒì¼ ìƒì„±
    - ğŸ¨ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)
    - ğŸ–¼ï¸ ì „ì²´ ì´ë¯¸ì§€ ë³‘í•© ì‹œê°í™”
    
    **ğŸ“‹ ë§¤ê°œë³€ìˆ˜:**
    - **images_zip**: ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼ (.zip)
    - **model_path**: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ìµœì í™”ëœ ì†Œë‚˜ë¬´ ëª¨ë¸)
    - **confidence**: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0, ê¸°ë³¸ê°’: 0.28)
    - **iou_threshold**: IoU ì„ê³„ê°’ (0.0-1.0, ì¤‘ë³µ íƒì§€ ì œê±°ìš©, ê¸°ë³¸ê°’: 0.6)
    - **save_visualization**: íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    - **output_tm_coordinates**: TM ì¢Œí‘œ ë³€í™˜ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    
    **ğŸ¯ ì¶œë ¥:**
    - ğŸ“Š íƒì§€ í†µê³„ ì •ë³´
    - ğŸ“ ê²°ê³¼ ZIP íŒŒì¼ (CSV + ì‹œê°í™” ì´ë¯¸ì§€ë“¤)
    - ğŸ–¼ï¸ ë³‘í•©ëœ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™”
    - ğŸ—ºï¸ TM ì¢Œí‘œê°€ í¬í•¨ëœ CSV íŒŒì¼
    """
    
    try:
        # íŒŒì¼ëª… ê²€ì¦
        if not images_zip.filename:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì— íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ZIP íŒŒì¼ í™•ì¥ì ê²€ì¦
        if not images_zip.filename.lower().endswith('.zip'):
            raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ëª¨ë¸ ê²½ë¡œ ê²€ì¦
        if not os.path.exists(model_path):
            raise HTTPException(status_code=400, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # YOLO ëª¨ë¸ ë¡œë“œ (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
        print(f"ğŸ¤– ëª¨ë¸ ë¡œë”©: {model_path}")
        model = YOLO(model_path)
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        print(f"  ğŸ“‹ ëª¨ë¸ ì •ë³´:")
        print(f"    - í´ë˜ìŠ¤ ìˆ˜: {len(model.names) if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - í´ë˜ìŠ¤ ëª…: {model.names if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - ëª¨ë¸ í¬ê¸°: {os.path.getsize(model_path) / 1024 / 1024:.1f}MB")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            
            # ZIP íŒŒì¼ ì €ì¥ ë° ì••ì¶• í•´ì œ
            zip_path = os.path.join(temp_dir, images_zip.filename)
            with open(zip_path, "wb") as f:
                shutil.copyfileobj(images_zip.file, f)
            
            # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
            extract_dir = os.path.join(temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
            image_files = []
            for root, dirs, files in os.walk(extract_dir):
                # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
                if '__MACOSX' in root:
                    continue
                for file in files:
                    # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                    if file.startswith('.') or file.startswith('._'):
                        continue
                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                        image_files.append(os.path.join(root, file))
            
            if not image_files:
                raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_base = os.path.join(DEFAULT_OUTPUT_DIR, f"batch_inference_{timestamp}")
            
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            os.makedirs(output_base, exist_ok=True)
            
            viz_dir = None
            if save_visualization:
                viz_dir = os.path.join(output_base, "visualizations")
                os.makedirs(viz_dir, exist_ok=True)
            
            # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
            all_results = []
            processed_images = []
            failed_images = []
            
            print(f"ğŸ“Š ë°°ì¹˜ ì¶”ë¡  ì‹œì‘: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì •")
            
            for idx, image_path in enumerate(image_files, 1):
                try:
                    image_name = os.path.basename(image_path)
                    print(f"ğŸ” ì²˜ë¦¬ ì¤‘ ({idx}/{len(image_files)}): {image_name}")
                    
                    # ğŸ¯ YOLOv11s ë‚´ì¥ FPN ì‚¬ìš©í•œ ë‹¨ì¼ ì¶”ë¡ 
                    print(f"  ï¿½ YOLOv11s FPN ì¶”ë¡ : conf={confidence}, iou={iou_threshold}")
                    results = model(image_path, conf=confidence, iou=iou_threshold)
                    
                    # TFW ì •ë³´ ì¶”ì¶œ (TM ì¢Œí‘œ ë³€í™˜ìš©)
                    tfw_params = None
                    if output_tm_coordinates:
                        tfw_params = get_tfw_from_tiff(image_path)
                        if not tfw_params:
                            # ë™ì¼ ë””ë ‰í† ë¦¬ì—ì„œ TFW íŒŒì¼ ì°¾ê¸°
                            tfw_file_path = image_path.replace('.tif', '.tfw').replace('.tiff', '.tfw')
                            if os.path.exists(tfw_file_path):
                                tfw_params = load_tfw_file(tfw_file_path)
                    
                    # YOLOv11s ë‚´ì¥ NMSë§Œ ì‚¬ìš© (ì¶”ê°€ NMS ë¶ˆí•„ìš”)
                    
                    # ê²°ê³¼ ì²˜ë¦¬ (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
                    image_results = []
                    raw_detections = 0  # ì›ì‹œ íƒì§€ ìˆ˜
                    
                    for result in results:
                        boxes = result.boxes
                        if boxes is not None:
                            raw_detections += len(boxes)
                            print(f"  ğŸ“Š ì›ì‹œ íƒì§€ ìˆ˜: {len(boxes)}ê°œ (conf >= {confidence})")
                            
                            for i, box in enumerate(boxes):
                                conf_value = float(box.conf[0].cpu().numpy())
                                print(f"    íƒì§€ {i+1}: ì‹ ë¢°ë„ {conf_value:.4f}")
                                # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                center_x = (x1 + x2) / 2
                                center_y = (y1 + y2) / 2
                                width = x2 - x1
                                height = y2 - y1
                                conf = float(box.conf[0].cpu().numpy())
                                class_id = int(box.cls[0].cpu().numpy())
                                
                                # TM ì¢Œí‘œ ë³€í™˜
                                tm_x, tm_y = None, None
                                if tfw_params:
                                    tm_x, tm_y = pixel_to_tm(center_x, center_y, tfw_params)
                                
                                detection = DetectionResult(
                                    filename=image_name,
                                    class_id=class_id,
                                    center_x=center_x,
                                    center_y=center_y,
                                    width=width,
                                    height=height,
                                    confidence=conf,
                                    tm_x=tm_x,
                                    tm_y=tm_y
                                )
                                
                                image_results.append(detection)
                                all_results.append(detection)
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                    if save_visualization and viz_dir and image_results:
                        viz_path = os.path.join(viz_dir, f"detected_{image_name}")
                        try:
                            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                            image = cv2.imread(image_path)
                            if image is not None:
                                # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
                                for detection in image_results:
                                    x1 = int(detection.center_x - detection.width / 2)
                                    y1 = int(detection.center_y - detection.height / 2)
                                    x2 = int(detection.center_x + detection.width / 2)
                                    y2 = int(detection.center_y + detection.height / 2)
                                    
                                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                                    
                                    # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì¶”ê°€
                                    if detection.confidence:
                                        text = f"{detection.confidence:.2f}"
                                        cv2.putText(image, text, (x1, y1-10), 
                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                                
                                # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                                cv2.imwrite(viz_path, image)
                                # ë©”ëª¨ë¦¬ í•´ì œ
                                del image
                        except Exception as e:
                            print(f"âš ï¸ ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨ ({image_name}): {e}")
                    
                    # ì¶”ë¡  ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ
                    del results
                    
                    processed_images.append(image_name)
                    print(f"âœ… ì™„ë£Œ: {image_name} (ì›ì‹œ: {raw_detections}ê°œ, ìµœì¢…: {len(image_results)}ê°œ íƒì§€)")
                    
                    # íƒì§€ê°€ ì—†ëŠ” ê²½ìš° ì¶”ê°€ ë””ë²„ê¹…
                    if raw_detections == 0:
                        print(f"  âš ï¸ íƒì§€ ì—†ìŒ: {image_name} - ì‹ ë¢°ë„ {confidence} ê¸°ì¤€")
                        # ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¬ì‹œë„
                        debug_results = model(image_path, conf=0.01, iou=iou_threshold)
                        debug_count = sum(len(r.boxes) if r.boxes is not None else 0 for r in debug_results)
                        print(f"  ğŸ” ë””ë²„ê·¸ (conf=0.01): {debug_count}ê°œ íƒì§€")
                        del debug_results
                    
                except Exception as e:
                    failed_images.append(f"{os.path.basename(image_path)}: {str(e)}")
                    print(f"âŒ ì‹¤íŒ¨: {os.path.basename(image_path)} - {e}")
            
            # CSV íŒŒì¼ ìƒì„±
            csv_file_url = None
            if all_results:
                csv_filename = f"batch_detections_{timestamp}.csv"
                csv_path = os.path.join(output_base, csv_filename)
                
                # íƒì§€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                results_data = []
                for idx, detection in enumerate(all_results, 1):
                    row = {
                        'no': idx,
                        'filename': detection.filename,
                        'class_id': detection.class_id,
                        'center_x': detection.center_x,
                        'center_y': detection.center_y,
                        'width': detection.width,
                        'height': detection.height,
                        'confidence': detection.confidence
                    }
                    
                    # TM ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                    if detection.tm_x is not None and detection.tm_y is not None:
                        row['tm_x'] = detection.tm_x
                        row['tm_y'] = detection.tm_y
                    
                    results_data.append(row)
                
                # CSV ì €ì¥
                df = pd.DataFrame(results_data)
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                csv_file_url = f"/api/v1/inference/download/{csv_filename}"
            
            # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            merged_viz_filename = None
            if save_visualization and all_results:
                merged_viz_filename = create_merged_visualization(
                    all_results, output_base, timestamp, extract_dir, tile_size=config.DEFAULT_TILE_SIZE
                )
            
            # ê²°ê³¼ ZIP íŒŒì¼ ìƒì„±
            results_zip_url = None
            if all_results or (save_visualization and viz_dir and os.path.exists(viz_dir) and os.listdir(viz_dir)):
                zip_filename = f"batch_results_{timestamp}.zip"
                zip_path = os.path.join(DEFAULT_OUTPUT_DIR, zip_filename)
                
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # CSV íŒŒì¼ ì¶”ê°€
                    if all_results:
                        csv_path = os.path.join(output_base, f"batch_detections_{timestamp}.csv")
                        if os.path.exists(csv_path):
                            zipf.write(csv_path, f"batch_detections_{timestamp}.csv")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
                    if save_visualization and viz_dir and os.path.exists(viz_dir):
                        for file in os.listdir(viz_dir):
                            file_path = os.path.join(viz_dir, file)
                            if os.path.isfile(file_path):  # íŒŒì¼ì¸ì§€ í™•ì¸
                                zipf.write(file_path, f"visualizations/{file}")
                    
                    # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì¶”ê°€
                    if merged_viz_filename:
                        merged_path = os.path.join(output_base, merged_viz_filename)
                        if os.path.exists(merged_path):
                            zipf.write(merged_path, merged_viz_filename)
                
                results_zip_url = f"/api/v1/inference/download/{zip_filename}"
            
            return BatchInferenceResponse(
                success=True,
                message=f"ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ: {len(processed_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬, {len(all_results)}ê°œ ê°ì²´ íƒì§€",
                total_images=len(image_files),
                total_detections=len(all_results),
                processed_images=processed_images,
                failed_images=failed_images,
                csv_file_url=csv_file_url,
                results_zip_url=results_zip_url,
                merged_visualization=merged_viz_filename
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
