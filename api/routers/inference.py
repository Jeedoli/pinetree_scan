# ì¶”ë¡ /íƒì§€ API ë¼ìš°í„° - yolo_infer_to_gps.py ê¸°ë°˜
# YOLO ëª¨ë¸ë¡œ í”¼í•´ëª© íƒì§€ + GPS ì¢Œí‘œ ë³€í™˜ + CSV ì €ì¥

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import os
import tempfile
import shutil
import pandas as pd
import cv2
import rasterio
from rasterio.transform import from_bounds
from rasterio import Affine
from ultralytics import YOLO
import datetime
import json
from pathlib import Path
import sys
import numpy as np
import zipfile

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (scripts í´ë” ì ‘ê·¼ìš©)
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from .. import config

router = APIRouter()

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class DetectionResult(BaseModel):
    filename: str
    class_id: int
    center_x: float
    center_y: float
    width: float
    height: float
    confidence: Optional[float] = None
    tm_x: Optional[float] = None  # TM ì¢Œí‘œ X
    tm_y: Optional[float] = None  # TM ì¢Œí‘œ Y

class BatchInferenceResponse(BaseModel):
    success: bool
    message: str
    total_images: int
    total_detections: int
    processed_images: List[str]
    failed_images: List[str]
    csv_file_url: Optional[str] = None
    results_zip_url: Optional[str] = None
    merged_visualization: Optional[str] = None  # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ íŒŒì¼ëª…

def extract_tile_position(filename: str) -> tuple:
    """íƒ€ì¼ íŒŒì¼ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (prefix_tile_x_y.tif -> (x, y))"""
    try:
        # ë‹¤ì–‘í•œ íŒŒì¼ëª… í˜•ì‹ ì§€ì›
        name_without_ext = filename.replace('.tif', '').replace('.tiff', '').replace('.jpg', '').replace('.jpeg', '').replace('.png', '')
        
        # í˜•ì‹ 1: A20250917_tile_2_1 -> ['A20250917', 'tile', '2', '1']
        parts = name_without_ext.split('_')
        
        # tileì´ í¬í•¨ëœ ê²½ìš°
        if 'tile' in parts:
            tile_idx = parts.index('tile')
            if len(parts) > tile_idx + 2:
                x = int(parts[tile_idx + 1])
                y = int(parts[tile_idx + 2])
                return (x, y)
        
        # í˜•ì‹ 2: prefix_x_y (ë§ˆì§€ë§‰ ë‘ ê°œê°€ ìˆ«ìì¸ ê²½ìš°)
        if len(parts) >= 3:
            try:
                x = int(parts[-2])
                y = int(parts[-1])
                return (x, y)
            except ValueError:
                pass
        
        # í˜•ì‹ 3: ì •ê·œì‹ìœ¼ë¡œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
        import re
        pattern = r'(\d+)_(\d+)(?:\.|$)'
        match = re.search(pattern, filename)
        if match:
            x = int(match.group(1))
            y = int(match.group(2))
            return (x, y)
            
    except (ValueError, IndexError, AttributeError):
        pass
    
    # íŒŒì‹± ì‹¤íŒ¨ì‹œ íŒŒì¼ëª…ì— _0_0ì´ ìˆëŠ”ì§€ í™•ì¸
    if '_0_0' in filename:
        return (0, 0)
    
    print(f"âš ï¸ íƒ€ì¼ ìœ„ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
    return (0, 0)  # ê¸°ë³¸ê°’


def create_merged_visualization(all_results: List[DetectionResult], output_base: str, 
                               timestamp: str, extract_dir: str, tile_size: int = config.DEFAULT_TILE_SIZE) -> Optional[str]:
    """íƒ€ì¼ë³„ íƒì§€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™” ìƒì„±"""
    
    if not all_results:
        return None
    
    try:
        print("ğŸ–¼ï¸ í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # ëª¨ë“  íƒ€ì¼ íŒŒì¼ ë¨¼ì € ìˆ˜ì§‘ (íƒì§€ ê²°ê³¼ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´)
        all_tile_files = {}
        tile_positions = {}
        
        # extract_dirì—ì„œ ëª¨ë“  íƒ€ì¼ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
        for root, dirs, files in os.walk(extract_dir):
            # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
            if '__MACOSX' in root:
                continue
            for file in files:
                # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                if file.startswith('.') or file.startswith('._'):
                    continue
                if file.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png')):
                    x, y = extract_tile_position(file)
                    if (x, y) != (0, 0) or '_0_0' in file:  # (0,0)ì€ ì‹¤ì œ ì¢Œí‘œì´ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨
                        tile_path = os.path.join(root, file)
                        all_tile_files[(x, y)] = tile_path
                        
                        # íƒì§€ ê²°ê³¼ê°€ ìˆëŠ” íƒ€ì¼ ì²´í¬
                        if (x, y) not in tile_positions:
                            tile_positions[(x, y)] = []
        
        # íƒì§€ ê²°ê³¼ë¥¼ í•´ë‹¹ íƒ€ì¼ ìœ„ì¹˜ì— í• ë‹¹
        for result in all_results:
            x, y = extract_tile_position(result.filename)
            if (x, y) in tile_positions:
                tile_positions[(x, y)].append(result)
        
        if not all_tile_files:
            print("âš ï¸ íƒ€ì¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì¼ë“¤ë¡œë¶€í„° ê²©ì ë²”ìœ„ ê³„ì‚°
        existing_positions = list(all_tile_files.keys())
        min_x = min(pos[0] for pos in existing_positions)
        max_x = max(pos[0] for pos in existing_positions)
        min_y = min(pos[1] for pos in existing_positions)
        max_y = max(pos[1] for pos in existing_positions)
        
        print(f"ğŸ“Š íƒ€ì¼ ê²©ì ë²”ìœ„: X({min_x}~{max_x}), Y({min_y}~{max_y})")
        print(f"ğŸ“Š ì „ì²´ íƒ€ì¼ ìˆ˜: {len(all_tile_files)}ê°œ")
        
        # ê° í–‰/ì—´ë³„ ì‹¤ì œ í¬ê¸° ê³„ì‚° (ì‹¤ì œ íƒ€ì¼ ì´ë¯¸ì§€ ê¸°ë°˜)
        row_heights = {}  # ty -> height
        col_widths = {}   # tx -> width
        
        # ëª¨ë“  íƒ€ì¼ì˜ í¬ê¸° ë¯¸ë¦¬ ì¸¡ì •
        print("ğŸ“ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì¤‘...")
        for (tx, ty), tile_path in all_tile_files.items():
            try:
                tile_img = cv2.imread(tile_path)
                if tile_img is not None:
                    h, w = tile_img.shape[:2]
                    
                    # í•´ë‹¹ í–‰/ì—´ì˜ ìµœëŒ€ í¬ê¸° ì €ì¥
                    if ty not in row_heights:
                        row_heights[ty] = h
                    else:
                        row_heights[ty] = max(row_heights[ty], h)
                    
                    if tx not in col_widths:
                        col_widths[tx] = w
                    else:
                        col_widths[tx] = max(col_widths[tx], w)
                else:
                    print(f"âš ï¸ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
            except Exception as e:
                print(f"âš ï¸ íƒ€ì¼ í¬ê¸° ì¸¡ì • ì‹¤íŒ¨ {tile_path}: {e}")
        
        # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
        total_width = sum(col_widths.get(tx, tile_size) for tx in range(min_x, max_x + 1))
        total_height = sum(row_heights.get(ty, tile_size) for ty in range(min_y, max_y + 1))
        
        print(f"ğŸ“ ê³„ì‚°ëœ ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°: {total_width}x{total_height}")
        print(f"ğŸ“ í–‰ë³„ ë†’ì´: {row_heights}")
        print(f"ğŸ“ ì—´ë³„ ë„ˆë¹„: {col_widths}")
        
        # ì „ì²´ ì´ë¯¸ì§€ ìƒì„± (íšŒìƒ‰ ë°°ê²½ìœ¼ë¡œ ì‹œì‘ - ëˆ„ë½ ì˜ì—­ ì‹ë³„ìš©)
        merged_image = np.full((total_height, total_width, 3), (128, 128, 128), dtype=np.uint8)
        
        # íƒ€ì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ í•©ì¹˜ê¸°
        current_y = 0
        for ty in range(min_y, max_y + 1):
            current_x = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                if (tx, ty) in all_tile_files:
                    tile_path = all_tile_files[(tx, ty)]
                    try:
                        # íƒ€ì¼ ì´ë¯¸ì§€ ë¡œë“œ
                        tile_img = cv2.imread(tile_path)
                        if tile_img is not None:
                            h, w = tile_img.shape[:2]
                            
                            # ë°°ì¹˜ ì˜ì—­ ê³„ì‚°
                            end_x = min(current_x + w, total_width)
                            end_y = min(current_y + h, total_height)
                            
                            actual_w = end_x - current_x
                            actual_h = end_y - current_y
                            
                            if actual_w > 0 and actual_h > 0:
                                merged_image[current_y:end_y, current_x:end_x] = tile_img[:actual_h, :actual_w]
                                print(f"âœ… íƒ€ì¼ ë°°ì¹˜: ({tx},{ty}) at ({current_x},{current_y}) size={actual_w}x{actual_h}")
                        else:
                            print(f"âŒ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨: {tile_path}")
                    except Exception as e:
                        print(f"âš ï¸ íƒ€ì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {tile_path}: {e}")
                else:
                    print(f"âš ï¸ íƒ€ì¼ ëˆ„ë½: ({tx},{ty}) at ({current_x},{current_y})")
                
                current_x += col_width
            
            current_y += row_height
        
        print("ğŸ¯ íƒ€ì¼ í•©ì¹˜ê¸° ì™„ë£Œ, íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì‹œì‘...")
        
        # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ê°œì„ ëœ ì¢Œí‘œ ê³„ì‚°)
        detection_count = 0
        current_y_offset = 0
        
        for ty in range(min_y, max_y + 1):
            current_x_offset = 0
            row_height = row_heights.get(ty, tile_size)
            
            for tx in range(min_x, max_x + 1):
                col_width = col_widths.get(tx, tile_size)
                
                # í•´ë‹¹ íƒ€ì¼ì˜ íƒì§€ ê²°ê³¼ë“¤ ê·¸ë¦¬ê¸°
                if (tx, ty) in tile_positions:
                    for detection in tile_positions[(tx, ty)]:
                        # íƒ€ì¼ ë‚´ ì¢Œí‘œë¥¼ ì „ì²´ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                        global_x = current_x_offset + detection.center_x
                        global_y = current_y_offset + detection.center_y
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                        x1 = int(global_x - detection.width / 2)
                        y1 = int(global_y - detection.height / 2)
                        x2 = int(global_x + detection.width / 2)
                        y2 = int(global_y + detection.height / 2)
                        
                        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
                        x1 = max(0, min(x1, total_width))
                        y1 = max(0, min(y1, total_height))
                        x2 = max(0, min(x2, total_width))
                        y2 = max(0, min(y2, total_height))
                        
                        if x2 > x1 and y2 > y1:  # ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ê·¸ë¦¬ê¸°
                            # ğŸ¨ ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì½”ë”© (ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±°)
                            confidence = detection.confidence if detection.confidence else 0.5
                            if confidence >= 0.7:
                                color = (0, 255, 0)      # ì´ˆë¡ìƒ‰: ë†’ì€ ì‹ ë¢°ë„ (70%+)
                            elif confidence >= 0.4:
                                color = (0, 165, 255)    # ì£¼í™©ìƒ‰: ì¤‘ê°„ ì‹ ë¢°ë„ (40-70%)
                            else:
                                color = (0, 0, 255)      # ë¹¨ê°„ìƒ‰: ë‚®ì€ ì‹ ë¢°ë„ (40% ë¯¸ë§Œ)
                            
                            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì‹ ë¢°ë„ë³„ ìƒ‰ìƒ)
                            cv2.rectangle(merged_image, (x1, y1), (x2, y2), color, 3)
                            
                            detection_count += 1
                
                current_x_offset += col_width
            
            current_y_offset += row_height
        
        print(f"âœ… íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì™„ë£Œ: {detection_count}ê°œ ë°”ìš´ë”© ë°•ìŠ¤")
        
        # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ (ëª©í‘œ: ì•½ 100MB JPG)
        merged_filename = f"merged_detection_{timestamp}.jpg"
        merged_path = os.path.join(output_base, merged_filename)
        
        # ğŸ¯ ì ì ˆí•œ í•´ìƒë„ë¡œ ì¡°ì • (ëª©í‘œ íŒŒì¼ í¬ê¸°: ~100MB)
        MAX_DIMENSION = 16384  # ìµœëŒ€ 16384px (ì•½ 100MB JPG í¬ê¸°)
        
        if total_width > MAX_DIMENSION or total_height > MAX_DIMENSION:
            scale = min(MAX_DIMENSION / total_width, MAX_DIMENSION / total_height)
            new_width = int(total_width * scale)
            new_height = int(total_height * scale)
            print(f"ğŸ”§ íŒŒì¼ í¬ê¸° ìµœì í™”: {total_width}x{total_height} â†’ {new_width}x{new_height} (ëª©í‘œ: ~100MB)")
            merged_image = cv2.resize(merged_image, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
        else:
            print(f"ğŸ’¾ ì›ë³¸ í¬ê¸°ë¡œ ì €ì¥: {total_width}x{total_height}px")
        
        # JPG ê³ í’ˆì§ˆ ì••ì¶•ìœ¼ë¡œ ì €ì¥ (í’ˆì§ˆ 90: ì„ ëª…ë„ ìœ ì§€ + íŒŒì¼ í¬ê¸° ìµœì í™”)
        cv2.imwrite(merged_path, merged_image, [cv2.IMWRITE_JPEG_QUALITY, 90])
        
        print(f"âœ… í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {merged_filename}")
        return merged_filename
        
    except Exception as e:
        print(f"âš ï¸ í•©ì³ì§„ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ê¸°ë³¸ ì„¤ì •
DEFAULT_WEIGHTS = str(config.DEFAULT_MODEL_PATH)
DEFAULT_OUTPUT_DIR = str(config.API_RESULTS_DIR)

def pixel_to_tm(px: float, py: float, tfw: List[float]) -> tuple:
    """í”½ì…€ ì¢Œí‘œë¥¼ TM ì¢Œí‘œë¡œ ë³€í™˜
    
    Args:
        px, py: í”½ì…€ ì¢Œí‘œ
        tfw: TFW íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸ [A, D, B, E, C, F]
    
    Returns:
        tuple: (tm_x, tm_y) TM ì¢Œí‘œ
    """
    A, D, B, E, C, F = tfw
    tm_x = A * px + B * py + C
    tm_y = D * px + E * py + F
    return tm_x, tm_y

def get_georeference_info(image_path: str) -> Optional[List[float]]:
    """ğŸ—ºï¸ ì´ë¯¸ì§€ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ (TIFF ë©”íƒ€ë°ì´í„° ë˜ëŠ” World File)
    
    ì§€ì› í˜•ì‹:
    - TIFF: ë‚´ì¥ ë©”íƒ€ë°ì´í„° ìš°ì„ 
    - JPG/PNG/ê¸°íƒ€: World File (.jgw, .pgw, .wld, .tfw)
    
    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        # 1ï¸âƒ£ TIFF íŒŒì¼ì˜ ë‚´ì¥ ë©”íƒ€ë°ì´í„° ìš°ì„  ì‹œë„
        if image_path.lower().endswith(('.tif', '.tiff')):
            try:
                with rasterio.open(image_path) as src:
                    if src.transform is not None:
                        transform = src.transform
                        tfw_params = [
                            transform.a,  # A: X í”½ì…€ í¬ê¸°
                            transform.d,  # D: Y í”½ì…€ í¬ê¸° (ë³´í†µ ìŒìˆ˜)
                            transform.b,  # B: íšŒì „/ê¸°ìš¸ê¸°
                            transform.e,  # E: íšŒì „/ê¸°ìš¸ê¸°
                            transform.c,  # C: ì¢Œìƒë‹¨ X ì¢Œí‘œ
                            transform.f   # F: ì¢Œìƒë‹¨ Y ì¢Œí‘œ
                        ]
                        print(f"âœ… TIFF ë©”íƒ€ë°ì´í„°ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì„±ê³µ")
                        return tfw_params
            except Exception as e:
                print(f"âš ï¸ TIFF ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨, World File ê²€ìƒ‰ ì‹œë„: {e}")
        
        # 2ï¸âƒ£ ì´ë¯¸ì§€ë³„ World File í™•ì¥ì ê²€ìƒ‰
        world_file_extensions = {
            '.tif': ['.tfw'],
            '.tiff': ['.tfw'],
            '.jpg': ['.jgw', '.jpgw'],
            '.jpeg': ['.jgw', '.jpgw'],
            '.png': ['.pgw', '.pngw'],
            '.gif': ['.gfw'],
            '.bmp': ['.bpw']
        }
        
        base_path = os.path.splitext(image_path)[0]
        img_ext = os.path.splitext(image_path)[1].lower()
        
        # ì´ë¯¸ì§€ë³„ World File ìš°ì„  ê²€ìƒ‰
        world_exts = world_file_extensions.get(img_ext, [])
        for world_ext in world_exts:
            world_path = base_path + world_ext
            if os.path.exists(world_path):
                params = load_world_file(world_path)
                if params:
                    print(f"âœ… World File ({world_ext}) ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì„±ê³µ")
                    return params
        
        # 3ï¸âƒ£ ë²”ìš© .wld íŒŒì¼ ê²€ìƒ‰ (ëª¨ë“  ì´ë¯¸ì§€ì— ì‚¬ìš© ê°€ëŠ¥)
        wld_path = base_path + '.wld'
        if os.path.exists(wld_path):
            params = load_world_file(wld_path)
            if params:
                print(f"âœ… ë²”ìš© World File (.wld) ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì„±ê³µ")
                return params
        
        # 4ï¸âƒ£ ë³„ë„ .tfw íŒŒì¼ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„±)
        if img_ext not in ['.tif', '.tiff']:
            tfw_path = base_path + '.tfw'
            if os.path.exists(tfw_path):
                params = load_world_file(tfw_path)
                if params:
                    print(f"âœ… TFW íŒŒì¼ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì„±ê³µ")
                    return params
        
        # ì§€ë¦¬ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•¨
        print(f"âš ï¸ ì§€ë¦¬ì°¸ì¡° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(image_path)}")
        print(f"   ğŸ’¡ GPS ì¢Œí‘œ ë³€í™˜ì„ ìœ„í•´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
        print(f"      - TIFF íŒŒì¼ (ì§€ë¦¬ì°¸ì¡° ë©”íƒ€ë°ì´í„° í¬í•¨)")
        print(f"      - ì´ë¯¸ì§€ + World File (.jgw, .pgw, .wld ë“±)")
        
    except Exception as e:
        print(f"âŒ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return None


def get_tfw_from_tiff(image_path: str) -> Optional[List[float]]:
    """[DEPRECATED] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€. get_georeference_info() ì‚¬ìš© ê¶Œì¥
    
    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    return get_georeference_info(image_path)

def load_world_file(world_path: str) -> Optional[List[float]]:
    """World Fileì—ì„œ ì§€ë¦¬ì°¸ì¡° íŒŒë¼ë¯¸í„° ë¡œë“œ (.tfw, .jgw, .pgw, .wld ë“±)
    
    World File í˜•ì‹ (6ì¤„):
    1. X ë°©í–¥ í”½ì…€ í¬ê¸°
    2. Y ë°©í–¥ íšŒì „
    3. X ë°©í–¥ íšŒì „
    4. Y ë°©í–¥ í”½ì…€ í¬ê¸° (ìŒìˆ˜)
    5. ì¢Œìƒë‹¨ X ì¢Œí‘œ
    6. ì¢Œìƒë‹¨ Y ì¢Œí‘œ
    
    Args:
        world_path: World File ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with open(world_path, 'r') as f:
            lines = f.readlines()
            if len(lines) >= 6:
                params = [float(line.strip()) for line in lines[:6]]
                return params
    except Exception as e:
        print(f"âš ï¸ World File ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(world_path)}): {e}")
    return None


def load_tfw_file(tfw_path: str) -> Optional[List[float]]:
    """[DEPRECATED] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€. load_world_file() ì‚¬ìš© ê¶Œì¥
    
    Args:
        tfw_path: TFW íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    return load_world_file(tfw_path)

def draw_bounding_boxes_on_image(image, results):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜ - ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™”"""
    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    img_height, img_width = image.shape[:2]
    
    for result in results:
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                # ï¿½ YOLO ì›ë³¸ ì˜ˆì¸¡ ì¢Œí‘œ ì‚¬ìš© (ì •í™•í•œ ìœ„ì¹˜ í‘œì‹œ)
                # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì¡°ì • ì—†ì´ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì •í™•í•œ ìœ„ì¹˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                new_x1 = int(x1)
                new_y1 = int(y1)
                new_x2 = int(x2)
                new_y2 = int(y2)
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì • (ë‚®ì€ ì‹ ë¢°ë„ëŠ” ì£¼í™©ìƒ‰ìœ¼ë¡œ)
                if confidence >= 0.7:
                    bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                elif confidence >= 0.4:
                    bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                else:
                    bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                
                # ìµœì í™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë” ì–‡ì€ ì„ )
                cv2.rectangle(image, (new_x1, new_y1), (new_x2, new_y2), 
                            bbox_color, 2)  # ë‘ê»˜ë¥¼ 2ë¡œ ì¤„ì„
                
                # ğŸ¨ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±° (ê¹”ë”í•œ ì‹œê°í™”ë¥¼ ìœ„í•´)
                # ìƒ‰ìƒë§Œìœ¼ë¡œ ì‹ ë¢°ë„ë¥¼ í‘œí˜„: ì´ˆë¡(ë†’ìŒ) â†’ ì£¼í™©(ì¤‘ê°„) â†’ ë¹¨ê°•(ë‚®ìŒ)

@router.get("/download/{filename}")
async def download_csv_result(filename: str):
    """
    íƒì§€ ê²°ê³¼ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(DEFAULT_OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )


@router.get("/visualization/{filename}")
async def download_visualization_image(filename: str):
    """
    íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(str(config.API_VISUALIZATION_DIR), filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='image/jpeg'
    )


@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ YOLO ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    models_dir = "models"
    results_dir = "results"
    
    available_models = []
    
    # models ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    if os.path.exists(models_dir):
        for root, dirs, files in os.walk(models_dir):
            for file in files:
                if file.endswith('.pt'):
                    model_path = os.path.join(root, file)
                    available_models.append({
                        "name": file,
                        "path": model_path,
                        "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                    })
    
    # results ë””ë ‰í† ë¦¬ì˜ weights í´ë”ë„ ìŠ¤ìº”
    if os.path.exists(results_dir):
        for root, dirs, files in os.walk(results_dir):
            if "weights" in root:
                for file in files:
                    if file.endswith('.pt'):
                        model_path = os.path.join(root, file)
                        available_models.append({
                            "name": f"{os.path.basename(os.path.dirname(root))}_{file}",
                            "path": model_path,
                            "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                        })
    
    return {
        "available_models": available_models,
        "total_count": len(available_models)
    }


@router.post("/detect", response_model=BatchInferenceResponse)
async def detect_damaged_trees(
    images_zip: UploadFile = File(..., description="ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼"),
    model_path: str = Form(default=DEFAULT_WEIGHTS, description="ì‚¬ìš©í•  YOLO ëª¨ë¸ ê²½ë¡œ"),
    confidence: float = Form(default=config.DEFAULT_CONFIDENCE, description="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.1)"),
    iou_threshold: float = Form(default=config.DEFAULT_IOU_THRESHOLD, description="IoU ì„ê³„ê°’ (ì¤‘ë³µ íƒì§€ ì œê±°ìš©)"),
    save_visualization: bool = Form(default=True, description="íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€"),
    output_tm_coordinates: bool = Form(default=True, description="TM ì¢Œí‘œ ë³€í™˜ ì—¬ë¶€"),
    enable_dense_detection: bool = Form(default=False, description="ì´˜ì´˜í•œ í”¼í•´ëª© íŠ¹í™” ì¶”ë¡  í™œì„±í™” (ë©€í‹°ìŠ¤ì¼€ì¼ 3ë‹¨ê³„)"),
    output_filename: str = Form(default="", description="ì‚¬ìš©ì ì§€ì • ZIP íŒŒì¼ëª… (ì„ íƒì , ê³µë°±ì´ë©´ ìë™ ìƒì„±)")
):
    """
    ğŸš€ **ì†Œë‚˜ë¬´ì¬ì„ ì¶©ë³‘ í”¼í•´ëª© íƒì§€ API**
    
    ZIP íŒŒì¼ë¡œ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤(ë˜ëŠ” íƒ€ì¼ë“¤)ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ í”¼í•´ëª©ì„ íƒì§€í•©ë‹ˆë‹¤.
    
    **ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:**
    - ğŸ–¼ï¸ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ íƒ€ì¼ ì¼ê´„ ì²˜ë¦¬
    - ğŸ” YOLO ëª¨ë¸ ê¸°ë°˜ í”¼í•´ëª© ìë™ íƒì§€
    - ğŸ—ºï¸ TM ì¢Œí‘œ ë³€í™˜ (ì§€ë¦¬ì°¸ì¡° ì •ë³´ í¬í•¨ ì‹œ)
    - ğŸ“Š CSV ê²°ê³¼ íŒŒì¼ ìƒì„±
    - ğŸ¨ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)
    - ğŸ–¼ï¸ ì „ì²´ ì´ë¯¸ì§€ ë³‘í•© ì‹œê°í™”
    
    **ğŸ“‹ ë§¤ê°œë³€ìˆ˜:**
    - **images_zip**: ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼ (.zip)
    - **model_path**: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ìµœì í™”ëœ ì†Œë‚˜ë¬´ ëª¨ë¸)
    - **confidence**: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0, ê¸°ë³¸ê°’: 0.1)
    - **iou_threshold**: IoU ì„ê³„ê°’ (0.0-1.0, ì¤‘ë³µ íƒì§€ ì œê±°ìš©, ê¸°ë³¸ê°’: 0.40)
    - **save_visualization**: íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    - **output_tm_coordinates**: TM ì¢Œí‘œ ë³€í™˜ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    - **enable_dense_detection**: ì´˜ì´˜í•œ í”¼í•´ëª© íŠ¹í™” ì¶”ë¡  í™œì„±í™” (False=ë‹¨ì¼ ìŠ¤ì¼€ì¼, True=3ë‹¨ê³„ ë©€í‹°ìŠ¤ì¼€ì¼)
    
    **ğŸ¯ ì¶œë ¥:**
    - ğŸ“Š íƒì§€ í†µê³„ ì •ë³´
    - ğŸ“ ê²°ê³¼ ZIP íŒŒì¼ (CSV + ì‹œê°í™” ì´ë¯¸ì§€ë“¤)
    - ğŸ–¼ï¸ ë³‘í•©ëœ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™”
    - ğŸ—ºï¸ TM ì¢Œí‘œê°€ í¬í•¨ëœ CSV íŒŒì¼
    """
    
    try:
        # íŒŒì¼ëª… ê²€ì¦
        if not images_zip.filename:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì— íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ZIP íŒŒì¼ í™•ì¥ì ê²€ì¦
        if not images_zip.filename.lower().endswith('.zip'):
            raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ëª¨ë¸ ê²½ë¡œ ê²€ì¦
        if not os.path.exists(model_path):
            raise HTTPException(status_code=400, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # YOLO ëª¨ë¸ ë¡œë“œ (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
        print(f"ğŸ¤– ëª¨ë¸ ë¡œë”©: {model_path}")
        model = YOLO(model_path)
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        print(f"  ğŸ“‹ ëª¨ë¸ ì •ë³´:")
        print(f"    - í´ë˜ìŠ¤ ìˆ˜: {len(model.names) if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - í´ë˜ìŠ¤ ëª…: {model.names if hasattr(model, 'names') else 'Unknown'}")
        print(f"    - ëª¨ë¸ í¬ê¸°: {os.path.getsize(model_path) / 1024 / 1024:.1f}MB")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            
            # ZIP íŒŒì¼ ì €ì¥ ë° ì••ì¶• í•´ì œ
            zip_path = os.path.join(temp_dir, images_zip.filename)
            with open(zip_path, "wb") as f:
                shutil.copyfileobj(images_zip.file, f)
            
            # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
            extract_dir = os.path.join(temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (macOS ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
            image_files = []
            for root, dirs, files in os.walk(extract_dir):
                # macOS ì‹œìŠ¤í…œ í´ë” ì œì™¸
                if '__MACOSX' in root:
                    continue
                for file in files:
                    # macOS ìˆ¨ê¹€ íŒŒì¼ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                    if file.startswith('.') or file.startswith('._'):
                        continue
                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                        image_files.append(os.path.join(root, file))
            
            if not image_files:
                raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
            output_base = os.path.join(DEFAULT_OUTPUT_DIR, f"batch_inference_{timestamp}")
            
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            os.makedirs(output_base, exist_ok=True)
            
            viz_dir = None
            if save_visualization:
                viz_dir = os.path.join(output_base, "visualizations")
                os.makedirs(viz_dir, exist_ok=True)
            
            # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
            all_results = []
            processed_images = []
            failed_images = []
            
            print(f"ğŸ“Š ë°°ì¹˜ ì¶”ë¡  ì‹œì‘: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì •")
            
            for idx, image_path in enumerate(image_files, 1):
                try:
                    image_name = os.path.basename(image_path)
                    print(f"ğŸ” ì²˜ë¦¬ ì¤‘ ({idx}/{len(image_files)}): {image_name}")
                    
                    # ì¶”ë¡  ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
                    if enable_dense_detection:
                        # ğŸ¯ ë©€í‹°ìŠ¤ì¼€ì¼ ì¶”ë¡  (í•´ìƒë„ë§Œ ë‹¤ë¥´ê²Œ, ì‚¬ìš©ì ì§€ì • confidence/iou ì‚¬ìš©)
                        print(f"  ğŸ” ë©€í‹°ìŠ¤ì¼€ì¼ ì¶”ë¡  ì‹œì‘ (ì‚¬ìš©ì ì§€ì •ê°’: conf={confidence}, iou={iou_threshold})...")
                        
                        # 1ë‹¨ê³„: í‘œì¤€ í•´ìƒë„
                        print(f"    ğŸ“Š 640px: conf={confidence}, iou={iou_threshold}")
                        results_640 = model(image_path, imgsz=640, conf=confidence, iou=iou_threshold)
                        
                        # 2ë‹¨ê³„: ê³ í•´ìƒë„
                        print(f"    ğŸ“Š 832px: conf={confidence}, iou={iou_threshold}")  
                        results_832 = model(image_path, imgsz=832, conf=confidence, iou=iou_threshold)
                        
                        # 3ë‹¨ê³„: ì´ˆê³ í•´ìƒë„
                        print(f"    ğŸ“Š 1024px: conf={confidence}, iou={iou_threshold}")
                        results_1024 = model(image_path, imgsz=1024, conf=confidence, iou=iou_threshold)
                        
                        # ê¸°ì¡´ ë³€ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€ (ê²°ê³¼ í†µí•©)
                        primary_results = results_640
                        dense_results = results_832  
                        fine_results = results_1024
                    else:
                        # ğŸ¯ ë‹¨ì¼ ìŠ¤ì¼€ì¼ ì¶”ë¡  (ì‚¬ìš©ì ì§€ì • confidence/iou ì‚¬ìš©)
                        print(f"  ğŸ” ë‹¨ì¼ ìŠ¤ì¼€ì¼ ì¶”ë¡ : conf={confidence}, iou={iou_threshold}")
                        primary_results = model(image_path, conf=confidence, iou=iou_threshold)
                        dense_results = None
                        fine_results = None
                    
                    # ğŸ—ºï¸ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ (TM ì¢Œí‘œ ë³€í™˜ìš©) - TIFF/JPG/PNG + World File ì§€ì›
                    tfw_params = None
                    if output_tm_coordinates:
                        tfw_params = get_georeference_info(image_path)
                        if tfw_params is None:
                            print(f"  âš ï¸ TM ì¢Œí‘œ ë³€í™˜ ë¶ˆê°€: ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì—†ìŒ ({image_name})")
                        else:
                            print(f"  âœ… ì§€ë¦¬ì°¸ì¡° ì •ë³´ í™•ì¸: TM ì¢Œí‘œ ë³€í™˜ ê°€ëŠ¥")
                    
                    # YOLOv11s ë‚´ì¥ NMSë§Œ ì‚¬ìš© (ì¶”ê°€ NMS ë¶ˆí•„ìš”)
                    
                    # ğŸ§© ê²°ê³¼ í†µí•© ë° ì§€ëŠ¥í˜• ì¤‘ë³µ ì œê±°
                    all_detections_raw = []
                    
                    if enable_dense_detection:
                        # ë©€í‹°ìŠ¤ì¼€ì¼: 3ë‹¨ê³„ ê²°ê³¼ í†µí•©
                        # 1ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ë†’ì€ ìš°ì„ ìˆœìœ„)
                        stage1_count = 0
                        for result in primary_results:
                            if result.boxes is not None:
                                for box in result.boxes:
                                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                    conf = float(box.conf[0].cpu().numpy())
                                    all_detections_raw.append({
                                        'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                        'box': box, 'stage': 1, 'priority': 3
                                    })
                                    stage1_count += 1
                        
                        # 2ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ì¤‘ê°„ ìš°ì„ ìˆœìœ„)
                        stage2_count = 0
                        for result in dense_results:
                            if result.boxes is not None:
                                for box in result.boxes:
                                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                    conf = float(box.conf[0].cpu().numpy())
                                    all_detections_raw.append({
                                        'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                        'box': box, 'stage': 2, 'priority': 2
                                    })
                                    stage2_count += 1
                        
                        # 3ë‹¨ê³„ ê²°ê³¼ ìˆ˜ì§‘ (ë‚®ì€ ìš°ì„ ìˆœìœ„)
                        stage3_count = 0
                        for result in fine_results:
                            if result.boxes is not None:
                                for box in result.boxes:
                                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                    conf = float(box.conf[0].cpu().numpy())
                                    all_detections_raw.append({
                                        'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                        'box': box, 'stage': 3, 'priority': 1
                                    })
                                    stage3_count += 1
                        
                        print(f"  ğŸ“Š ë‹¨ê³„ë³„ ì›ì‹œ íƒì§€: 1ë‹¨ê³„={stage1_count}ê°œ, 2ë‹¨ê³„={stage2_count}ê°œ, 3ë‹¨ê³„={stage3_count}ê°œ")
                    else:
                        # ë‹¨ì¼ ìŠ¤ì¼€ì¼: primary_resultsë§Œ ì‚¬ìš©
                        stage1_count = 0
                        stage2_count = 0
                        stage3_count = 0
                        for result in primary_results:
                            if result.boxes is not None:
                                for box in result.boxes:
                                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                                    conf = float(box.conf[0].cpu().numpy())
                                    all_detections_raw.append({
                                        'center_x': center_x, 'center_y': center_y, 'conf': conf,
                                        'box': box, 'stage': 1, 'priority': 1
                                    })
                                    stage1_count += 1
                        
                        print(f"  ğŸ“Š ë‹¨ì¼ ìŠ¤ì¼€ì¼ íƒì§€: {stage1_count}ê°œ")
                    
                    # ğŸ¯ ì§€ëŠ¥í˜• ì¤‘ë³µ ì œê±° (ë©€í‹°ìŠ¤ì¼€ì¼ ëª¨ë“œì¼ ë•Œë§Œ í•„ìš”)
                    if enable_dense_detection:
                        # ë†’ì€ ìš°ì„ ìˆœìœ„(stage1) > ë†’ì€ ì‹ ë¢°ë„ > ë‚®ì€ stage ìˆœìœ¼ë¡œ ì •ë ¬
                        all_detections_raw.sort(key=lambda x: (x['priority'], x['conf']), reverse=True)
                        
                        filtered_detections = []
                        MIN_DISTANCE = 15  # 15í”½ì…€ ì´ë‚´ëŠ” ì¤‘ë³µ (ê¸°ì¡´ 25ì—ì„œ ì¤„ì„)
                        
                        for detection in all_detections_raw:
                            is_duplicate = False
                            for existing in filtered_detections:
                                dist = ((detection['center_x'] - existing['center_x']) ** 2 + 
                                       (detection['center_y'] - existing['center_y']) ** 2) ** 0.5
                                if dist < MIN_DISTANCE:
                                    is_duplicate = True
                                    break
                            
                            if not is_duplicate:
                                filtered_detections.append(detection)
                        
                        print(f"  ğŸ§¹ ì¤‘ë³µ ì œê±° í›„: {len(filtered_detections)}ê°œ (ê±°ë¦¬ {MIN_DISTANCE}px ê¸°ì¤€)")
                    else:
                        # ë‹¨ì¼ ìŠ¤ì¼€ì¼ì€ ì¤‘ë³µ ì œê±° ë¶ˆí•„ìš” (YOLO ë‚´ì¥ NMS ì‚¬ìš©)
                        filtered_detections = all_detections_raw
                        print(f"  âœ… YOLO ë‚´ì¥ NMS ì‚¬ìš©: {len(filtered_detections)}ê°œ")
                    
                    # ê²°ê³¼ ì²˜ë¦¬ ë° ë°€ë„ ê¸°ë°˜ ë™ì  ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ìµœì í™”
                    image_results = []
                    all_boxes = [(det['center_x'], det['center_y'], det['conf']) for det in filtered_detections]
                        # ê° íƒì§€ì— ëŒ€í•´ ë°€ë„ ê¸°ë°˜ í¬ê¸° ì¡°ì •
                    for i, detection_info in enumerate(filtered_detections):
                        center_x = detection_info['center_x']
                        center_y = detection_info['center_y']
                        box = detection_info['box']
                        stage = detection_info['stage']
                        
                        conf_value = detection_info['conf']
                        print(f"    íƒì§€ {i+1}: ì‹ ë¢°ë„ {conf_value:.4f} (ë‹¨ê³„{stage})")
                        
                        # ì›ë³¸ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        orig_width = x2 - x1
                        orig_height = y2 - y1
                        
                        # ğŸŒ² ì£¼ë³€ ë°€ë„ ê¸°ë°˜ ë™ì  í¬ê¸° ì¡°ì •
                        SEARCH_RADIUS = 80  # 80í”½ì…€ ë°˜ê²½ ë‚´ ë°€ë„ í™•ì¸
                        nearby_count = 0
                        
                        # í˜„ì¬ íƒì§€ ì£¼ë³€ì˜ ë‹¤ë¥¸ íƒì§€ë“¤ ê°œìˆ˜ ì„¸ê¸°
                        for other_x, other_y, _ in all_boxes:
                            if other_x != center_x or other_y != center_y:  # ìê¸° ìì‹  ì œì™¸
                                distance = ((center_x - other_x) ** 2 + (center_y - other_y) ** 2) ** 0.5
                                if distance <= SEARCH_RADIUS:
                                    nearby_count += 1
                        
                        # ğŸ¯ YOLO ì›ë³¸ ì˜ˆì¸¡ í¬ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš© (í¬ê¸° ì œí•œ ì—†ìŒ)
                        # ë°€ë„ ë ˆë²¨ ê³„ì‚° (ë¡œê¹…ìš©)
                        if nearby_count >= 5:
                            density_level = "ë§¤ìš°ì´˜ì´˜"
                        elif nearby_count >= 3:
                            density_level = "ì´˜ì´˜"
                        elif nearby_count >= 1:
                            density_level = "ë³´í†µ"
                        else:
                            density_level = "ì™¸ë”´"
                        
                        print(f"      ğŸ¯ ì£¼ë³€ ë°€ë„: {nearby_count}ê°œ â†’ ë°€ë„ ë ˆë²¨: {density_level}")
                        print(f"      ğŸ“ YOLO ì›ë³¸ ì˜ˆì¸¡ í¬ê¸°: {orig_width:.1f}x{orig_height:.1f}px")
                        
                        # âœ… ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì œí•œ ì œê±°: YOLO ì˜ˆì¸¡ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        new_width = orig_width
                        new_height = orig_height
                        print(f"      âœ… ìµœì¢… í¬ê¸°: {new_width:.1f}x{new_height:.1f}px (í¬ê¸° ì œí•œ ì—†ìŒ)")
                        
                        conf = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # TM ì¢Œí‘œ ë³€í™˜
                        tm_x, tm_y = None, None
                        if tfw_params:
                            tm_x, tm_y = pixel_to_tm(center_x, center_y, tfw_params)
                        
                        detection = DetectionResult(
                            filename=image_name,
                            class_id=class_id,
                            center_x=center_x,
                            center_y=center_y,
                            width=new_width,  # ë°€ë„ ê¸°ë°˜ ì¡°ì •ëœ í¬ê¸°
                            height=new_height,  # ë°€ë„ ê¸°ë°˜ ì¡°ì •ëœ í¬ê¸°
                            confidence=conf,
                            tm_x=tm_x,
                            tm_y=tm_y
                        )
                        
                        image_results.append(detection)
                        all_results.append(detection)
                    
                    processed_images.append(image_name)
                    raw_detections = stage1_count + stage2_count + stage3_count
                    print(f"âœ… ì™„ë£Œ: {image_name} (ì›ì‹œ: {raw_detections}ê°œ, ìµœì¢…: {len(image_results)}ê°œ íƒì§€)")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ (ë™ì  ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ë°˜ì˜)
                    if save_visualization and viz_dir and image_results:
                        viz_filename = f"{os.path.splitext(image_name)[0]}_detected_{timestamp}.jpg"
                        viz_path = os.path.join(viz_dir, viz_filename)
                        try:
                            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                            image = cv2.imread(image_path)
                            if image is not None:
                                # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ë™ì  í¬ê¸° ë°˜ì˜)
                                for detection in image_results:
                                    x1 = int(detection.center_x - detection.width / 2)
                                    y1 = int(detection.center_y - detection.height / 2)
                                    x2 = int(detection.center_x + detection.width / 2)
                                    y2 = int(detection.center_y + detection.height / 2)
                                    
                                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì •
                                    if detection.confidence >= 0.7:
                                        bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                                    elif detection.confidence >= 0.4:
                                        bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                                    else:
                                        bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                                    
                                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í¬ê¸°ì— ë”°ë¥¸ ì„  ë‘ê»˜ ì¡°ì •)
                                    thickness = 2 if detection.width >= 24 else 1
                                    cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, thickness)
                                    
                                    # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì œê±° (ì‹œì¸ì„± í–¥ìƒì„ ìœ„í•´)
                                
                                # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                                cv2.imwrite(viz_path, image)
                                print(f"  ğŸ–¼ï¸ ì‹œê°í™” ì €ì¥: {viz_filename}")
                        except Exception as e:
                            print(f"âš ï¸ ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨ ({image_name}): {e}")
                    elif save_visualization and viz_dir:
                        # íƒì§€ ê²°ê³¼ê°€ ì—†ì–´ë„ ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (íšŒìƒ‰ í…Œë‘ë¦¬ë¡œ í‘œì‹œ)
                        original_img = cv2.imread(image_path)
                        if original_img is not None:
                            h, w = original_img.shape[:2]
                            cv2.rectangle(original_img, (0, 0), (w-1, h-1), (128, 128, 128), 10)
                            
                            viz_filename = f"{os.path.splitext(image_name)[0]}_no_detection_{timestamp}.jpg"
                            viz_path = os.path.join(viz_dir, viz_filename)
                            cv2.imwrite(viz_path, original_img)
                            print(f"  ğŸ–¼ï¸ íƒì§€ì—†ìŒ ì‹œê°í™” ì €ì¥: {viz_filename}")
                    
                    # ì¶”ë¡  ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ
                    del primary_results
                    if enable_dense_detection:
                        del dense_results, fine_results
                    
                except Exception as e:
                    failed_images.append(f"{os.path.basename(image_path)}: {str(e)}")
                    print(f"âŒ ì‹¤íŒ¨: {os.path.basename(image_path)} - {e}")
            
            # CSV íŒŒì¼ ìƒì„±
            csv_file_url = None
            if all_results:
                csv_filename = f"batch_detections_{timestamp}.csv"
                csv_path = os.path.join(output_base, csv_filename)
                
                # íƒì§€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                results_data = []
                tm_coords_count = 0
                for idx, detection in enumerate(all_results, 1):
                    row = {
                        'no': idx,
                        'filename': detection.filename,
                        'class_id': detection.class_id,
                        'center_x': detection.center_x,
                        'center_y': detection.center_y,
                        'width': detection.width,
                        'height': detection.height,
                        'confidence': detection.confidence
                    }
                    
                    # TM ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                    if detection.tm_x is not None and detection.tm_y is not None:
                        row['tm_x'] = detection.tm_x
                        row['tm_y'] = detection.tm_y
                        tm_coords_count += 1
                    
                    results_data.append(row)
                
                # CSV ì €ì¥
                df = pd.DataFrame(results_data)
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                csv_file_url = f"/api/v1/inference/download/{csv_filename}"
                
                # TM ì¢Œí‘œ í†µê³„ ì¶œë ¥
                print(f"ğŸ“Š CSV ìƒì„± ì™„ë£Œ: {len(all_results)}ê°œ íƒì§€ ì¤‘ {tm_coords_count}ê°œ TM ì¢Œí‘œ í¬í•¨")
                if tm_coords_count == 0:
                    print(f"âš ï¸ TM ì¢Œí‘œ ì—†ìŒ: ì´ë¯¸ì§€ì— ì§€ë¦¬ì°¸ì¡° ì •ë³´(.tfw, .jgw ë˜ëŠ” TIFF ë©”íƒ€ë°ì´í„°)ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            merged_viz_filename = None
            if save_visualization and all_results:
                merged_viz_filename = create_merged_visualization(
                    all_results, output_base, timestamp, extract_dir, tile_size=config.DEFAULT_TILE_SIZE
                )
            
            # ê²°ê³¼ ZIP íŒŒì¼ ìƒì„±
            results_zip_url = None
            if all_results or (save_visualization and viz_dir and os.path.exists(viz_dir) and os.listdir(viz_dir)):
                # ì‚¬ìš©ì ì§€ì • íŒŒì¼ëª… ë˜ëŠ” ìë™ ìƒì„±
                if output_filename.strip():
                    # ì‚¬ìš©ìê°€ ì§€ì •í•œ íŒŒì¼ëª… ì‚¬ìš© (.zip í™•ì¥ì ìë™ ì¶”ê°€)
                    if not output_filename.endswith('.zip'):
                        zip_filename = f"{output_filename}.zip"
                    else:
                        zip_filename = output_filename
                else:
                    # ê¸°ë³¸ ìë™ ìƒì„± íŒŒì¼ëª…
                    zip_filename = f"batch_results_{timestamp}.zip"
                
                zip_path = os.path.join(DEFAULT_OUTPUT_DIR, zip_filename)
                
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # CSV íŒŒì¼ ì¶”ê°€
                    if all_results:
                        csv_path = os.path.join(output_base, f"batch_detections_{timestamp}.csv")
                        if os.path.exists(csv_path):
                            zipf.write(csv_path, f"batch_detections_{timestamp}.csv")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
                    if save_visualization and viz_dir and os.path.exists(viz_dir):
                        for file in os.listdir(viz_dir):
                            file_path = os.path.join(viz_dir, file)
                            if os.path.isfile(file_path):  # íŒŒì¼ì¸ì§€ í™•ì¸
                                zipf.write(file_path, f"visualizations/{file}")
                    
                    # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì¶”ê°€
                    if merged_viz_filename:
                        merged_path = os.path.join(output_base, merged_viz_filename)
                        if os.path.exists(merged_path):
                            zipf.write(merged_path, merged_viz_filename)
                
                results_zip_url = f"/api/v1/inference/download/{zip_filename}"
            
            return BatchInferenceResponse(
                success=True,
                message=f"ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ: {len(processed_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬, {len(all_results)}ê°œ ê°ì²´ íƒì§€",
                total_images=len(image_files),
                total_detections=len(all_results),
                processed_images=processed_images,
                failed_images=failed_images,
                csv_file_url=csv_file_url,
                results_zip_url=results_zip_url,
                merged_visualization=merged_viz_filename
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
