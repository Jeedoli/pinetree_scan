# ì¶”ë¡ /íƒì§€ API ë¼ìš°í„° - yolo_infer_to_gps.py ê¸°ë°˜
# YOLO ëª¨ë¸ë¡œ í”¼í•´ëª© íƒì§€ + GPS ì¢Œí‘œ ë³€í™˜ + CSV ì €ì¥

from fastapi import APIRouter, File, UploadFile, HTTPException, Form, Query
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import os
import tempfile
import shutil
import pandas as pd
import cv2
import rasterio
from rasterio.transform import from_bounds
from rasterio import Affine
from ultralytics import YOLO
import datetime
import json
from pathlib import Path
import sys
import numpy as np
import zipfile

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (scripts í´ë” ì ‘ê·¼ìš©)
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from .. import config

router = APIRouter()

# ì‘ë‹µ ëª¨ë¸ ì •ì˜
class DetectionResult(BaseModel):
    filename: str
    class_id: int
    center_x: float
    center_y: float
    width: float
    height: float
    confidence: Optional[float] = None
    tm_x: Optional[float] = None  # TM ì¢Œí‘œ X
    tm_y: Optional[float] = None  # TM ì¢Œí‘œ Y

class InferenceResponse(BaseModel):
    success: bool
    message: str
    detected_count: int
    results: List[DetectionResult]
    csv_file_url: Optional[str] = None
    visualization_images: Optional[List[str]] = None  # ì‹œê°í™” ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸

class BatchInferenceResponse(BaseModel):
    success: bool
    message: str
    total_images: int
    total_detections: int
    processed_images: List[str]
    failed_images: List[str]
    csv_file_url: Optional[str] = None
    results_zip_url: Optional[str] = None
    merged_visualization: Optional[str] = None  # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ íŒŒì¼ëª…

def extract_tile_position(filename: str) -> tuple:
    """íƒ€ì¼ íŒŒì¼ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (prefix_tile_x_y.tif -> (x, y))"""
    try:
        # A20250917_tile_2_1.tif -> ['A20250917', 'tile', '2', '1', 'tif']
        parts = filename.replace('.tif', '').replace('.tiff', '').split('_')
        if len(parts) >= 4 and parts[-3] == 'tile':
            x = int(parts[-2])
            y = int(parts[-1])
            return (x, y)
    except (ValueError, IndexError):
        pass
    return (0, 0)


def create_merged_visualization(all_results: List[DetectionResult], output_base: str, 
                               timestamp: str, extract_dir: str, tile_size: int = 1024) -> Optional[str]:
    """íƒ€ì¼ë³„ íƒì§€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì „ì²´ ì´ë¯¸ì§€ ì‹œê°í™” ìƒì„±"""
    
    if not all_results:
        return None
    
    try:
        print("ğŸ–¼ï¸ í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # íƒ€ì¼ ìœ„ì¹˜ ì •ë³´ ìˆ˜ì§‘
        tile_positions = {}
        tile_files = {}  # íƒ€ì¼ íŒŒì¼ ê²½ë¡œ ì €ì¥
        
        for result in all_results:
            x, y = extract_tile_position(result.filename)
            if (x, y) not in tile_positions:
                tile_positions[(x, y)] = []
                # íƒ€ì¼ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
                tile_path = None
                for root, dirs, files in os.walk(extract_dir):
                    if result.filename in files:
                        tile_path = os.path.join(root, result.filename)
                        break
                tile_files[(x, y)] = tile_path
            tile_positions[(x, y)].append(result)
        
        if not tile_positions:
            return None
        
        # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
        max_x = max(pos[0] for pos in tile_positions.keys())
        max_y = max(pos[1] for pos in tile_positions.keys())
        
        # ì‹¤ì œ íƒ€ì¼ë“¤ì„ ë¡œë“œí•´ì„œ ì •í™•í•œ í¬ê¸° ê³„ì‚°
        total_width = 0
        total_height = 0
        tile_dimensions = {}  # ê° íƒ€ì¼ì˜ ì‹¤ì œ í¬ê¸° ì €ì¥
        
        # ì²« ë²ˆì§¸ í–‰ì˜ ëª¨ë“  íƒ€ì¼ë¡œ ì „ì²´ ë„ˆë¹„ ê³„ì‚°
        for tx in range(max_x + 1):
            if (tx, 0) in tile_files and tile_files[(tx, 0)]:
                try:
                    tile_img = cv2.imread(tile_files[(tx, 0)])
                    if tile_img is not None:
                        h, w = tile_img.shape[:2]
                        tile_dimensions[(tx, 0)] = (w, h)
                        total_width += w
                    else:
                        tile_dimensions[(tx, 0)] = (tile_size, tile_size)
                        total_width += tile_size
                except:
                    tile_dimensions[(tx, 0)] = (tile_size, tile_size)
                    total_width += tile_size
            else:
                tile_dimensions[(tx, 0)] = (tile_size, tile_size)
                total_width += tile_size
        
        # ì²« ë²ˆì§¸ ì—´ì˜ ëª¨ë“  íƒ€ì¼ë¡œ ì „ì²´ ë†’ì´ ê³„ì‚°
        for ty in range(max_y + 1):
            if (0, ty) in tile_files and tile_files[(0, ty)]:
                try:
                    tile_img = cv2.imread(tile_files[(0, ty)])
                    if tile_img is not None:
                        h, w = tile_img.shape[:2]
                        tile_dimensions[(0, ty)] = (w, h)
                        total_height += h
                    else:
                        tile_dimensions[(0, ty)] = (tile_size, tile_size)
                        total_height += tile_size
                except:
                    tile_dimensions[(0, ty)] = (tile_size, tile_size)
                    total_height += tile_size
            else:
                tile_dimensions[(0, ty)] = (tile_size, tile_size)
                total_height += tile_size
        
        print(f"ğŸ“ ê³„ì‚°ëœ ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°: {total_width}x{total_height}")
        
        # ì „ì²´ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ìƒ‰ ë°°ê²½ìœ¼ë¡œ ì‹œì‘)
        merged_image = np.zeros((total_height, total_width, 3), dtype=np.uint8)
        
        # íƒ€ì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ í•©ì¹˜ê¸°
        current_y = 0
        for ty in range(max_y + 1):
            current_x = 0
            row_height = 0
            
            for tx in range(max_x + 1):
                tile_path = tile_files.get((tx, ty))
                
                if tile_path and os.path.exists(tile_path):
                    try:
                        # íƒ€ì¼ ì´ë¯¸ì§€ ë¡œë“œ
                        tile_img = cv2.imread(tile_path)
                        if tile_img is not None:
                            h, w = tile_img.shape[:2]
                            
                            # íƒ€ì¼ì„ ì „ì²´ ì´ë¯¸ì§€ì— ë°°ì¹˜
                            end_x = min(current_x + w, total_width)
                            end_y = min(current_y + h, total_height)
                            
                            actual_w = end_x - current_x
                            actual_h = end_y - current_y
                            
                            if actual_w > 0 and actual_h > 0:
                                merged_image[current_y:end_y, current_x:end_x] = tile_img[:actual_h, :actual_w]
                            
                            row_height = max(row_height, h)
                            current_x += w
                        else:
                            current_x += tile_size
                            row_height = max(row_height, tile_size)
                    except Exception as e:
                        print(f"âš ï¸ íƒ€ì¼ ë¡œë“œ ì‹¤íŒ¨ {tile_path}: {e}")
                        current_x += tile_size
                        row_height = max(row_height, tile_size)
                else:
                    current_x += tile_size
                    row_height = max(row_height, tile_size)
            
            current_y += row_height
        
        print("ğŸ¯ íƒ€ì¼ í•©ì¹˜ê¸° ì™„ë£Œ, íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° ì‹œì‘...")
        
        # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        current_y_offset = 0
        for ty in range(max_y + 1):
            current_x_offset = 0
            row_height = tile_dimensions.get((0, ty), (tile_size, tile_size))[1]
            
            for tx in range(max_x + 1):
                tile_width = tile_dimensions.get((tx, 0), (tile_size, tile_size))[0]
                
                # í•´ë‹¹ íƒ€ì¼ì˜ íƒì§€ ê²°ê³¼ë“¤ ê·¸ë¦¬ê¸°
                if (tx, ty) in tile_positions:
                    for detection in tile_positions[(tx, ty)]:
                        # íƒ€ì¼ ë‚´ ì¢Œí‘œë¥¼ ì „ì²´ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                        global_x = current_x_offset + detection.center_x
                        global_y = current_y_offset + detection.center_y
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                        x1 = int(global_x - detection.width / 2)
                        y1 = int(global_y - detection.height / 2)
                        x2 = int(global_x + detection.width / 2)
                        y2 = int(global_y + detection.height / 2)
                        
                        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
                        x1 = max(0, min(x1, total_width))
                        y1 = max(0, min(y1, total_height))
                        x2 = max(0, min(x2, total_width))
                        y2 = max(0, min(y2, total_height))
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì–‡ì€ ì´ˆë¡ìƒ‰)
                        cv2.rectangle(merged_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        
                        # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì¶”ê°€
                        if detection.confidence:
                            text = f"{detection.confidence:.2f}"
                            # í…ìŠ¤íŠ¸ ë°°ê²½ ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
                            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
                            cv2.rectangle(merged_image, (x1, y1-25), (x1 + text_size[0] + 10, y1), (0, 255, 0), -1)
                            cv2.putText(merged_image, text, (x1 + 5, y1-8), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
                
                current_x_offset += tile_width
            
            current_y_offset += row_height
        
        # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
        merged_filename = f"merged_detection_{timestamp}.jpg"
        merged_path = os.path.join(output_base, merged_filename)
        
        # í° ì´ë¯¸ì§€ì¸ ê²½ìš° í¬ê¸° ì¡°ì • (ë©”ëª¨ë¦¬ ì ˆì•½ ë° íŒŒì¼ í¬ê¸° ìµœì í™”)
        if total_width > 8192 or total_height > 8192:
            scale = min(8192 / total_width, 8192 / total_height)
            new_width = int(total_width * scale)
            new_height = int(total_height * scale)
            print(f"ğŸ”§ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {total_width}x{total_height} â†’ {new_width}x{new_height}")
            merged_image = cv2.resize(merged_image, (new_width, new_height))
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ì„¤ì •ìœ¼ë¡œ ì €ì¥
        cv2.imwrite(merged_path, merged_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
        
        print(f"âœ… í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {merged_filename}")
        return merged_filename
        
    except Exception as e:
        print(f"âš ï¸ í•©ì³ì§„ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


# ê¸°ë³¸ ì„¤ì •
DEFAULT_WEIGHTS = str(config.DEFAULT_MODEL_PATH)
DEFAULT_OUTPUT_DIR = str(config.API_RESULTS_DIR)

def pixel_to_tm(px: float, py: float, tfw: List[float]) -> tuple:
    """í”½ì…€ ì¢Œí‘œë¥¼ TM ì¢Œí‘œë¡œ ë³€í™˜
    
    Args:
        px, py: í”½ì…€ ì¢Œí‘œ
        tfw: TFW íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸ [A, D, B, E, C, F]
    
    Returns:
        tuple: (tm_x, tm_y) TM ì¢Œí‘œ
    """
    A, D, B, E, C, F = tfw
    tm_x = A * px + B * py + C
    tm_y = D * px + E * py + F
    return tm_x, tm_y

def get_tfw_from_tiff(image_path: str) -> Optional[List[float]]:
    """TIFF íŒŒì¼ì—ì„œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œí•˜ì—¬ TFW íŒŒë¼ë¯¸í„° ìƒì„±
    
    Args:
        image_path: TIFF ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with rasterio.open(image_path) as src:
            if src.transform:
                # Affine ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ TFW íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                transform = src.transform
                # Affine ë§¤íŠ¸ë¦­ìŠ¤: [a, b, c, d, e, f]
                # TFW í˜•ì‹: [A=a, D=d, B=b, E=e, C=c, F=f]
                tfw_params = [
                    transform.a,  # A: X í”½ì…€ í¬ê¸°
                    transform.d,  # D: Y í”½ì…€ í¬ê¸° (ë³´í†µ ìŒìˆ˜)
                    transform.b,  # B: íšŒì „/ê¸°ìš¸ê¸°
                    transform.e,  # E: íšŒì „/ê¸°ìš¸ê¸°
                    transform.c,  # C: ì¢Œìƒë‹¨ X ì¢Œí‘œ
                    transform.f   # F: ì¢Œìƒë‹¨ Y ì¢Œí‘œ
                ]
                return tfw_params
    except Exception as e:
        print(f"âš ï¸ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

def load_tfw_file(tfw_path: str) -> Optional[List[float]]:
    """TFW íŒŒì¼ì—ì„œ ë³€í™˜ íŒŒë¼ë¯¸í„° ë¡œë“œ
    
    Args:
        tfw_path: TFW íŒŒì¼ ê²½ë¡œ
        
    Returns:
        List[float]: TFW íŒŒë¼ë¯¸í„° [A, D, B, E, C, F] ë˜ëŠ” None
    """
    try:
        with open(tfw_path, 'r') as f:
            lines = f.readlines()
            if len(lines) >= 6:
                return [float(line.strip()) for line in lines[:6]]
    except Exception as e:
        print(f"âš ï¸ TFW íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return None

def draw_bounding_boxes_on_image(image, results):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜ - ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™”"""
    for result in results:
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                # ğŸŒ² ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ìš© ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ìµœì í™”
                # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ 15% ì¶•ì†Œí•˜ì—¬ ë” ì •í™•í•œ ì˜ì—­ë§Œ í‘œì‹œ
                width = x2 - x1
                height = y2 - y1
                center_x = x1 + width / 2
                center_y = y1 + height / 2
                
                # í¬ê¸° ì¶•ì†Œ ë¹„ìœ¨ (85% í¬ê¸°ë¡œ ì¶•ì†Œ)
                scale_factor = 0.85
                new_width = width * scale_factor
                new_height = height * scale_factor
                
                # ìƒˆë¡œìš´ ì¢Œí‘œ ê³„ì‚°
                new_x1 = int(center_x - new_width / 2)
                new_y1 = int(center_y - new_height / 2)
                new_x2 = int(center_x + new_width / 2)
                new_y2 = int(center_y + new_height / 2)
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì • (ë‚®ì€ ì‹ ë¢°ë„ëŠ” ì£¼í™©ìƒ‰ìœ¼ë¡œ)
                if confidence >= 0.7:
                    bbox_color = (0, 255, 0)  # ë…¹ìƒ‰ (ë†’ì€ ì‹ ë¢°ë„)
                elif confidence >= 0.4:
                    bbox_color = (0, 165, 255)  # ì£¼í™©ìƒ‰ (ì¤‘ê°„ ì‹ ë¢°ë„)
                else:
                    bbox_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì‹ ë¢°ë„)
                
                # ìµœì í™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë” ì–‡ì€ ì„ )
                cv2.rectangle(image, (new_x1, new_y1), (new_x2, new_y2), 
                            bbox_color, 2)  # ë‘ê»˜ë¥¼ 2ë¡œ ì¤„ì„
                
                # ë” ì‘ì€ í°íŠ¸ë¡œ ë ˆì´ë¸” í‘œì‹œ
                label = f"Pine Damage: {confidence:.2f}"
                font_scale = 0.5  # í°íŠ¸ í¬ê¸° ì¶•ì†Œ
                font_thickness = 1  # í°íŠ¸ ë‘ê»˜ ì¶•ì†Œ
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 
                                           font_scale, font_thickness)[0]
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ë” ì‘ê²Œ)
                cv2.rectangle(image, (new_x1, new_y1 - label_size[1] - 5), 
                            (new_x1 + label_size[0], new_y1), 
                            bbox_color, -1)
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ë” ì‘ê²Œ)
                cv2.putText(image, label, (new_x1, new_y1 - 3), 
                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, 
                          (255, 255, 255), font_thickness)

@router.post("/detect", response_model=InferenceResponse)
async def detect_damaged_trees(
    files: List[UploadFile] = File(..., description="íƒì§€í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤ (TIFF, JPG, PNG)"),
    weights: str = Form(default=DEFAULT_WEIGHTS, description="YOLO ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ"),
    confidence: float = Form(default=0.3, description="ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0~1.0) - ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™”"),
    iou_threshold: float = Form(default=0.6, description="IOU ì„ê³„ê°’ (0.0~1.0) - ì˜¤íƒì§€ ë°©ì§€"),
    save_csv: bool = Form(default=True, description="CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ ì—¬ë¶€"),
    save_visualization: bool = Form(default=True, description="ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€")
):
    """
    ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ì†Œë‚˜ë¬´ì¬ì„ ì¶©ë³‘ í”¼í•´ëª©ì„ íƒì§€í•©ë‹ˆë‹¤.
    
    - **files**: íƒì§€í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤ (TIFF, JPG, PNG ì§€ì›)
    - **weights**: YOLO ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
    - **confidence**: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.05)
    - **iou_threshold**: IOU ì„ê³„ê°’ (ê¸°ë³¸: 0.25)
    - **save_csv**: CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    - **save_visualization**: ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    
    try:
        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(weights):
            raise HTTPException(status_code=404, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {weights}")
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        model = YOLO(weights)
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        all_results = []
        damaged_count = 0
        visualization_urls = []  # ì‹œê°í™” ì´ë¯¸ì§€ URL ì €ì¥ìš©
        
        # ì„¸ì…˜ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (íŒŒì¼ëª… ì¼ê´€ì„±ì„ ìœ„í•´)
        session_timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            
            # ê° íŒŒì¼ ì²˜ë¦¬
            for file in files:
                # íŒŒì¼ í™•ì¥ì ê²€ì¦
                if not file.filename.lower().endswith(('.tif', '.tiff', '.jpg', '.jpeg', '.png')):
                    raise HTTPException(
                        status_code=400, 
                        detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file.filename}"
                    )
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_file_path = os.path.join(temp_dir, file.filename)
                with open(temp_file_path, "wb") as buffer:
                    shutil.copyfileobj(file.file, buffer)
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (4ì±„ë„ -> 3ì±„ë„ ë³€í™˜)
                img = cv2.imread(temp_file_path, cv2.IMREAD_UNCHANGED)
                if img is not None and len(img.shape) == 3 and img.shape[2] == 4:
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
                    cv2.imwrite(temp_file_path, img_rgb)
                    img = img_rgb
                
                # ğŸ—ºï¸ TM ì¢Œí‘œ ë³€í™˜ì„ ìœ„í•œ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ
                tfw_params = None
                if file.filename.lower().endswith(('.tif', '.tiff')):
                    # 1. TIFF íŒŒì¼ì—ì„œ ì§ì ‘ ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì¶”ì¶œ ì‹œë„
                    tfw_params = get_tfw_from_tiff(temp_file_path)
                    
                    # 2. TFW íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ë™ì¼í•œ ì´ë¦„)
                    if not tfw_params:
                        tfw_path = temp_file_path.replace('.tif', '.tfw').replace('.tiff', '.tfw')
                        if os.path.exists(tfw_path):
                            tfw_params = load_tfw_file(tfw_path)
                
                # YOLO ì¶”ë¡  ì‹¤í–‰
                yolo_results = model(temp_file_path, conf=confidence, iou=iou_threshold)
                
                # ê²°ê³¼ ì²˜ë¦¬
                for r in yolo_results:
                    for box in r.boxes:
                        class_id = int(box.cls[0])
                        conf_score = float(box.conf[0])
                        
                        # í”¼í•´ëª© í´ë˜ìŠ¤(class_id=0)ë§Œ ì²˜ë¦¬
                        if class_id == 0:
                            xmin, ymin, xmax, ymax = box.xyxy[0].tolist()
                            
                            # ì •ê·œí™”ëœ ì¢Œí‘œ ê³„ì‚°
                            x_center = (xmin + xmax) / 2 / img.shape[1]
                            y_center = (ymin + ymax) / 2 / img.shape[0]
                            width = (xmax - xmin) / img.shape[1]
                            height = (ymax - ymin) / img.shape[0]
                            
                            # ğŸ—ºï¸ TM ì¢Œí‘œ ê³„ì‚° (ì§€ë¦¬ì°¸ì¡° ì •ë³´ê°€ ìˆëŠ” ê²½ìš°)
                            tm_x, tm_y = None, None
                            if tfw_params:
                                # í”½ì…€ ì¢Œí‘œ (ë°•ìŠ¤ ì¤‘ì‹¬ì )
                                center_px = (xmin + xmax) / 2
                                center_py = (ymin + ymax) / 2
                                
                                # í”½ì…€ ì¢Œí‘œë¥¼ TM ì¢Œí‘œë¡œ ë³€í™˜
                                tm_x, tm_y = pixel_to_tm(center_px, center_py, tfw_params)
                            
                            result = DetectionResult(
                                filename=file.filename,
                                class_id=class_id,
                                center_x=x_center,
                                center_y=y_center,
                                width=width,
                                height=height,
                                confidence=conf_score,
                                tm_x=tm_x,  # TM ì¢Œí‘œ X
                                tm_y=tm_y   # TM ì¢Œí‘œ Y
                            )
                            all_results.append(result)
                            damaged_count += 1
                
                # ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
                if save_visualization and yolo_results[0].boxes is not None and len(yolo_results[0].boxes) > 0:
                    # íƒì§€ëœ ê°ì²´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹œê°í™”
                    img_copy = img.copy()
                    draw_bounding_boxes_on_image(img_copy, yolo_results)
                    
                    # ì‹œê°í™” ë””ë ‰í† ë¦¬ ìƒì„±
                    vis_dir = str(config.API_VISUALIZATION_DIR)
                    os.makedirs(vis_dir, exist_ok=True)
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„± (ì„¸ì…˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©)
                    name_without_ext = os.path.splitext(file.filename)[0]
                    vis_filename = f"{name_without_ext}_detected_{session_timestamp}.jpg"
                    vis_path = os.path.join(vis_dir, vis_filename)
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                    cv2.imwrite(vis_path, img_copy)
                    
                    # URL ìƒì„±
                    vis_url = f"/api/v1/inference/visualization/{vis_filename}"
                    visualization_urls.append(vis_url)
        
        # CSV ì €ì¥ ì²˜ë¦¬
        csv_file_url = None
        if save_csv and all_results:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            
            # CSV íŒŒì¼ëª… ìƒì„± (ì„¸ì…˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©)
            csv_filename = f"detection_results_{session_timestamp}.csv"
            csv_path = os.path.join(DEFAULT_OUTPUT_DIR, csv_filename)
            
            # ğŸ—ºï¸ TM ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ë³„ë„ CSV ìƒì„±
            tm_results = [r for r in all_results if r.tm_x is not None and r.tm_y is not None]
            
            if tm_results:
                # TM ì¢Œí‘œ CSV ì €ì¥ (ì²¨ë¶€í•´ì£¼ì‹  í˜•ì‹ê³¼ ë™ì¼)
                tm_csv_filename = f"damaged_trees_tm_coords_{session_timestamp}.csv"
                tm_csv_path = os.path.join(DEFAULT_OUTPUT_DIR, tm_csv_filename)
                
                # TM ì¢Œí‘œ DataFrame ìƒì„± (no, x, y í˜•ì‹)
                tm_data = []
                for i, result in enumerate(tm_results, 1):
                    tm_data.append({
                        'no': i,
                        'x': round(result.tm_x, 3),  # TM X ì¢Œí‘œ (ì†Œìˆ˜ì  3ìë¦¬)
                        'y': round(result.tm_y, 3)   # TM Y ì¢Œí‘œ (ì†Œìˆ˜ì  3ìë¦¬)
                    })
                
                df_tm = pd.DataFrame(tm_data)
                df_tm.to_csv(tm_csv_path, index=False)
                print(f"ğŸ—ºï¸ TM ì¢Œí‘œ CSV ì €ì¥: {tm_csv_path}")
                print(f"ğŸ“Š TM ì¢Œí‘œ ë³€í™˜ ì„±ê³µ: {len(tm_results)}ê°œ/{len(all_results)}ê°œ")
            
            # ê¸°ì¡´ ì „ì²´ ì •ë³´ CSV ì €ì¥ (ì •ê·œí™” ì¢Œí‘œ + TM ì¢Œí‘œ ëª¨ë‘ í¬í•¨)
            df_results = pd.DataFrame([result.dict() for result in all_results])
            df_results.to_csv(csv_path, index=False)
            csv_file_url = f"/api/v1/inference/download/{csv_filename}"
        
        # ì„±ê³µ ë©”ì‹œì§€ ìƒì„±
        tm_count = len([r for r in all_results if r.tm_x is not None and r.tm_y is not None])
        if tm_count > 0:
            message = f"íƒì§€ ì™„ë£Œ: {damaged_count}ê°œì˜ í”¼í•´ëª©ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (TM ì¢Œí‘œ ë³€í™˜: {tm_count}ê°œ)"
        else:
            message = f"íƒì§€ ì™„ë£Œ: {damaged_count}ê°œì˜ í”¼í•´ëª©ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (ì§€ë¦¬ì°¸ì¡° ì •ë³´ ì—†ìŒ)"
        
        return InferenceResponse(
            success=True,
            message=message,
            detected_count=damaged_count,
            results=all_results,
            csv_file_url=csv_file_url,
            visualization_images=visualization_urls if visualization_urls else None
        )
        
    except Exception as e:
        import traceback
        error_detail = f"íƒì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\nìƒì„¸: {traceback.format_exc()}"
        print(f"API ERROR: {error_detail}")  # ì„œë²„ ë¡œê·¸ì— ì¶œë ¥
        raise HTTPException(status_code=500, detail=f"íƒì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.get("/download/{filename}")
async def download_csv_result(filename: str):
    """
    íƒì§€ ê²°ê³¼ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(DEFAULT_OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )


@router.get("/visualization/{filename}")
async def download_visualization_image(filename: str):
    """
    íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    """
    file_path = os.path.join(str(config.API_VISUALIZATION_DIR), filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='image/jpeg'
    )


@router.get("/models")
async def list_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ YOLO ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    models_dir = "models"
    results_dir = "results"
    
    available_models = []
    
    # models ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    if os.path.exists(models_dir):
        for root, dirs, files in os.walk(models_dir):
            for file in files:
                if file.endswith('.pt'):
                    model_path = os.path.join(root, file)
                    available_models.append({
                        "name": file,
                        "path": model_path,
                        "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                    })
    
    # results ë””ë ‰í† ë¦¬ì˜ weights í´ë”ë„ ìŠ¤ìº”
    if os.path.exists(results_dir):
        for root, dirs, files in os.walk(results_dir):
            if "weights" in root:
                for file in files:
                    if file.endswith('.pt'):
                        model_path = os.path.join(root, file)
                        available_models.append({
                            "name": f"{os.path.basename(os.path.dirname(root))}_{file}",
                            "path": model_path,
                            "size": os.path.getsize(model_path) if os.path.exists(model_path) else 0
                        })
    
    return {
        "available_models": available_models,
        "total_count": len(available_models)
    }


@router.post("/detect-all", response_model=BatchInferenceResponse)
async def batch_inference(
    images_zip: UploadFile = File(..., description="ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼"),
    model_path: str = Form(default=DEFAULT_WEIGHTS, description="ì‚¬ìš©í•  YOLO ëª¨ë¸ ê²½ë¡œ"),
    confidence: float = Form(default=0.5, description="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’"),
    iou_threshold: float = Form(default=0.8, description="IoU ì„ê³„ê°’ (ì¤‘ë³µ íƒì§€ ì œê±°ìš©)"),
    save_visualization: bool = Form(default=True, description="íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€"),
    output_tm_coordinates: bool = Form(default=True, description="TM ì¢Œí‘œ ë³€í™˜ ì—¬ë¶€")
):
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ë°°ì¹˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ZIP íŒŒì¼ë¡œ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ íƒì§€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    - **images_zip**: ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤ì´ í¬í•¨ëœ ZIP íŒŒì¼
    - **model_path**: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    - **confidence**: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0, ê¸°ë³¸ê°’: 0.5)
    - **iou_threshold**: IoU ì„ê³„ê°’ (0.0-1.0, ì¤‘ë³µ íƒì§€ ì œê±°ìš©, ê¸°ë³¸ê°’: 0.8)
    - **save_visualization**: íƒì§€ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€
    - **output_tm_coordinates**: TM ì¢Œí‘œ ë³€í™˜ ì¶œë ¥ ì—¬ë¶€
    """
    
    try:
        # íŒŒì¼ëª… ê²€ì¦
        if not images_zip.filename:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì— íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ZIP íŒŒì¼ í™•ì¥ì ê²€ì¦
        if not images_zip.filename.lower().endswith('.zip'):
            raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ëª¨ë¸ ê²½ë¡œ ê²€ì¦
        if not os.path.exists(model_path):
            raise HTTPException(status_code=400, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        model = YOLO(model_path)
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            
            # ZIP íŒŒì¼ ì €ì¥ ë° ì••ì¶• í•´ì œ
            zip_path = os.path.join(temp_dir, images_zip.filename)
            with open(zip_path, "wb") as f:
                shutil.copyfileobj(images_zip.file, f)
            
            # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
            extract_dir = os.path.join(temp_dir, "extracted")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_files = []
            for root, dirs, files in os.walk(extract_dir):
                for file in files:
                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                        image_files.append(os.path.join(root, file))
            
            if not image_files:
                raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_base = os.path.join(DEFAULT_OUTPUT_DIR, f"batch_inference_{timestamp}")
            
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            os.makedirs(output_base, exist_ok=True)
            
            viz_dir = None
            if save_visualization:
                viz_dir = os.path.join(output_base, "visualizations")
                os.makedirs(viz_dir, exist_ok=True)
            
            # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
            all_results = []
            processed_images = []
            failed_images = []
            
            print(f"ğŸ“Š ë°°ì¹˜ ì¶”ë¡  ì‹œì‘: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì •")
            
            for idx, image_path in enumerate(image_files, 1):
                try:
                    image_name = os.path.basename(image_path)
                    print(f"ğŸ” ì²˜ë¦¬ ì¤‘ ({idx}/{len(image_files)}): {image_name}")
                    
                    # ê°œë³„ ì´ë¯¸ì§€ ì¶”ë¡ 
                    results = model(image_path, conf=confidence, iou=iou_threshold)
                    
                    # TFW ì •ë³´ ì¶”ì¶œ (TM ì¢Œí‘œ ë³€í™˜ìš©)
                    tfw_params = None
                    if output_tm_coordinates:
                        tfw_params = get_tfw_from_tiff(image_path)
                        if not tfw_params:
                            # ë™ì¼ ë””ë ‰í† ë¦¬ì—ì„œ TFW íŒŒì¼ ì°¾ê¸°
                            tfw_file_path = image_path.replace('.tif', '.tfw').replace('.tiff', '.tfw')
                            if os.path.exists(tfw_file_path):
                                tfw_params = load_tfw_file(tfw_file_path)
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    image_results = []
                    for result in results:
                        boxes = result.boxes
                        if boxes is not None:
                            for box in boxes:
                                # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                center_x = (x1 + x2) / 2
                                center_y = (y1 + y2) / 2
                                width = x2 - x1
                                height = y2 - y1
                                conf = float(box.conf[0].cpu().numpy())
                                class_id = int(box.cls[0].cpu().numpy())
                                
                                # TM ì¢Œí‘œ ë³€í™˜
                                tm_x, tm_y = None, None
                                if tfw_params:
                                    tm_x, tm_y = pixel_to_tm(center_x, center_y, tfw_params)
                                
                                detection = DetectionResult(
                                    filename=image_name,
                                    class_id=class_id,
                                    center_x=center_x,
                                    center_y=center_y,
                                    width=width,
                                    height=height,
                                    confidence=conf,
                                    tm_x=tm_x,
                                    tm_y=tm_y
                                )
                                
                                image_results.append(detection)
                                all_results.append(detection)
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                    if save_visualization and viz_dir and image_results:
                        viz_path = os.path.join(viz_dir, f"detected_{image_name}")
                        try:
                            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                            image = cv2.imread(image_path)
                            if image is not None:
                                # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
                                for detection in image_results:
                                    x1 = int(detection.center_x - detection.width / 2)
                                    y1 = int(detection.center_y - detection.height / 2)
                                    x2 = int(detection.center_x + detection.width / 2)
                                    y2 = int(detection.center_y + detection.height / 2)
                                    
                                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                                    
                                    # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì¶”ê°€
                                    if detection.confidence:
                                        text = f"{detection.confidence:.2f}"
                                        cv2.putText(image, text, (x1, y1-10), 
                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                                
                                # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
                                cv2.imwrite(viz_path, image)
                                # ë©”ëª¨ë¦¬ í•´ì œ
                                del image
                        except Exception as e:
                            print(f"âš ï¸ ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨ ({image_name}): {e}")
                    
                    # ì¶”ë¡  ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ
                    del results
                    
                    processed_images.append(image_name)
                    print(f"âœ… ì™„ë£Œ: {image_name} ({len(image_results)}ê°œ íƒì§€)")
                    
                except Exception as e:
                    failed_images.append(f"{os.path.basename(image_path)}: {str(e)}")
                    print(f"âŒ ì‹¤íŒ¨: {os.path.basename(image_path)} - {e}")
            
            # CSV íŒŒì¼ ìƒì„±
            csv_file_url = None
            if all_results:
                csv_filename = f"batch_detections_{timestamp}.csv"
                csv_path = os.path.join(output_base, csv_filename)
                
                # íƒì§€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                results_data = []
                for idx, detection in enumerate(all_results, 1):
                    row = {
                        'no': idx,
                        'filename': detection.filename,
                        'class_id': detection.class_id,
                        'center_x': detection.center_x,
                        'center_y': detection.center_y,
                        'width': detection.width,
                        'height': detection.height,
                        'confidence': detection.confidence
                    }
                    
                    # TM ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                    if detection.tm_x is not None and detection.tm_y is not None:
                        row['tm_x'] = detection.tm_x
                        row['tm_y'] = detection.tm_y
                    
                    results_data.append(row)
                
                # CSV ì €ì¥
                df = pd.DataFrame(results_data)
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                csv_file_url = f"/api/v1/inference/download/{csv_filename}"
            
            # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            merged_viz_filename = None
            if save_visualization and all_results:
                merged_viz_filename = create_merged_visualization(
                    all_results, output_base, timestamp, extract_dir, tile_size=1024
                )
            
            # ê²°ê³¼ ZIP íŒŒì¼ ìƒì„±
            results_zip_url = None
            if all_results or (save_visualization and viz_dir and os.path.exists(viz_dir) and os.listdir(viz_dir)):
                zip_filename = f"batch_results_{timestamp}.zip"
                zip_path = os.path.join(DEFAULT_OUTPUT_DIR, zip_filename)
                
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    # CSV íŒŒì¼ ì¶”ê°€
                    if all_results:
                        csv_path = os.path.join(output_base, f"batch_detections_{timestamp}.csv")
                        if os.path.exists(csv_path):
                            zipf.write(csv_path, f"batch_detections_{timestamp}.csv")
                    
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
                    if save_visualization and viz_dir and os.path.exists(viz_dir):
                        for file in os.listdir(viz_dir):
                            file_path = os.path.join(viz_dir, file)
                            if os.path.isfile(file_path):  # íŒŒì¼ì¸ì§€ í™•ì¸
                                zipf.write(file_path, f"visualizations/{file}")
                    
                    # í•©ì³ì§„ ì‹œê°í™” ì´ë¯¸ì§€ ì¶”ê°€
                    if merged_viz_filename:
                        merged_path = os.path.join(output_base, merged_viz_filename)
                        if os.path.exists(merged_path):
                            zipf.write(merged_path, merged_viz_filename)
                
                results_zip_url = f"/api/v1/inference/download/{zip_filename}"
            
            return BatchInferenceResponse(
                success=True,
                message=f"ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ: {len(processed_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬, {len(all_results)}ê°œ ê°ì²´ íƒì§€",
                total_images=len(image_files),
                total_detections=len(all_results),
                processed_images=processed_images,
                failed_images=failed_images,
                csv_file_url=csv_file_url,
                results_zip_url=results_zip_url,
                merged_visualization=merged_viz_filename
            )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
