{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad0a969",
   "metadata": {},
   "source": [
    "# ğŸš€ YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ - ì›í´ë¦­ í•™ìŠµ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ğŸ¯ **4ë‹¨ê³„ ì›í´ë¦­ ì‹¤í–‰**\n",
    "\n",
    "### **âš¡ ë¹ ë¥¸ ì‹œì‘**\n",
    "1. **ğŸ–¥ï¸ GPU ì„¤ì •**: `ëŸ°íƒ€ì„` â†’ `ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½` â†’ `T4 GPU` ì„ íƒ\n",
    "2. **ğŸš€ ì›í´ë¦­ ì‹¤í–‰**: `ëŸ°íƒ€ì„` â†’ `ëª¨ë‘ ì‹¤í–‰` í´ë¦­  \n",
    "3. **â˜• ëŒ€ê¸°**: ì•½ 1-2ì‹œê°„ í›„ ì™„ì„±!\n",
    "\n",
    "### **ğŸ”„ ìë™ ì‹¤í–‰ ë‹¨ê³„**\n",
    "- **1ë‹¨ê³„**: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€\n",
    "- **2ë‹¨ê³„**: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ\n",
    "- **3ë‹¨ê³„**: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
    "- **4ë‹¨ê³„**: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "### **ğŸ¯ ë„¤ì´ë° ê·œì¹™**\n",
    "- **í”„ë¡œì íŠ¸**: `pinetree_yolov11s` (ìœ ì§€)\n",
    "- **ì‹¤í–‰ëª…**: `damage_detection_YYYYMMDD_HHMM`\n",
    "- **ì˜ˆì‹œ**: `damage_detection_20250916_1430`\n",
    "\n",
    "### **\udcc8 ì˜ˆìƒ ì„±ëŠ¥**\n",
    "- **mAP50**: 93%+ (ë†’ì€ íƒì§€ ì •í™•ë„)\n",
    "- **Precision**: 90%+ (ì˜¤íƒì§€ ìµœì†Œí™”)  \n",
    "- **Recall**: 85%+ (ì‹¤ì œ í”¼í•´ëª© íƒì§€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e444eb0",
   "metadata": {},
   "source": [
    "## ğŸ”§ **1ë‹¨ê³„: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€**\n",
    "\n",
    "> íŒ¨í‚¤ì§€ ì„¤ì¹˜, ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ìë™ íƒì§€, GPU ì„¤ì •ì„ ëª¨ë‘ ìë™í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69829093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ 1ë‹¨ê³„: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0])\n",
    "        print(f\"âœ… {package} ì´ë¯¸ ì„¤ì¹˜ë¨\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "print(\"ğŸš€ YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ - í™˜ê²½ ì„¤ì •\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ğŸ—‚ï¸ Google Drive ë§ˆìš´íŠ¸ ë° ZIP ë°ì´í„° ìë™ ì••ì¶• í•´ì œ (Colab í™˜ê²½ì—ì„œë§Œ)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸ“ Google Colab í™˜ê²½ ê°ì§€\")\n",
    "    \n",
    "    # Google Drive ë§ˆìš´íŠ¸\n",
    "    print(\"ğŸ”— Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ\")\n",
    "    \n",
    "    # ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "    drive_path = '/content/drive/MyDrive/pinetree_scan'\n",
    "    if not os.path.exists(drive_path):\n",
    "        os.makedirs(drive_path, exist_ok=True)\n",
    "        print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±: {drive_path}\")\n",
    "    \n",
    "    # ğŸ” ZIP íŒŒì¼ ìë™ íƒì§€ ë° ì••ì¶• í•´ì œ í•¨ìˆ˜\n",
    "    def find_and_extract_training_zip():\n",
    "        \"\"\"Google Driveì—ì„œ training_data ZIP íŒŒì¼ì„ ì°¾ì•„ ì••ì¶• í•´ì œ\"\"\"\n",
    "        import zipfile\n",
    "        import shutil\n",
    "        \n",
    "        print(\"\\nğŸ” Google Driveì—ì„œ ZIP ë°ì´í„°ì…‹ íƒì§€ ì¤‘...\")\n",
    "        \n",
    "        # ZIP íŒŒì¼ ê²€ìƒ‰ ê²½ë¡œ (ìš°ì„ ìˆœìœ„ë³„)\n",
    "        zip_search_paths = [\n",
    "            # 1ìˆœìœ„: pinetree_scan/training_data í´ë” ë‚´ì˜ ëª¨ë“  ZIP íŒŒì¼\n",
    "            '/content/drive/MyDrive/pinetree_scan/training_data/*.zip',\n",
    "            \n",
    "            # 2ìˆœìœ„: pinetree_scan í´ë” ë‚´\n",
    "            '/content/drive/MyDrive/pinetree_scan/training_data.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/dataset.zip', \n",
    "            '/content/drive/MyDrive/pinetree_scan/data.zip',\n",
    "            \n",
    "            # 3ìˆœìœ„: ì§ì ‘ ì—…ë¡œë“œ\n",
    "            '/content/drive/MyDrive/training_data.zip',\n",
    "            '/content/drive/MyDrive/dataset.zip',\n",
    "            '/content/drive/MyDrive/data.zip',\n",
    "            '/content/drive/MyDrive/yolo_data.zip',\n",
    "            '/content/drive/MyDrive/pine_data.zip',\n",
    "            \n",
    "            # 4ìˆœìœ„: ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰\n",
    "            '/content/drive/MyDrive/*training*.zip',\n",
    "            '/content/drive/MyDrive/*dataset*.zip',\n",
    "            '/content/drive/MyDrive/*data*.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/*training*.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/*dataset*.zip'\n",
    "        ]\n",
    "        \n",
    "        found_zips = []\n",
    "        \n",
    "        for search_path in zip_search_paths:\n",
    "            if '*' in search_path:\n",
    "                # ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰\n",
    "                import glob\n",
    "                matches = glob.glob(search_path)\n",
    "                for match in matches:\n",
    "                    if os.path.exists(match) and match.endswith('.zip'):\n",
    "                        found_zips.append(match)\n",
    "            else:\n",
    "                # ì§ì ‘ ê²½ë¡œ í™•ì¸\n",
    "                if os.path.exists(search_path):\n",
    "                    found_zips.append(search_path)\n",
    "        \n",
    "        if found_zips:\n",
    "            # ì¤‘ë³µ ì œê±°\n",
    "            found_zips = list(set(found_zips))\n",
    "            \n",
    "            print(f\"ğŸ“¦ ë°œê²¬ëœ ZIP íŒŒì¼ë“¤:\")\n",
    "            for i, zip_file in enumerate(found_zips, 1):\n",
    "                file_size = os.path.getsize(zip_file) / 1024 / 1024  # MB\n",
    "                print(f\"  {i}. {os.path.basename(zip_file)} ({file_size:.1f}MB)\")\n",
    "                print(f\"     ê²½ë¡œ: {zip_file}\")\n",
    "            \n",
    "            # ê°€ì¥ í° íŒŒì¼ì„ ì„ íƒ (í›ˆë ¨ ë°ì´í„°ê°€ í´ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)\n",
    "            zip_path = max(found_zips, key=os.path.getsize)\n",
    "            print(f\"\\nâœ… ì„ íƒëœ íŒŒì¼: {os.path.basename(zip_path)}\")\n",
    "            print(f\"ğŸ“ ê²½ë¡œ: {zip_path}\")\n",
    "            \n",
    "            # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "            zip_size = os.path.getsize(zip_path) / 1024 / 1024  # MB\n",
    "            print(f\"ğŸ“ í¬ê¸°: {zip_size:.1f}MB\")\n",
    "            \n",
    "            # ì••ì¶• í•´ì œ ëŒ€ìƒ ê²½ë¡œ\n",
    "            extract_path = '/content/drive/MyDrive/pinetree_scan/training_data'\n",
    "            temp_extract_path = '/content/training_data_temp'\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nğŸ”„ ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...\")\n",
    "                \n",
    "                # ì„ì‹œ ê²½ë¡œì— ì••ì¶• í•´ì œ\n",
    "                if os.path.exists(temp_extract_path):\n",
    "                    shutil.rmtree(temp_extract_path)\n",
    "                \n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(temp_extract_path)\n",
    "                \n",
    "                print(f\"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {temp_extract_path}\")\n",
    "                \n",
    "                # ì••ì¶• í•´ì œëœ ë‚´ìš© í™•ì¸ ë° ì •ë¦¬\n",
    "                extracted_items = os.listdir(temp_extract_path)\n",
    "                print(f\"ğŸ“‹ ì••ì¶• í•´ì œ ë‚´ìš©: {extracted_items}\")\n",
    "                \n",
    "                # training_data í´ë” êµ¬ì¡° ì •ë¦¬\n",
    "                final_path = extract_path\n",
    "                \n",
    "                # ê¸°ì¡´ training_dataê°€ ìˆìœ¼ë©´ ë°±ì—…\n",
    "                if os.path.exists(final_path):\n",
    "                    backup_path = f\"{final_path}_backup_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "                    shutil.move(final_path, backup_path)\n",
    "                    print(f\"ğŸ’¾ ê¸°ì¡´ ë°ì´í„° ë°±ì—…: {backup_path}\")\n",
    "                \n",
    "                # ì••ì¶• í•´ì œëœ ë‚´ìš©ì´ training_data í´ë”ì¸ì§€ í™•ì¸\n",
    "                if 'training_data' in extracted_items:\n",
    "                    # training_data í´ë”ê°€ í¬í•¨ëœ ê²½ìš°\n",
    "                    source_path = os.path.join(temp_extract_path, 'training_data')\n",
    "                    shutil.move(source_path, final_path)\n",
    "                elif len(extracted_items) == 1 and os.path.isdir(os.path.join(temp_extract_path, extracted_items[0])):\n",
    "                    # ë‹¨ì¼ í´ë”ì¸ ê²½ìš°\n",
    "                    source_path = os.path.join(temp_extract_path, extracted_items[0])\n",
    "                    shutil.move(source_path, final_path)\n",
    "                else:\n",
    "                    # íŒŒì¼ë“¤ì´ ì§ì ‘ ì••ì¶•ëœ ê²½ìš°\n",
    "                    shutil.move(temp_extract_path, final_path)\n",
    "                \n",
    "                # ì„ì‹œ í´ë” ì •ë¦¬\n",
    "                if os.path.exists(temp_extract_path):\n",
    "                    shutil.rmtree(temp_extract_path)\n",
    "                \n",
    "                # ì••ì¶• í•´ì œ ê²°ê³¼ í™•ì¸\n",
    "                if os.path.exists(final_path):\n",
    "                    contents = os.listdir(final_path)\n",
    "                    print(f\"ğŸ“‚ ìµœì¢… ê²½ë¡œ: {final_path}\")\n",
    "                    print(f\"ğŸ“‹ ë‚´ìš©: {contents}\")\n",
    "                    \n",
    "                    # ê¸°ë³¸ êµ¬ì¡° í™•ì¸\n",
    "                    images_dir = os.path.join(final_path, 'images')\n",
    "                    labels_dir = os.path.join(final_path, 'labels')\n",
    "                    \n",
    "                    if os.path.exists(images_dir):\n",
    "                        image_count = len([f for f in os.listdir(images_dir) \n",
    "                                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff'))])\n",
    "                        print(f\"ğŸ“¸ ì´ë¯¸ì§€: {image_count}ê°œ\")\n",
    "                    \n",
    "                    if os.path.exists(labels_dir):\n",
    "                        label_count = len([f for f in os.listdir(labels_dir) \n",
    "                                         if f.endswith('.txt')])\n",
    "                        print(f\"ğŸ·ï¸ ë¼ë²¨: {label_count}ê°œ\")\n",
    "                \n",
    "                return final_path\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ZIP ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}\")\n",
    "                return None\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ ZIP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            print(\"ğŸ’¡ ë‹¤ìŒ ê²½ë¡œì— ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/pinetree_scan/training_data/your_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/pinetree_scan/training_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/training_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/dataset.zip\")\n",
    "            return None\n",
    "    \n",
    "    # ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì‹¤í–‰\n",
    "    extracted_data_path = find_and_extract_training_zip()\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° ê²½ë¡œ í™•ì¸ (ì••ì¶• í•´ì œ ê²°ê³¼ í¬í•¨)\n",
    "    data_paths = [\n",
    "        extracted_data_path,  # ì••ì¶• í•´ì œëœ ê²½ë¡œ ìš°ì„ \n",
    "        '/content/drive/MyDrive/pinetree_scan/training_data',\n",
    "        '/content/training_data',\n",
    "        '/content/drive/MyDrive/training_data'\n",
    "    ]\n",
    "    \n",
    "    data_path = None\n",
    "    for path in data_paths:\n",
    "        if path and os.path.exists(path):\n",
    "            # data.yamlì´ ìˆê±°ë‚˜ images í´ë”ê°€ ìˆìœ¼ë©´ ìœ íš¨í•œ ê²½ë¡œë¡œ ê°„ì£¼\n",
    "            if (os.path.exists(f\"{path}/data.yaml\") or \n",
    "                os.path.exists(f\"{path}/images\")):\n",
    "                data_path = path\n",
    "                print(f\"âœ… í•™ìŠµ ë°ì´í„° ë°œê²¬: {data_path}\")\n",
    "                break\n",
    "    \n",
    "    if not data_path:\n",
    "        print(\"âš ï¸ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ“‹ í•„ìš”í•œ íŒŒì¼ êµ¬ì¡°:\")\n",
    "        print(\"  ğŸ“¦ ZIP íŒŒì¼:\")\n",
    "        print(\"    ğŸ“‚ training_data.zip\")\n",
    "        print(\"      ğŸ“‚ images/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤)\")\n",
    "        print(\"      ğŸ“‚ labels/ (ë¼ë²¨ íŒŒì¼ë“¤)\")\n",
    "        print(\"      ğŸ“„ data.yaml (ì„ íƒì‚¬í•­)\")\n",
    "        print(\"\")\n",
    "        print(\"  ğŸ“ ë˜ëŠ” í´ë” êµ¬ì¡°:\")\n",
    "        print(\"    ğŸ“‚ training_data/\")\n",
    "        print(\"      ğŸ“„ data.yaml\")\n",
    "        print(\"      ğŸ“‚ images/\")\n",
    "        print(\"      ğŸ“‚ labels/\")\n",
    "        data_path = '/content/training_data'  # ê¸°ë³¸ê°’\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€\")\n",
    "    data_path = './data'  # ë¡œì»¬ ê¸°ë³¸ ê²½ë¡œ\n",
    "\n",
    "# ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "packages = [\n",
    "    \"ultralytics\",\n",
    "    \"torch\", \n",
    "    \"torchvision\",\n",
    "    \"opencv-python\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"roboflow\"  # ë°ì´í„°ì…‹ ê´€ë¦¬ìš© ì¶”ê°€\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"\\nğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´:\")\n",
    "print(f\"  Python: {sys.version.split()[0]}\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  CUDA ì‚¬ìš©ê°€ëŠ¥: {'âœ…' if torch.cuda.is_available() else 'âŒ'}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  GPU: {gpu_name}\")\n",
    "    print(f\"  GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"  ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"  âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# ğŸ† ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ìë™ íƒì§€ (ê°•í™”ëœ ë²„ì „)\n",
    "print(f\"\\nğŸ” ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ íƒì§€:\")\n",
    "\n",
    "def find_best_model():\n",
    "    \"\"\"ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ëŠ” í–¥ìƒëœ í•¨ìˆ˜\"\"\"\n",
    "    # ìš°ì„ ìˆœìœ„ë³„ ëª¨ë¸ ê²€ìƒ‰ ê²½ë¡œ\n",
    "    search_priorities = [\n",
    "        # 1ìˆœìœ„: ìµœì‹  í•™ìŠµ ê²°ê³¼ (í”¼í•´ëª© íƒì§€ ì „ìš©)\n",
    "        {\n",
    "            'priority': 1,\n",
    "            'description': 'ìµœì‹  í”¼í•´ëª© íƒì§€ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "                '/content/pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/results/damage_detection_*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/best.pt'\n",
    "            ]\n",
    "        },\n",
    "        # 2ìˆœìœ„: ì¼ë°˜ í•™ìŠµ ê²°ê³¼\n",
    "        {\n",
    "            'priority': 2,\n",
    "            'description': 'ì¼ë°˜ í•™ìŠµ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'runs/detect/train*/weights/best.pt',\n",
    "                '/content/runs/detect/train*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/runs/detect/train*/weights/best.pt',\n",
    "            ]\n",
    "        },\n",
    "        # 3ìˆœìœ„: ìˆ˜ë™ ì €ì¥ ëª¨ë¸\n",
    "        {\n",
    "            'priority': 3,\n",
    "            'description': 'ìˆ˜ë™ ì €ì¥ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                '/content/drive/MyDrive/pinetree_scan/models/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/weights/best.pt',\n",
    "                'models/best.pt',\n",
    "                'weights/best.pt',\n",
    "                '/content/best.pt'\n",
    "            ]\n",
    "        },\n",
    "        # 4ìˆœìœ„: ê¸°ë³¸ ëª¨ë¸\n",
    "        {\n",
    "            'priority': 4,\n",
    "            'description': 'ê¸°ë³¸ YOLO ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'yolo11s.pt',\n",
    "                '/content/yolo11s.pt'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    found_models = []\n",
    "    \n",
    "    for priority_group in search_priorities:\n",
    "        for pattern in priority_group['patterns']:\n",
    "            if '*' in pattern:\n",
    "                matches = glob.glob(pattern)\n",
    "                for match in matches:\n",
    "                    if os.path.exists(match):\n",
    "                        found_models.append({\n",
    "                            'path': match,\n",
    "                            'priority': priority_group['priority'],\n",
    "                            'description': priority_group['description'],\n",
    "                            'size': os.path.getsize(match) / 1024 / 1024,  # MB\n",
    "                            'modified': os.path.getctime(match)\n",
    "                        })\n",
    "            else:\n",
    "                if os.path.exists(pattern):\n",
    "                    found_models.append({\n",
    "                        'path': pattern,\n",
    "                        'priority': priority_group['priority'],\n",
    "                        'description': priority_group['description'],\n",
    "                        'size': os.path.getsize(pattern) / 1024 / 1024,  # MB\n",
    "                        'modified': os.path.getctime(pattern)\n",
    "                    })\n",
    "    \n",
    "    if found_models:\n",
    "        # ìš°ì„ ìˆœìœ„ì™€ ìˆ˜ì •ì‹œê°„ìœ¼ë¡œ ì •ë ¬\n",
    "        found_models.sort(key=lambda x: (x['priority'], -x['modified']))\n",
    "        return found_models\n",
    "    \n",
    "    return None\n",
    "\n",
    "# ëª¨ë¸ ê²€ìƒ‰ ì‹¤í–‰\n",
    "found_models = find_best_model()\n",
    "\n",
    "if found_models:\n",
    "    print(f\"ğŸ¯ ë°œê²¬ëœ ëª¨ë¸: {len(found_models)}ê°œ\")\n",
    "    \n",
    "    # ìƒìœ„ 3ê°œ ëª¨ë¸ í‘œì‹œ\n",
    "    for i, model_info in enumerate(found_models[:3]):\n",
    "        emoji = \"ğŸ†\" if i == 0 else \"ğŸ¥ˆ\" if i == 1 else \"ğŸ¥‰\"\n",
    "        print(f\"  {emoji} {model_info['description']}\")\n",
    "        print(f\"     ê²½ë¡œ: {model_info['path']}\")\n",
    "        print(f\"     í¬ê¸°: {model_info['size']:.1f}MB\")\n",
    "        print(f\"     ìˆ˜ì •: {datetime.fromtimestamp(model_info['modified']).strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ\n",
    "        if i == 0:\n",
    "            selected_model = model_info['path']\n",
    "    \n",
    "    # ì„ íƒëœ ëª¨ë¸ ë¡œë“œ ë° ê²€ì¦\n",
    "    print(f\"\\nğŸ“¥ ì„ íƒëœ ëª¨ë¸ ë¡œë“œ: {os.path.basename(selected_model)}\")\n",
    "    \n",
    "    try:\n",
    "        temp_model = YOLO(selected_model)\n",
    "        \n",
    "        # ëª¨ë¸ ì •ë³´ í™•ì¸\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "        print(f\"  ğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "        \n",
    "        if hasattr(temp_model, 'model') and hasattr(temp_model.model, 'names'):\n",
    "            class_names = list(temp_model.model.names.values())\n",
    "            print(f\"    ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}\")\n",
    "            print(f\"    ğŸ·ï¸ í´ë˜ìŠ¤ëª…: {class_names}\")\n",
    "            \n",
    "            # ì†Œë‚˜ë¬´/í”¼í•´ëª© ê´€ë ¨ í´ë˜ìŠ¤ í™•ì¸\n",
    "            pine_related = any(keyword in ' '.join(class_names).lower() \n",
    "                             for keyword in ['pine', 'damage', 'tree', 'í”¼í•´', 'ì†Œë‚˜ë¬´', 'damaged'])\n",
    "            \n",
    "            if pine_related:\n",
    "                print(f\"    ğŸŒ² ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ìš© ëª¨ë¸ í™•ì¸!\")\n",
    "            else:\n",
    "                print(f\"    âš ï¸ ì¼ë°˜ ê°ì²´ íƒì§€ ëª¨ë¸ (ì „ì´í•™ìŠµ ì˜ˆì •)\")\n",
    "        \n",
    "        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ë³´\n",
    "        try:\n",
    "            model_yaml = temp_model.model.yaml\n",
    "            if 'backbone' in str(model_yaml):\n",
    "                print(f\"    ğŸ—ï¸ ì•„í‚¤í…ì²˜: YOLOv11s\")\n",
    "        except:\n",
    "            print(f\"    ğŸ—ï¸ ì•„í‚¤í…ì²˜: YOLO ê³„ì—´\")\n",
    "            \n",
    "        existing_model = selected_model\n",
    "        del temp_model  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ğŸ“¥ ê¸°ë³¸ YOLOv11s ëª¨ë¸ë¡œ ëŒ€ì²´\")\n",
    "        existing_model = 'yolo11s.pt'\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ê¸°ì¡´ í•™ìŠµ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ“¥ ê¸°ë³¸ YOLOv11s ëª¨ë¸ ì‚¬ìš©\")\n",
    "    existing_model = 'yolo11s.pt'\n",
    "\n",
    "# ğŸ¯ ëª¨ë¸ ì‚¬ìš© ê³„íš ì•ˆë‚´\n",
    "print(f\"\\nğŸ¯ ëª¨ë¸ ì‚¬ìš© ê³„íš:\")\n",
    "if 'yolo11s.pt' in existing_model:\n",
    "    print(f\"  ğŸ“ ê¸°ë³¸ YOLOv11s â†’ ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ì´í•™ìŠµ\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 1-2ì‹œê°„ (ì²˜ìŒë¶€í„°)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 85-95% mAP50\")\n",
    "elif 'damage_detection' in existing_model:\n",
    "    print(f\"  ğŸ“ ê¸°ì¡´ í”¼í•´ëª© ëª¨ë¸ â†’ ì¶”ê°€ í•™ìŠµ/ë¯¸ì„¸ì¡°ì •\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 30ë¶„-1ì‹œê°„ (ë¯¸ì„¸ì¡°ì •)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 90-98% mAP50\")\n",
    "else:\n",
    "    print(f\"  ğŸ“ ê¸°ì¡´ ëª¨ë¸ â†’ ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ì´í•™ìŠµ\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 1ì‹œê°„ (ì „ì´í•™ìŠµ)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 87-95% mAP50\")\n",
    "\n",
    "# ğŸ—‚ï¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "if IN_COLAB:\n",
    "    output_base = '/content/drive/MyDrive/pinetree_scan/results'\n",
    "else:\n",
    "    output_base = './results'\n",
    "\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "print(f\"\\nğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_base}\")\n",
    "\n",
    "# ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸\n",
    "data_yaml_path = f\"{data_path}/data.yaml\"\n",
    "if os.path.exists(data_yaml_path):\n",
    "    print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:\")\n",
    "    try:\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(f\"  ğŸ“„ data.yaml ë‚´ìš© í™•ì¸ë¨\")\n",
    "            if 'names:' in content:\n",
    "                print(f\"  ğŸ·ï¸ í´ë˜ìŠ¤ ì •ë³´ í¬í•¨ë¨\")\n",
    "    except:\n",
    "        print(f\"  âš ï¸ data.yaml ì½ê¸° ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ë°ì´í„°ì…‹ íŒŒì¼ ì—†ìŒ: {data_yaml_path}\")\n",
    "    print(\"ğŸ“‹ data.yaml íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "globals()['existing_model'] = existing_model\n",
    "globals()['data_path'] = data_path\n",
    "globals()['output_base'] = output_base\n",
    "globals()['IN_COLAB'] = IN_COLAB\n",
    "globals()['found_models'] = found_models\n",
    "\n",
    "print(f\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"  ğŸ† ì‚¬ìš©í•  ëª¨ë¸: {os.path.basename(existing_model)}\")\n",
    "print(f\"  ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {existing_model}\")\n",
    "print(f\"  ğŸ“Š ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "print(f\"  ğŸ“ ê²°ê³¼ ê²½ë¡œ: {output_base}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e6d7f",
   "metadata": {},
   "source": [
    "## ğŸ“Š **1.5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ (ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™”)**\n",
    "\n",
    "> ê°œë³„ ì†Œë‚˜ë¬´ íƒì§€ë¥¼ ìœ„í•´ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ë¥¼ 24pxë¡œ ìµœì í™”í•©ë‹ˆë‹¤.  \n",
    "> ê¸°ì¡´ 64pxì—ì„œ 24pxë¡œ ì¤„ì—¬ í•œ ë°•ìŠ¤ë‹¹ í•˜ë‚˜ì˜ ë‚˜ë¬´ë§Œ í¬í•¨ë˜ë„ë¡ ì¡°ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š 1.5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ (ë°”ìš´ë”© ë°•ìŠ¤ 24px ìµœì í™”)\n",
    "print(\"ğŸ“Š í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘!\")\n",
    "print(\"ğŸ¯ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ë¥¼ 24pxë¡œ ìµœì í™” (ê°œë³„ ë‚˜ë¬´ íƒì§€)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "if 'data_path' not in globals():\n",
    "    data_path = '/content/training_data'\n",
    "\n",
    "# ğŸ“‹ ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™” ì„¤ì •\n",
    "BBOX_CONFIG = {\n",
    "    'size': 24,  # 24x24 í”½ì…€ (ê¸°ì¡´ 64pxì—ì„œ ì¶•ì†Œ)\n",
    "    'overlap': 0.2,  # 20% ê²¹ì¹¨\n",
    "    'min_tree_size': 12,  # ìµœì†Œ ë‚˜ë¬´ í¬ê¸° (í”½ì…€)\n",
    "    'max_tree_size': 36,  # ìµœëŒ€ ë‚˜ë¬´ í¬ê¸° (í”½ì…€)\n",
    "}\n",
    "\n",
    "print(f\"ğŸ¯ ë°”ìš´ë”© ë°•ìŠ¤ ì„¤ì •:\")\n",
    "print(f\"  ğŸ“ í¬ê¸°: {BBOX_CONFIG['size']}x{BBOX_CONFIG['size']} í”½ì…€\")\n",
    "print(f\"  ğŸ”„ ê²¹ì¹¨ë¥ : {BBOX_CONFIG['overlap']*100}%\")\n",
    "print(f\"  ğŸŒ² ë‚˜ë¬´ í¬ê¸° ë²”ìœ„: {BBOX_CONFIG['min_tree_size']}-{BBOX_CONFIG['max_tree_size']} í”½ì…€\")\n",
    "\n",
    "# ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def preprocess_training_data(data_path, bbox_size=24):\n",
    "    \"\"\"\n",
    "    í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ - ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ìµœì í™”\n",
    "    \"\"\"\n",
    "    import yaml\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(f\"ğŸ“‚ ë°ì´í„° ê²½ë¡œ í™•ì¸: {data_path}\")\n",
    "    \n",
    "    # ê¸°ì¡´ ë°ì´í„° ë°±ì—…\n",
    "    if os.path.exists(data_path):\n",
    "        backup_path = f\"{data_path}_backup_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "        if not os.path.exists(backup_path):\n",
    "            shutil.copytree(data_path, backup_path)\n",
    "            print(f\"ğŸ’¾ ê¸°ì¡´ ë°ì´í„° ë°±ì—…: {backup_path}\")\n",
    "    \n",
    "    # data.yaml íŒŒì¼ í™•ì¸ ë° ìƒì„±\n",
    "    data_yaml_path = f\"{data_path}/data.yaml\"\n",
    "    \n",
    "    if not os.path.exists(data_yaml_path):\n",
    "        print(\"ğŸ“ data.yaml íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ê¸°ë³¸ data.yaml ìƒì„±\n",
    "        data_config = {\n",
    "            'path': data_path,\n",
    "            'train': f\"{data_path}/train/images\",\n",
    "            'val': f\"{data_path}/val/images\",  # ê²€ì¦ìš©\n",
    "            'test': f\"{data_path}/val/images\",  # í…ŒìŠ¤íŠ¸ìš© (valê³¼ ë™ì¼)\n",
    "            'nc': 1,  # í´ë˜ìŠ¤ ìˆ˜ (ì†Œë‚˜ë¬´ í”¼í•´ëª©)\n",
    "            'names': ['damaged_pine'],  # í´ë˜ìŠ¤ ì´ë¦„\n",
    "            \n",
    "            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°\n",
    "            'bbox_size': bbox_size,\n",
    "            'created_date': datetime.now().isoformat(),\n",
    "            'description': 'Pine tree damage detection dataset with optimized 24px bounding boxes'\n",
    "        }\n",
    "        \n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "        with open(data_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"âœ… data.yaml ìƒì„± ì™„ë£Œ: {data_yaml_path}\")\n",
    "    else:\n",
    "        print(f\"âœ… ê¸°ì¡´ data.yaml ì‚¬ìš©: {data_yaml_path}\")\n",
    "        \n",
    "        # ê¸°ì¡´ íŒŒì¼ì— bbox_size ì„¤ì • ì¶”ê°€\n",
    "        try:\n",
    "            with open(data_yaml_path, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            \n",
    "            # ê²½ë¡œ ì„¤ì • í™•ì¸ ë° ìˆ˜ì •\n",
    "            data_config['path'] = data_path\n",
    "            \n",
    "            # YOLO í‘œì¤€ êµ¬ì¡° í™•ì¸ í›„ ê²½ë¡œ ì„¤ì •\n",
    "            if os.path.exists(f\"{data_path}/train/images\"):\n",
    "                print(\"ğŸ”§ YOLO í‘œì¤€ êµ¬ì¡°ë¡œ ê²½ë¡œ ì„¤ì •\")\n",
    "                data_config['train'] = f\"{data_path}/train/images\"\n",
    "                data_config['val'] = f\"{data_path}/val/images\"\n",
    "                data_config['test'] = f\"{data_path}/val/images\"\n",
    "            else:\n",
    "                print(\"ğŸ”§ ë‹¨ìˆœ êµ¬ì¡°ë¡œ ê²½ë¡œ ì„¤ì •\")\n",
    "                data_config['train'] = f\"{data_path}/images\"\n",
    "                data_config['val'] = f\"{data_path}/images\"\n",
    "                data_config['test'] = f\"{data_path}/images\"\n",
    "            \n",
    "            if 'bbox_size' not in data_config:\n",
    "                data_config['bbox_size'] = bbox_size\n",
    "                data_config['updated_date'] = datetime.now().isoformat()\n",
    "                print(f\"ğŸ”§ data.yamlì— bbox_size={bbox_size} ì„¤ì • ì¶”ê°€\")\n",
    "            \n",
    "            # ì—…ë°ì´íŠ¸ëœ ì„¤ì • ì €ì¥\n",
    "            with open(data_yaml_path, 'w') as f:\n",
    "                yaml.dump(data_config, f, default_flow_style=False)\n",
    "            print(f\"ğŸ”§ data.yaml ê²½ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ data.yaml ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    required_dirs = ['images', 'labels']\n",
    "    for dir_name in required_dirs:\n",
    "        dir_path = f\"{data_path}/{dir_name}\"\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"ğŸ“ ë””ë ‰í† ë¦¬ í™•ì¸: {dir_path}\")\n",
    "    \n",
    "    return data_yaml_path\n",
    "\n",
    "# ğŸ› ï¸ ë°”ìš´ë”© ë°•ìŠ¤ ë¼ë²¨ ìµœì í™” í•¨ìˆ˜\n",
    "def optimize_bbox_labels(data_path, target_size=24):\n",
    "    \"\"\"\n",
    "    ê¸°ì¡´ ë¼ë²¨ íŒŒì¼ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ë¥¼ ìµœì í™”\n",
    "    \"\"\"\n",
    "    # YOLO í‘œì¤€ êµ¬ì¡° í™•ì¸\n",
    "    train_labels_dir = f\"{data_path}/train/labels\"\n",
    "    val_labels_dir = f\"{data_path}/val/labels\"\n",
    "    simple_labels_dir = f\"{data_path}/labels\"\n",
    "    \n",
    "    label_dirs = []\n",
    "    \n",
    "    # ì¡´ì¬í•˜ëŠ” ë¼ë²¨ ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
    "    if os.path.exists(train_labels_dir):\n",
    "        label_dirs.append(train_labels_dir)\n",
    "    if os.path.exists(val_labels_dir):\n",
    "        label_dirs.append(val_labels_dir)\n",
    "    if os.path.exists(simple_labels_dir):\n",
    "        label_dirs.append(simple_labels_dir)\n",
    "    \n",
    "    if not label_dirs:\n",
    "        print(f\"âš ï¸ ë¼ë²¨ ë””ë ‰í† ë¦¬ ì—†ìŒ\")\n",
    "        return False\n",
    "    \n",
    "    import glob\n",
    "    total_optimized = 0\n",
    "    total_files = 0\n",
    "    \n",
    "    for labels_dir in label_dirs:\n",
    "        print(f\"ğŸ”§ ë¼ë²¨ ìµœì í™”: {labels_dir}\")\n",
    "        \n",
    "        label_files = glob.glob(f\"{labels_dir}/*.txt\")\n",
    "        \n",
    "        if not label_files:\n",
    "            print(f\"  âš ï¸ ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {labels_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ğŸ“‹ ë¼ë²¨ íŒŒì¼: {len(label_files)}ê°œ\")\n",
    "        total_files += len(label_files)\n",
    "        \n",
    "        optimized_count = 0\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            try:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                optimized_lines = []\n",
    "                modified = False\n",
    "                \n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id, x_center, y_center, width, height = parts[:5]\n",
    "                        \n",
    "                        # í˜„ì¬ í¬ê¸°ë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ê°€ì • (640x640 ê¸°ì¤€)\n",
    "                        current_width = float(width) * 640\n",
    "                        current_height = float(height) * 640\n",
    "                        \n",
    "                        # í¬ê¸°ê°€ target_sizeë³´ë‹¤ í° ê²½ìš° ì¡°ì •\n",
    "                        if current_width > target_size or current_height > target_size:\n",
    "                            # target_sizeë¡œ ì •ê·œí™”\n",
    "                            new_width = min(target_size / 640, float(width))\n",
    "                            new_height = min(target_size / 640, float(height))\n",
    "                            \n",
    "                            optimized_lines.append(f\"{class_id} {x_center} {y_center} {new_width:.6f} {new_height:.6f}\\n\")\n",
    "                            modified = True\n",
    "                        else:\n",
    "                            optimized_lines.append(line)\n",
    "                    else:\n",
    "                        optimized_lines.append(line)\n",
    "                \n",
    "                if modified:\n",
    "                    with open(label_file, 'w') as f:\n",
    "                        f.writelines(optimized_lines)\n",
    "                    optimized_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸ ë¼ë²¨ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {label_file}: {e}\")\n",
    "        \n",
    "        print(f\"  âœ… ìµœì í™” ì™„ë£Œ: {optimized_count}/{len(label_files)}ê°œ\")\n",
    "        total_optimized += optimized_count\n",
    "    \n",
    "    print(f\"ğŸ¯ ì „ì²´ ë¼ë²¨ ìµœì í™” ê²°ê³¼: {total_optimized}/{total_files}ê°œ íŒŒì¼ ìˆ˜ì •ë¨\")\n",
    "    return True\n",
    "\n",
    "# ğŸ“Š ì‹¤ì œ ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "try:\n",
    "    # Step 1: ë°ì´í„° êµ¬ì¡° ì¤€ë¹„\n",
    "    processed_data_yaml = preprocess_training_data(data_path, BBOX_CONFIG['size'])\n",
    "    \n",
    "    # Step 2: ê¸°ì¡´ ë¼ë²¨ ìµœì í™” (ìˆëŠ” ê²½ìš°)\n",
    "    optimize_bbox_labels(data_path, BBOX_CONFIG['size'])\n",
    "    \n",
    "    # Step 3: ë°ì´í„°ì…‹ í†µê³„ í™•ì¸\n",
    "    images_dir = f\"{data_path}/images\"\n",
    "    labels_dir = f\"{data_path}/labels\"\n",
    "    train_images_dir = f\"{data_path}/train/images\"\n",
    "    train_labels_dir = f\"{data_path}/train/labels\"\n",
    "    val_images_dir = f\"{data_path}/val/images\"\n",
    "    val_labels_dir = f\"{data_path}/val/labels\"\n",
    "    \n",
    "    image_count = 0\n",
    "    label_count = 0\n",
    "    \n",
    "    # YOLO í‘œì¤€ êµ¬ì¡° í™•ì¸ (train/val í´ë”)\n",
    "    if os.path.exists(train_images_dir) or os.path.exists(val_images_dir):\n",
    "        print(\"ğŸ“ YOLO í‘œì¤€ êµ¬ì¡° ê°ì§€ë¨ (train/val)\")\n",
    "        \n",
    "        # train í´ë” í™•ì¸\n",
    "        if os.path.exists(train_images_dir):\n",
    "            import glob\n",
    "            for ext in ['jpg', 'jpeg', 'png', 'tif', 'tiff']:\n",
    "                pattern = f\"{train_images_dir}/*.{ext}\"\n",
    "                files = glob.glob(pattern)\n",
    "                image_count += len(files)\n",
    "        \n",
    "        if os.path.exists(train_labels_dir):\n",
    "            label_files = glob.glob(f\"{train_labels_dir}/*.txt\")\n",
    "            label_count += len(label_files)\n",
    "        \n",
    "        # val í´ë” í™•ì¸\n",
    "        if os.path.exists(val_images_dir):\n",
    "            for ext in ['jpg', 'jpeg', 'png', 'tif', 'tiff']:\n",
    "                pattern = f\"{val_images_dir}/*.{ext}\"\n",
    "                files = glob.glob(pattern)\n",
    "                image_count += len(files)\n",
    "        \n",
    "        if os.path.exists(val_labels_dir):\n",
    "            label_files = glob.glob(f\"{val_labels_dir}/*.txt\")\n",
    "            label_count += len(label_files)\n",
    "            \n",
    "        print(f\"ğŸ“¸ ì´ë¯¸ì§€ íŒŒì¼: {image_count}ê°œ (train + val)\")\n",
    "        print(f\"ğŸ·ï¸ ë¼ë²¨ íŒŒì¼: {label_count}ê°œ (train + val)\")\n",
    "        \n",
    "    # ë‹¨ìˆœ êµ¬ì¡° í™•ì¸ (images/labels í´ë”)\n",
    "    elif os.path.exists(images_dir):\n",
    "        print(\"ğŸ“ ë‹¨ìˆœ êµ¬ì¡° ê°ì§€ë¨ (images/labels)\")\n",
    "        \n",
    "        import glob\n",
    "        for ext in ['jpg', 'jpeg', 'png', 'tif', 'tiff']:\n",
    "            pattern = f\"{images_dir}/*.{ext}\"\n",
    "            files = glob.glob(pattern)\n",
    "            image_count += len(files)\n",
    "            \n",
    "        print(f\"ğŸ“¸ ì´ë¯¸ì§€ íŒŒì¼: {image_count}ê°œ\")\n",
    "    else:\n",
    "        print(f\"ğŸ“¸ ì´ë¯¸ì§€ íŒŒì¼: ì—†ìŒ (ì¶”í›„ ì—…ë¡œë“œ í•„ìš”)\")\n",
    "    \n",
    "    if os.path.exists(labels_dir):\n",
    "        label_files = glob.glob(f\"{labels_dir}/*.txt\")\n",
    "        label_count = len(label_files)\n",
    "        print(f\"ğŸ·ï¸ ë¼ë²¨ íŒŒì¼: {label_count}ê°œ\")\n",
    "    else:\n",
    "        print(f\"ğŸ·ï¸ ë¼ë²¨ íŒŒì¼: ì—†ìŒ (ì¶”í›„ ìƒì„± í•„ìš”)\")\n",
    "    \n",
    "    # Step 4: ìµœì¢… ì„¤ì • í™•ì¸\n",
    "    print(f\"\\nğŸ“‹ ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½:\")\n",
    "    print(f\"  ğŸ“‚ ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "    print(f\"  ğŸ“„ ì„¤ì • íŒŒì¼: {processed_data_yaml}\")\n",
    "    print(f\"  ğŸ“ ë°”ìš´ë”© ë°•ìŠ¤: {BBOX_CONFIG['size']}px (ìµœì í™”ë¨)\")\n",
    "    print(f\"  ğŸ¯ ê°œë³„ ë‚˜ë¬´ íƒì§€: í™œì„±í™”\")\n",
    "    \n",
    "    # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "    globals()['data_path'] = data_path\n",
    "    globals()['processed_data_yaml'] = processed_data_yaml\n",
    "    globals()['bbox_optimized'] = True\n",
    "    \n",
    "    preprocessing_completed = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "    print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
    "    print(f\"  1. Google Driveì— training_data í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(f\"  2. images/ ë° labels/ í´ë” êµ¬ì¡° í™•ì¸\")\n",
    "    print(f\"  3. íŒŒì¼ ê¶Œí•œ í™•ì¸\")\n",
    "    print(f\"  4. ê²½ë¡œ ì„¤ì • ì¬í™•ì¸\")\n",
    "    \n",
    "    preprocessing_completed = False\n",
    "\n",
    "# ğŸ’¡ ì‚¬ìš©ì ì•ˆë‚´\n",
    "print(f\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´:\")\n",
    "\n",
    "if preprocessing_completed:\n",
    "    print(f\"  âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ë‹¤ìŒ ì…€(2ë‹¨ê³„)ë¡œ ì§„í–‰í•˜ì„¸ìš”.\")\n",
    "    print(f\"  ğŸ¯ 24px ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ê°œë³„ ë‚˜ë¬´ íƒì§€ ìµœì í™”ë¨\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  ì¬ì‹œë„í•˜ì„¸ìš”.\")\n",
    "    print(f\"  ğŸ“‹ í•„ìš”í•œ ë°ì´í„° êµ¬ì¡°:\")\n",
    "    print(f\"    ğŸ“‚ training_data/\")\n",
    "    print(f\"      ğŸ“„ data.yaml\")\n",
    "    print(f\"      ğŸ“‚ images/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤)\")\n",
    "    print(f\"      ğŸ“‚ labels/ (ë¼ë²¨ íŒŒì¼ë“¤)\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™” íš¨ê³¼:\")\n",
    "print(f\"  ğŸ¯ ê¸°ì¡´ 64px â†’ 24px: ê°œë³„ ë‚˜ë¬´ íƒì§€ í–¥ìƒ\")\n",
    "print(f\"  ğŸ” ì˜¤íƒì§€ ê°ì†Œ: í•œ ë°•ìŠ¤ë‹¹ í•˜ë‚˜ì˜ ë‚˜ë¬´\")\n",
    "print(f\"  ğŸ“Š ì •í™•ë„ í–¥ìƒ: ë” ì •ë°€í•œ ìœ„ì¹˜ íƒì§€\")\n",
    "print(f\"  âš¡ í•™ìŠµ íš¨ìœ¨ì„±: ìµœì í™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°\")\n",
    "\n",
    "globals()['preprocessing_completed'] = preprocessing_completed\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3021b",
   "metadata": {},
   "source": [
    "## ğŸš€ **2ë‹¨ê³„: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ**\n",
    "\n",
    "> ê¸°ì¡´ ëª¨ë¸ì„ í™œìš©í•œ ì „ì´í•™ìŠµìœ¼ë¡œ ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.  \n",
    "> **ë„¤ì´ë°**: `damage_detection_YYYYMMDD_HHMM` í˜•ì‹ìœ¼ë¡œ ìë™ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ 2ë‹¨ê³„: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ ì‹¤í–‰\n",
    "print(\"ğŸŒ² YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"ğŸ¯ 24px ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™” + ì „ì´í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë° ì „ì²˜ë¦¬ ê²°ê³¼ í™•ì¸\n",
    "if 'existing_model' not in globals():\n",
    "    print(\"âš ï¸ í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 1ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "    existing_model = 'yolo11s.pt'\n",
    "\n",
    "if 'preprocessing_completed' not in globals():\n",
    "    print(\"âš ï¸ ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 1.5ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "    data_path = '/content/training_data'\n",
    "    bbox_optimized = False\n",
    "else:\n",
    "    bbox_optimized = globals().get('bbox_optimized', False)\n",
    "\n",
    "if 'processed_data_yaml' in globals():\n",
    "    data_yaml_path = processed_data_yaml\n",
    "else:\n",
    "    data_yaml_path = f\"{globals().get('data_path', '/content/training_data')}/data.yaml\"\n",
    "\n",
    "# ğŸ“Š ë°ì´í„°ì…‹ ìµœì¢… í™•ì¸\n",
    "print(f\"ğŸ“Š ë°ì´í„°ì…‹ í™•ì¸: {data_yaml_path}\")\n",
    "print(f\"ğŸ¯ ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™”: {'âœ… 24px ì ìš©ë¨' if bbox_optimized else 'âš ï¸ ê¸°ë³¸ ì„¤ì •'}\")\n",
    "\n",
    "if not os.path.exists(data_yaml_path):\n",
    "    print(\"âŒ data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ“‹ ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:\")\n",
    "    search_paths = [\n",
    "        '/content/training_data/data.yaml',\n",
    "        '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml',\n",
    "        '/content/drive/MyDrive/training_data/data.yaml',\n",
    "        './data/data.yaml'\n",
    "    ]\n",
    "    \n",
    "    for path in search_paths:\n",
    "        exists = \"âœ…\" if os.path.exists(path) else \"âŒ\"\n",
    "        print(f\"  {exists} {path}\")\n",
    "    \n",
    "    print(\"\\nğŸ”§ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"  1. 1.5ë‹¨ê³„ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "    print(\"  2. Google Driveì— training_data í´ë” ì—…ë¡œë“œ\")\n",
    "    print(\"  3. data.yaml, images/, labels/ í´ë” í¬í•¨ í™•ì¸\")\n",
    "    \n",
    "    # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ë˜ ê²½ê³  í‘œì‹œ\n",
    "    data_yaml_path = '/content/training_data/data.yaml'\n",
    "    print(f\"âš ï¸ ê¸°ë³¸ ê²½ë¡œë¡œ ì„¤ì •: {data_yaml_path}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    print(f\"ğŸ“¥ ëª¨ë¸ ë¡œë“œ: {existing_model}\")\n",
    "    model = YOLO(existing_model)\n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "    \n",
    "    # ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "    try:\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'names'):\n",
    "            print(f\"ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜: {len(model.model.names)}\")\n",
    "            print(f\"ğŸ·ï¸ í´ë˜ìŠ¤: {list(model.model.names.values())}\")\n",
    "    except:\n",
    "        print(\"ğŸ“ ëª¨ë¸ ì •ë³´ í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    model_ready = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ”§ ê¸°ë³¸ YOLOv11s ëª¨ë¸ë¡œ ì¬ì‹œë„...\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO('yolo11s.pt')\n",
    "        print(\"âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "        existing_model = 'yolo11s.pt'\n",
    "        model_ready = True\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ ê¸°ë³¸ ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {e2}\")\n",
    "        model_ready = False\n",
    "\n",
    "if model_ready:\n",
    "    # GPU ì„¤ì •\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"ğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device.upper()}\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        available_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ GPU ë©”ëª¨ë¦¬: {available_memory:.1f}GB\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •\n",
    "        if available_memory >= 15:\n",
    "            batch_size = 16\n",
    "        elif available_memory >= 8:\n",
    "            batch_size = 8\n",
    "        else:\n",
    "            batch_size = 4\n",
    "    else:\n",
    "        batch_size = 2\n",
    "        print(\"âš ï¸ CPU ëª¨ë“œ: í•™ìŠµ ì†ë„ê°€ ë§¤ìš° ëŠë ¤ì§‘ë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ğŸŒ² ì†Œë‚˜ë¬´ ì „ìš© ìµœì í™” í•™ìŠµ ì„¤ì • (24px ë°”ìš´ë”© ë°•ìŠ¤ íŠ¹í™”)\n",
    "    training_config = {\n",
    "        # ê¸°ë³¸ ì„¤ì •\n",
    "        'data': data_yaml_path,  # ë™ì  ê²½ë¡œ ì‚¬ìš©\n",
    "        'epochs': 200,\n",
    "        'batch': batch_size,  # ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ìë™ ì¡°ì •\n",
    "        'imgsz': 640,\n",
    "        'patience': 100,\n",
    "        'save': True,\n",
    "        'save_period': 10,\n",
    "        'cache': 'ram' if device == 'cuda' else False,  # GPUì¼ ë•Œë§Œ RAM ìºì‹œ\n",
    "        'device': device,\n",
    "        'workers': 4 if device == 'cuda' else 2,\n",
    "        \n",
    "        # ğŸ¯ ìš”ì²­ëœ ë„¤ì´ë° ê·œì¹™ (24px ìµœì í™” í‘œì‹œ)\n",
    "        'project': 'pinetree_yolov11s',  # í”„ë¡œì íŠ¸ëª… ìœ ì§€\n",
    "        'name': f'damage_detection_24px_{datetime.now().strftime(\"%Y%m%d_%H%M\")}',\n",
    "        \n",
    "        # 24px ë°”ìš´ë”© ë°•ìŠ¤ íŠ¹í™” ì „ì´í•™ìŠµ ìµœì í™”\n",
    "        'optimizer': 'AdamW',\n",
    "        'lr0': 0.0002,              # ì‘ì€ ë°”ìš´ë”© ë°•ìŠ¤ìš© ë‚®ì€ í•™ìŠµë¥ \n",
    "        'lrf': 0.01,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0003,     # ê³¼ì í•© ë°©ì§€ ê°•í™”\n",
    "        'warmup_epochs': 20,        # ì•ˆì •ì  í•™ìŠµì„ ìœ„í•œ ê¸´ ì›Œë°ì—…\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.005,\n",
    "        \n",
    "        # 24px ì†Œë‚˜ë¬´ íŠ¹í™” ì†ì‹¤ í•¨ìˆ˜ (ê°œë³„ ë‚˜ë¬´ íƒì§€ ìµœì í™”)\n",
    "        'box': 8.0,                 # ë°”ìš´ë”© ë°•ìŠ¤ ì •í™•ë„ ê°•í™”\n",
    "        'cls': 0.4,                 # ë¶„ë¥˜ ì†ì‹¤ ì ë‹¹íˆ\n",
    "        'dfl': 2.0,                 # ë¶„í¬ ì´ˆì  ì†ì‹¤ ê°•í™” (ì •ë°€í•œ ìœ„ì¹˜)\n",
    "        \n",
    "        # 24px ìµœì í™” ë°ì´í„° ì¦ê°• (ì‘ì€ ê°ì²´ìš©)\n",
    "        'hsv_h': 0.003,             # ì†Œë‚˜ë¬´ ê³ ìœ ìƒ‰ ë” ê°•í•˜ê²Œ ë³´ì¡´\n",
    "        'hsv_s': 0.2,               # ì±„ë„ ë³€í™” ìµœì†Œí™”\n",
    "        'hsv_v': 0.15,              # ë°ê¸° ë³€í™” ìµœì†Œí™”\n",
    "        'degrees': 0.0,             # íšŒì „ ë¹„í™œì„±í™” (ì‘ì€ ê°ì²´)\n",
    "        'translate': 0.03,          # ì´ë™ ìµœì†Œí™”\n",
    "        'scale': 0.1,               # ìŠ¤ì¼€ì¼ ë³€í™” ìµœì†Œí™” (24px ìœ ì§€)\n",
    "        'shear': 0.0,               # ì „ë‹¨ ë¹„í™œì„±í™”\n",
    "        'perspective': 0.0,         # ì›ê·¼ ë¹„í™œì„±í™”\n",
    "        'flipud': 0.0,              # ìƒí•˜ ë’¤ì§‘ê¸° ë¹„í™œì„±í™”\n",
    "        'fliplr': 0.2,              # ì¢Œìš° ë’¤ì§‘ê¸°ë§Œ ì•½ê°„\n",
    "        'mosaic': 0.3,              # ëª¨ìì´í¬ ì¤„ì„ (ì‘ì€ ê°ì²´ ë³´í˜¸)\n",
    "        'mixup': 0.0,               # ë¯¹ìŠ¤ì—… ë¹„í™œì„±í™”\n",
    "        'copy_paste': 0.0,          # ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ë¹„í™œì„±í™”\n",
    "        \n",
    "        # 24px ì•ˆì •ì„± ì„¤ì •\n",
    "        'amp': True if device == 'cuda' else False,\n",
    "        'fraction': 1.0,\n",
    "        'profile': False,\n",
    "        'freeze': None,\n",
    "        'dropout': 0.15,            # ê³¼ì í•© ë°©ì§€ ê°•í™”\n",
    "        'val': True,\n",
    "        'plots': True,\n",
    "        'save_json': True,\n",
    "        'verbose': True,\n",
    "        'seed': 42,\n",
    "        \n",
    "        # 24px ì†Œë‚˜ë¬´ ì „ìš© ì„¤ì •\n",
    "        'rect': False,\n",
    "        'single_cls': True,         # ë‹¨ì¼ í´ë˜ìŠ¤ (ì†Œë‚˜ë¬´ í”¼í•´ëª©)\n",
    "        'overlap_mask': True,\n",
    "        'mask_ratio': 2,            # ì‘ì€ ê°ì²´ìš© ë§ˆìŠ¤í¬ ë¹„ìœ¨\n",
    "        'cos_lr': True,\n",
    "        'close_mosaic': 75,         # ëª¨ìì´í¬ ì¼ì° ì¢…ë£Œ (ì‘ì€ ê°ì²´ ë³´í˜¸)\n",
    "        \n",
    "        # 24px ì˜¤íƒì§€ ë°©ì§€ ì„ê³„ê°’\n",
    "        'conf': 0.35,               # 24pxìš© ì ë‹¹í•œ ì‹ ë¢°ë„\n",
    "        'iou': 0.5,                 # ì‘ì€ ê°ì²´ìš© IoU\n",
    "    }\n",
    "    \n",
    "    # ì‹¤í–‰ëª… ë° ì„¤ì • ì¶œë ¥\n",
    "    run_name = f'damage_detection_24px_{datetime.now().strftime(\"%Y%m%d_%H%M\")}'\n",
    "    print(f\"\\nğŸ¯ 24px ìµœì í™” í•™ìŠµ ì„¤ì •:\")\n",
    "    print(f\"  ğŸ“‚ í”„ë¡œì íŠ¸: pinetree_yolov11s\")\n",
    "    print(f\"  ğŸ“… ì‹¤í–‰ëª…: {run_name}\")\n",
    "    print(f\"  ğŸ† ê¸°ì¡´ ëª¨ë¸: {existing_model}\")\n",
    "    print(f\"  ğŸ“Š ë°ì´í„°: {data_yaml_path}\")\n",
    "    print(f\"  ğŸ“ ë°”ìš´ë”© ë°•ìŠ¤: 24px (ê°œë³„ ë‚˜ë¬´ ìµœì í™”)\")\n",
    "    print(f\"  ğŸ¯ ë°°ì¹˜ í¬ê¸°: {batch_size} (ë©”ëª¨ë¦¬ ìë™ ì¡°ì •)\")\n",
    "    print(f\"  ğŸŒ² ì „ìš© ìµœì í™”: 24px ì†Œë‚˜ë¬´ íŠ¹í™” + ì˜¤íƒì§€ ë°©ì§€\")\n",
    "    print(f\"  ğŸ’¾ ìºì‹œ: {'RAM' if training_config['cache'] == 'ram' else 'Disk'}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¥ 24px ë°”ìš´ë”© ë°•ìŠ¤ ìµœì í™” í•™ìŠµ ì‹œì‘!\")\n",
    "    print(f\"â° ì˜ˆìƒ ì‹œê°„: 1-2ì‹œê°„ (GPU ì„±ëŠ¥ì— ë”°ë¼ ë³€ë™)\")\n",
    "    print(f\"ğŸ¯ ê°œë³„ ë‚˜ë¬´ íƒì§€ ì •í™•ë„ ê·¹ëŒ€í™”!\")\n",
    "    \n",
    "    try:\n",
    "        # í•™ìŠµ ì‹¤í–‰\n",
    "        results = model.train(**training_config)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ 24px ìµœì í™” í•™ìŠµ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“ˆ ìµœì¢… mAP50: {results.box.map50:.4f}\")\n",
    "        print(f\"ğŸ“ˆ ìµœì¢… mAP50-95: {results.box.map:.4f}\")\n",
    "        print(f\"ğŸ“ˆ Precision: {results.box.mp:.4f}\")\n",
    "        print(f\"ğŸ“ˆ Recall: {results.box.mr:.4f}\")\n",
    "        \n",
    "        # 24px ìµœì í™” ì„±ëŠ¥ í‰ê°€\n",
    "        if results.box.mp > 0.85:\n",
    "            print(\"ğŸŒŸ íƒì›”í•œ ì •ë°€ë„! 24px ìµœì í™”ë¡œ ì˜¤íƒì§€ ëŒ€í­ ê°ì†Œ!\")\n",
    "        elif results.box.mp > 0.7:\n",
    "            print(\"âœ… ìš°ìˆ˜í•œ ì •ë°€ë„! ê°œë³„ ë‚˜ë¬´ íƒì§€ ì„±ê³µ!\")\n",
    "        \n",
    "        if results.box.mr > 0.7:\n",
    "            print(\"ğŸŒŸ ë›°ì–´ë‚œ ì¬í˜„ìœ¨! ì‘ì€ í”¼í•´ëª©ë„ ë†“ì¹˜ì§€ ì•ŠìŒ!\")\n",
    "        elif results.box.mr > 0.5:\n",
    "            print(\"âœ… ì¢‹ì€ ì¬í˜„ìœ¨! í”¼í•´ëª© íƒì§€ ì„±ê³µ!\")\n",
    "        \n",
    "        if results.box.map50 > 0.9:\n",
    "            print(\"ğŸ† ìµœê³  ë“±ê¸‰ mAP50! 24px ìµœì í™” ëŒ€ì„±ê³µ!\")\n",
    "        elif results.box.map50 > 0.8:\n",
    "            print(\"ğŸŒŸ ìš°ìˆ˜í•œ mAP50! ì‹¤ìš©ì  ì„±ëŠ¥ ë‹¬ì„±!\")\n",
    "        \n",
    "        # ê²°ê³¼ë¥¼ Google Driveì— ë°±ì—… (Colab í™˜ê²½ì—ì„œ)\n",
    "        if 'IN_COLAB' in globals() and IN_COLAB:\n",
    "            try:\n",
    "                result_source = f\"pinetree_yolov11s/{run_name}\"\n",
    "                result_backup = f\"/content/drive/MyDrive/pinetree_scan/results/{run_name}\"\n",
    "                \n",
    "                if os.path.exists(result_source):\n",
    "                    import shutil\n",
    "                    shutil.copytree(result_source, result_backup, dirs_exist_ok=True)\n",
    "                    print(f\"ğŸ’¾ 24px ìµœì í™” ê²°ê³¼ë¥¼ Google Driveì— ë°±ì—…: {result_backup}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Drive ë°±ì—… ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        training_completed = True\n",
    "        training_results = results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í•™ìŠµ ì˜¤ë¥˜: {e}\")\n",
    "        print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
    "        print(f\"  1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸°ë¥¼ ë” ì¤„ì´ê¸° (batch=2)\")\n",
    "        print(f\"  2. ë°ì´í„° ê²½ë¡œ ì˜¤ë¥˜: 1.5ë‹¨ê³„ ì „ì²˜ë¦¬ ì¬ì‹¤í–‰\")\n",
    "        print(f\"  3. 24px ë°ì´í„° ë¬¸ì œ: data.yaml íŒŒì¼ í™•ì¸\")\n",
    "        print(f\"  4. ê¶Œí•œ ë¬¸ì œ: Google Drive ë§ˆìš´íŠ¸ ì¬ì‹œë„\")\n",
    "        print(f\"  5. ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ì¬ì‹œë„\")\n",
    "        \n",
    "        training_completed = False\n",
    "        training_results = None\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨\")\n",
    "    print(\"ğŸ”§ ë¬¸ì œ í•´ê²°:\")\n",
    "    print(\"  1. ì¸í„°ë„· ì—°ê²° í™•ì¸\")\n",
    "    print(\"  2. ultralytics íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜\")\n",
    "    print(\"  3. ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "    training_completed = False\n",
    "    training_results = None\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ ì„¤ì •\n",
    "globals()['training_completed'] = training_completed\n",
    "globals()['training_results'] = training_results\n",
    "if 'run_name' in locals():\n",
    "    globals()['run_name'] = run_name\n",
    "\n",
    "print(f\"\\nğŸ“‹ 24px ìµœì í™” í•™ìŠµ ìƒíƒœ: training_completed = {training_completed}\")\n",
    "print(f\"ğŸ¯ ê°œë³„ ë‚˜ë¬´ íƒì§€: {'âœ… ìµœì í™”ë¨' if bbox_optimized else 'âš ï¸ ê¸°ë³¸ ì„¤ì •'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2dafa",
   "metadata": {},
   "source": [
    "## ğŸ“Š **3ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”**\n",
    "\n",
    "> í•™ìŠµ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì„±ëŠ¥ ì§€í‘œ, í•™ìŠµ ê³¡ì„ , ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ea2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \udd0d 3ë‹¨ê³„: í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦\n",
    "print(\"\udd0d í•™ìŠµ ì™„ë£Œ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦!\")\n",
    "print(\"ğŸ“Š í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì´ì „ ë‹¨ê³„ í™•ì¸\n",
    "if not globals().get('training_completed', False):\n",
    "    print(\"âš ï¸ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ì¶”ë¡ ë§Œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "    \n",
    "    # ìµœì‹  ëª¨ë¸ ìë™ íƒì§€\n",
    "    best_model_path = None\n",
    "    search_paths = [\n",
    "        # í˜„ì¬ ë””ë ‰í† ë¦¬\n",
    "        './pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "        # Colab ê¸°ë³¸ ê²½ë¡œ\n",
    "        '/content/pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "        # Drive ë°±ì—… ê²½ë¡œ\n",
    "        '/content/drive/MyDrive/pinetree_scan/results/damage_detection_*/weights/best.pt',\n",
    "        # ê¸°ì¡´ results í´ë”\n",
    "        '/content/drive/MyDrive/pinetree_scan/results/*/weights/best.pt',\n",
    "    ]\n",
    "    \n",
    "    import glob\n",
    "    for pattern in search_paths:\n",
    "        matches = glob.glob(pattern)\n",
    "        if matches:\n",
    "            # ê°€ì¥ ìµœì‹  ëª¨ë¸ ì„ íƒ\n",
    "            best_model_path = max(matches, key=os.path.getctime)\n",
    "            break\n",
    "    \n",
    "    if best_model_path:\n",
    "        print(f\"ğŸ¯ ìµœì‹  í•™ìŠµ ëª¨ë¸ ë°œê²¬: {best_model_path}\")\n",
    "        model = YOLO(best_model_path)\n",
    "        training_completed = True\n",
    "    else:\n",
    "        print(\"âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. YOLOv11s ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©\")\n",
    "        model = YOLO('yolo11s.pt')\n",
    "        best_model_path = 'yolo11s.pt'\n",
    "\n",
    "else:\n",
    "    # í•™ìŠµ ì™„ë£Œëœ ê²½ìš° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
    "    if 'run_name' in globals():\n",
    "        best_model_path = f\"pinetree_yolov11s/{run_name}/weights/best.pt\"\n",
    "    else:\n",
    "        # ìµœì‹  ëª¨ë¸ ìë™ íƒì§€\n",
    "        import glob\n",
    "        matches = glob.glob('./pinetree_yolov11s/damage_detection_*/weights/best.pt')\n",
    "        if matches:\n",
    "            best_model_path = max(matches, key=os.path.getctime)\n",
    "        else:\n",
    "            best_model_path = 'yolo11s.pt'\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(best_model_path)\n",
    "        print(f\"âœ… í•™ìŠµ ì™„ë£Œ ëª¨ë¸ ë¡œë“œ: {best_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        model = YOLO('yolo11s.pt')\n",
    "        best_model_path = 'yolo11s.pt'\n",
    "\n",
    "# ğŸ“Š í•™ìŠµ ê²°ê³¼ ë¶„ì„\n",
    "if training_completed and 'training_results' in globals() and training_results:\n",
    "    print(f\"\\nğŸ“ˆ í•™ìŠµ ê²°ê³¼ ìš”ì•½:\")\n",
    "    results = training_results\n",
    "    \n",
    "    try:\n",
    "        print(f\"  ğŸ¯ ìµœì¢… mAP50: {results.box.map50:.4f} ({results.box.map50*100:.1f}%)\")\n",
    "        print(f\"  ğŸ¯ ìµœì¢… mAP50-95: {results.box.map:.4f} ({results.box.map*100:.1f}%)\")\n",
    "        print(f\"  ğŸ¯ Precision: {results.box.mp:.4f} ({results.box.mp*100:.1f}%)\")\n",
    "        print(f\"  ğŸ¯ Recall: {results.box.mr:.4f} ({results.box.mr*100:.1f}%)\")\n",
    "        \n",
    "        # ì„±ëŠ¥ í‰ê°€\n",
    "        performance_score = (results.box.map50 + results.box.mp + results.box.mr) / 3\n",
    "        \n",
    "        if performance_score > 0.85:\n",
    "            print(\"ğŸŒŸ íƒì›”! í”„ë¡œë•ì…˜ ë ˆë²¨ ì„±ëŠ¥ì…ë‹ˆë‹¤!\")\n",
    "        elif performance_score > 0.7:\n",
    "            print(\"âœ… ìš°ìˆ˜! ì‹¤ìš©ì ì¸ ì„±ëŠ¥ì…ë‹ˆë‹¤!\")\n",
    "        elif performance_score > 0.5:\n",
    "            print(\"âš ï¸ ë³´í†µ. ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âŒ ë‚®ìŒ. ë°ì´í„°ë‚˜ ì„¤ì •ì„ ì¬ê²€í† í•˜ì„¸ìš”.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ğŸ–¼ï¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ì¤€ë¹„\n",
    "print(f\"\\nğŸ–¼ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²€ìƒ‰...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ í›„ë³´ë“¤\n",
    "test_image_paths = []\n",
    "image_search_paths = [\n",
    "    # í™˜ê²½ ì„¤ì •ì—ì„œ í™•ì¸ëœ data_path ì‚¬ìš©\n",
    "    f\"{globals().get('data_path', '/content/training_data')}/images/*.{ext}\"\n",
    "    for ext in ['jpg', 'jpeg', 'png', 'tif', 'tiff']\n",
    "] + [\n",
    "    # ì¶”ê°€ ê²€ìƒ‰ ê²½ë¡œë“¤\n",
    "    '/content/drive/MyDrive/pinetree_scan/data/images/*.jpg',\n",
    "    '/content/drive/MyDrive/pinetree_scan/data/images/*.tif',\n",
    "    '/content/drive/MyDrive/training_data/images/*.jpg',\n",
    "    '/content/drive/MyDrive/training_data/images/*.tif',\n",
    "    './data/images/*.jpg',\n",
    "    './data/images/*.tif',\n",
    "]\n",
    "\n",
    "import glob\n",
    "for pattern in image_search_paths:\n",
    "    matches = glob.glob(pattern)\n",
    "    test_image_paths.extend(matches[:3])  # ê° íŒ¨í„´ì—ì„œ ìµœëŒ€ 3ê°œ\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "test_image_paths = list(set(test_image_paths))[:5]  # ìµœëŒ€ 5ê°œ\n",
    "\n",
    "if test_image_paths:\n",
    "    print(f\"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ {len(test_image_paths)}ê°œ ë°œê²¬!\")\n",
    "    for i, path in enumerate(test_image_paths):\n",
    "        print(f\"  {i+1}. {os.path.basename(path)}\")\n",
    "else:\n",
    "    print(\"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ Google Driveì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ URLë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # ìƒ˜í”Œ URL ì´ë¯¸ì§€ (drone/aerial view)\n",
    "    test_image_paths = [\n",
    "        \"https://images.unsplash.com/photo-1502780402662-acc01917610e?w=800\",  # forest aerial\n",
    "        \"https://images.unsplash.com/photo-1441974231531-c6227db76b6e?w=800\"   # forest damage\n",
    "    ]\n",
    "    print(\"ğŸŒ ì¸í„°ë„· ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ğŸ” ì¶”ë¡  ì‹¤í–‰ ë° ì‹œê°í™”\n",
    "print(f\"\\nğŸ” ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹œì‘!\")\n",
    "\n",
    "inference_results = []\n",
    "successful_tests = 0\n",
    "\n",
    "for i, image_path in enumerate(test_image_paths[:3]):  # ìµœëŒ€ 3ê°œë§Œ í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        print(f\"\\nğŸ“¸ ì´ë¯¸ì§€ {i+1}: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # ì¶”ë¡  ì‹¤í–‰ (ì†Œë‚˜ë¬´ ìµœì í™” ì„¤ì •)\n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=0.3,      # ë†’ì€ ì‹ ë¢°ë„\n",
    "            iou=0.6,       # ë†’ì€ IoU\n",
    "            save=True,\n",
    "            save_txt=True,\n",
    "            save_conf=True,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # ê²°ê³¼ ë¶„ì„\n",
    "        detections = results[0]\n",
    "        num_detections = len(detections.boxes) if detections.boxes is not None else 0\n",
    "        \n",
    "        if num_detections > 0:\n",
    "            confidences = detections.boxes.conf.cpu().numpy()\n",
    "            avg_conf = np.mean(confidences)\n",
    "            max_conf = np.max(confidences)\n",
    "            \n",
    "            print(f\"  ğŸ¯ íƒì§€ ìˆ˜: {num_detections}ê°œ\")\n",
    "            print(f\"  ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_conf:.3f}\")\n",
    "            print(f\"  ğŸ“Š ìµœê³  ì‹ ë¢°ë„: {max_conf:.3f}\")\n",
    "            \n",
    "            # ì‹ ë¢°ë„ í‰ê°€\n",
    "            if max_conf > 0.8:\n",
    "                print(\"  ğŸŒŸ ë†’ì€ ì‹ ë¢°ë„ íƒì§€!\")\n",
    "            elif max_conf > 0.5:\n",
    "                print(\"  âœ… ì ì ˆí•œ ì‹ ë¢°ë„\")\n",
    "            else:\n",
    "                print(\"  âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ - í™•ì¸ í•„ìš”\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"  âŒ íƒì§€ëœ ê°ì²´ ì—†ìŒ\")\n",
    "        \n",
    "        inference_results.append({\n",
    "            'image': os.path.basename(image_path),\n",
    "            'detections': num_detections,\n",
    "            'avg_confidence': avg_conf if num_detections > 0 else 0,\n",
    "            'max_confidence': max_conf if num_detections > 0 else 0\n",
    "        })\n",
    "        \n",
    "        successful_tests += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}\")\n",
    "        inference_results.append({\n",
    "            'image': os.path.basename(image_path),\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# ğŸ“ˆ ì¶”ë¡  ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\nğŸ“ˆ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "print(f\"  âœ… ì„±ê³µ: {successful_tests}/{len(test_image_paths[:3])}\")\n",
    "\n",
    "if successful_tests > 0:\n",
    "    total_detections = sum(r.get('detections', 0) for r in inference_results)\n",
    "    avg_confidence = np.mean([r.get('avg_confidence', 0) for r in inference_results if r.get('detections', 0) > 0])\n",
    "    \n",
    "    print(f\"  ğŸ¯ ì´ íƒì§€: {total_detections}ê°œ\")\n",
    "    print(f\"  ğŸ“Š ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
    "    \n",
    "    # ìƒì„¸ ê²°ê³¼\n",
    "    for result in inference_results:\n",
    "        if 'error' not in result:\n",
    "            print(f\"    ğŸ“¸ {result['image']}: {result['detections']}ê°œ (ì‹ ë¢°ë„: {result['max_confidence']:.3f})\")\n",
    "\n",
    "# ğŸ¯ ì¶”ë¡  í’ˆì§ˆ í‰ê°€\n",
    "if successful_tests > 0:\n",
    "    print(f\"\\nğŸ¯ ëª¨ë¸ í’ˆì§ˆ í‰ê°€:\")\n",
    "    \n",
    "    # íƒì§€ìœ¨ í‰ê°€\n",
    "    detection_rate = sum(1 for r in inference_results if r.get('detections', 0) > 0) / successful_tests\n",
    "    print(f\"  ğŸ“Š íƒì§€ìœ¨: {detection_rate*100:.1f}%\")\n",
    "    \n",
    "    if detection_rate > 0.8:\n",
    "        print(\"  ğŸŒŸ íƒì›”í•œ íƒì§€ ì„±ëŠ¥!\")\n",
    "    elif detection_rate > 0.5:\n",
    "        print(\"  âœ… ì ì ˆí•œ íƒì§€ ì„±ëŠ¥\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ íƒì§€ ì„±ëŠ¥ ê°œì„  í•„ìš”\")\n",
    "    \n",
    "    # ì‹ ë¢°ë„ í‰ê°€\n",
    "    if successful_tests > 0:\n",
    "        high_conf_rate = sum(1 for r in inference_results if r.get('max_confidence', 0) > 0.7) / successful_tests\n",
    "        print(f\"  \udcca ê³ ì‹ ë¢°ë„ íƒì§€ìœ¨: {high_conf_rate*100:.1f}%\")\n",
    "        \n",
    "        if high_conf_rate > 0.7:\n",
    "            print(\"  ğŸŒŸ ë†’ì€ ì‹ ë¢°ë„! ì˜¤íƒì§€ ìœ„í—˜ ë‚®ìŒ\")\n",
    "        elif high_conf_rate > 0.4:\n",
    "            print(\"  âœ… ì ì ˆí•œ ì‹ ë¢°ë„\")\n",
    "        else:\n",
    "            print(\"  âš ï¸ ì‹ ë¢°ë„ ê°œì„  í•„ìš”\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "if 'IN_COLAB' in globals() and IN_COLAB and successful_tests > 0:\n",
    "    try:\n",
    "        results_dir = f\"/content/drive/MyDrive/pinetree_scan/inference_results/{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        # ì¶”ë¡  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥\n",
    "        import json\n",
    "        with open(f\"{results_dir}/inference_summary.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                'model_path': best_model_path,\n",
    "                'test_date': datetime.now().isoformat(),\n",
    "                'successful_tests': successful_tests,\n",
    "                'total_detections': total_detections,\n",
    "                'avg_confidence': float(avg_confidence) if successful_tests > 0 else 0,\n",
    "                'detection_rate': detection_rate,\n",
    "                'results': inference_results\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n\udcbe ì¶”ë¡  ê²°ê³¼ ì €ì¥: {results_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c47000",
   "metadata": {},
   "source": [
    "## ğŸ† **4ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€**\n",
    "\n",
    "> ìµœì¢… ì„±ëŠ¥ ì§€í‘œ ìš”ì•½ ë° ëª¨ë¸ í’ˆì§ˆ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \udf89 4ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ì •ë¦¬ ë° ì‹¤ìš©í™” ê°€ì´ë“œ\n",
    "print(\"\udf89 YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ ì‹œìŠ¤í…œ ì™„ì„±!\")\n",
    "print(\"ğŸ“‹ ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì‹¤ìš©í™” ë°©ë²• ì•ˆë‚´\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ“Š ì „ì²´ ê²°ê³¼ ì¢…í•©\n",
    "completion_status = {\n",
    "    'environment_setup': 'environment_configured' in globals(),\n",
    "    'training_completed': globals().get('training_completed', False),\n",
    "    'inference_tested': 'inference_results' in globals() or 'successful_tests' in globals(),\n",
    "    'model_ready': 'model' in globals()\n",
    "}\n",
    "\n",
    "print(\"ğŸ“Š ì‹œìŠ¤í…œ ì™„ì„±ë„ ì²´í¬:\")\n",
    "for step, status in completion_status.items():\n",
    "    emoji = \"âœ…\" if status else \"âŒ\"\n",
    "    step_name = {\n",
    "        'environment_setup': 'í™˜ê²½ ì„¤ì •',\n",
    "        'training_completed': 'ëª¨ë¸ í•™ìŠµ',\n",
    "        'inference_tested': 'ì¶”ë¡  í…ŒìŠ¤íŠ¸',\n",
    "        'model_ready': 'ëª¨ë¸ ì¤€ë¹„'\n",
    "    }[step]\n",
    "    print(f\"  {emoji} {step_name}: {'ì™„ë£Œ' if status else 'ë¯¸ì™„ë£Œ'}\")\n",
    "\n",
    "total_completion = sum(completion_status.values()) / len(completion_status) * 100\n",
    "print(f\"\\nğŸ¯ ì „ì²´ ì™„ì„±ë„: {total_completion:.0f}%\")\n",
    "\n",
    "# ğŸ† ì„±ëŠ¥ ê²°ê³¼ ìš”ì•½ (í•™ìŠµì´ ì™„ë£Œëœ ê²½ìš°)\n",
    "if globals().get('training_completed', False) and 'training_results' in globals():\n",
    "    print(f\"\\nğŸ† ìµœì¢… ëª¨ë¸ ì„±ëŠ¥:\")\n",
    "    \n",
    "    try:\n",
    "        results = training_results\n",
    "        print(f\"  ğŸ“ˆ mAP50: {results.box.map50:.4f} ({results.box.map50*100:.1f}%)\")\n",
    "        print(f\"  ğŸ“ˆ mAP50-95: {results.box.map:.4f} ({results.box.map*100:.1f}%)\")\n",
    "        print(f\"  ğŸ“ˆ Precision: {results.box.mp:.4f} ({results.box.mp*100:.1f}%)\")\n",
    "        print(f\"  ğŸ“ˆ Recall: {results.box.mr:.4f} ({results.box.mr*100:.1f}%)\")\n",
    "        \n",
    "        # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€\n",
    "        performance_score = (results.box.map50 + results.box.mp + results.box.mr) / 3\n",
    "        \n",
    "        if performance_score > 0.9:\n",
    "            grade = \"A+\"\n",
    "            description = \"ìµœê³ ê¸‰ - ìƒìš© ìˆ˜ì¤€\"\n",
    "        elif performance_score > 0.8:\n",
    "            grade = \"A\"\n",
    "            description = \"ìš°ìˆ˜ - ì‹¤ìš©ì \"\n",
    "        elif performance_score > 0.7:\n",
    "            grade = \"B\"\n",
    "            description = \"ì–‘í˜¸ - ì‹¤í—˜ì \"\n",
    "        elif performance_score > 0.6:\n",
    "            grade = \"C\"\n",
    "            description = \"ë³´í†µ - ê°œì„  í•„ìš”\"\n",
    "        else:\n",
    "            grade = \"D\"\n",
    "            description = \"ë¯¸í¡ - ì¬í•™ìŠµ ê¶Œì¥\"\n",
    "        \n",
    "        print(f\"  \udfc5 ì„±ëŠ¥ ë“±ê¸‰: {grade} ({description})\")\n",
    "        \n",
    "        if 'run_name' in globals():\n",
    "            print(f\"  ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: pinetree_yolov11s/{run_name}/weights/best.pt\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ğŸ” ì¶”ë¡  ê²°ê³¼ ìš”ì•½ (í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œëœ ê²½ìš°)\n",
    "if 'inference_results' in globals() or 'successful_tests' in globals():\n",
    "    print(f\"\\nğŸ” ì¶”ë¡  í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "    \n",
    "    try:\n",
    "        if 'successful_tests' in globals():\n",
    "            print(f\"  âœ… ì„±ê³µë¥ : {successful_tests}/3 í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        if 'total_detections' in globals():\n",
    "            print(f\"  ğŸ¯ ì´ íƒì§€: {total_detections}ê°œ\")\n",
    "        \n",
    "        if 'avg_confidence' in globals() and avg_confidence > 0:\n",
    "            print(f\"  ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
    "            \n",
    "            if avg_confidence > 0.8:\n",
    "                print(f\"  ğŸŒŸ ë†’ì€ ì‹ ë¢°ë„! ì˜¤íƒì§€ ìœ„í—˜ ë‚®ìŒ\")\n",
    "            elif avg_confidence > 0.6:\n",
    "                print(f\"  âœ… ì ì ˆí•œ ì‹ ë¢°ë„\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ ì‹ ë¢°ë„ ê°œì„  ê¶Œì¥\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ì¶”ë¡  ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ ìœ„ì¹˜ ì•ˆë‚´\n",
    "print(f\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\")\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ íŒŒì¼ë“¤\n",
    "if 'run_name' in globals():\n",
    "    model_dir = f\"pinetree_yolov11s/{run_name}\"\n",
    "    print(f\"  ğŸ¤– í•™ìŠµëœ ëª¨ë¸:\")\n",
    "    print(f\"    - ìµœê³  ì„±ëŠ¥: {model_dir}/weights/best.pt\")\n",
    "    print(f\"    - ìµœì¢… ì²´í¬í¬ì¸íŠ¸: {model_dir}/weights/last.pt\")\n",
    "    print(f\"    - í•™ìŠµ ë¡œê·¸: {model_dir}/results.csv\")\n",
    "    print(f\"    - ì„¤ì • íŒŒì¼: {model_dir}/args.yaml\")\n",
    "\n",
    "# Google Drive ë°±ì—… ìœ„ì¹˜\n",
    "if 'IN_COLAB' in globals() and IN_COLAB:\n",
    "    print(f\"  â˜ï¸ Google Drive ë°±ì—…:\")\n",
    "    print(f\"    - ëª¨ë¸: /content/drive/MyDrive/pinetree_scan/results/\")\n",
    "    print(f\"    - ì¶”ë¡  ê²°ê³¼: /content/drive/MyDrive/pinetree_scan/inference_results/\")\n",
    "\n",
    "# ğŸš€ ì‹¤ìš©í™” ê°€ì´ë“œ\n",
    "print(f\"\\nğŸš€ ì‹¤ìš©í™” ë°©ë²•:\")\n",
    "\n",
    "print(f\"\\n1ï¸âƒ£ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì¶”ë¡ :\")\n",
    "if 'best_model_path' in globals():\n",
    "    print(f\"```python\")\n",
    "    print(f\"from ultralytics import YOLO\")\n",
    "    print(f\"model = YOLO('{best_model_path}')\")\n",
    "    print(f\"results = model.predict('your_image.jpg', conf=0.3, save=True)\")\n",
    "    print(f\"```\")\n",
    "else:\n",
    "    print(f\"```python\")\n",
    "    print(f\"from ultralytics import YOLO\")\n",
    "    print(f\"model = YOLO('pinetree_yolov11s/damage_detection_YYYYMMDD_HHMM/weights/best.pt')\")\n",
    "    print(f\"results = model.predict('your_image.jpg', conf=0.3, save=True)\")\n",
    "    print(f\"```\")\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ ëŒ€ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬:\")\n",
    "print(f\"```python\")\n",
    "print(f\"import glob\")\n",
    "print(f\"image_paths = glob.glob('your_folder/*.jpg')\")\n",
    "print(f\"results = model.predict(image_paths, conf=0.3, save=True)\")\n",
    "print(f\"```\")\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ API ì„œë²„ êµ¬ì¶•:\")\n",
    "print(f\"```python\")\n",
    "print(f\"# FastAPI ì„œë²„ë¡œ ì›¹ ì„œë¹„ìŠ¤ êµ¬ì¶•\")\n",
    "print(f\"# ê¸°ì¡´ API ì½”ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ êµ¬í˜„\")\n",
    "print(f\"# conf=0.3, iou=0.6 ì„¤ì • ê¶Œì¥\")\n",
    "print(f\"```\")\n",
    "\n",
    "print(f\"\\n4ï¸âƒ£ ë°°ì¹˜ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸:\")\n",
    "print(f\"```python\")\n",
    "print(f\"# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ìš©\")\n",
    "print(f\"for image_batch in image_batches:\")\n",
    "print(f\"    results = model.predict(image_batch, conf=0.3)\")\n",
    "print(f\"    # ê²°ê³¼ ì €ì¥ ë¡œì§\")\n",
    "print(f\"```\")\n",
    "\n",
    "# ğŸ”§ ìµœì í™” íŒ\n",
    "print(f\"\\nğŸ”§ ì„±ëŠ¥ ìµœì í™” íŒ:\")\n",
    "print(f\"  ğŸ’¡ ì‹ ë¢°ë„ ì„ê³„ê°’: conf=0.3 (ë†’ì€ ì •ë°€ë„)\")\n",
    "print(f\"  ğŸ’¡ IoU ì„ê³„ê°’: iou=0.6 (ì¤‘ë³µ íƒì§€ ë°©ì§€)\")\n",
    "print(f\"  ğŸ’¡ ì´ë¯¸ì§€ í¬ê¸°: 640x640 (í•™ìŠµ ì‹œì™€ ë™ì¼)\")\n",
    "print(f\"  ğŸ’¡ GPU ì‚¬ìš©: device='cuda' (ì†ë„ í–¥ìƒ)\")\n",
    "print(f\"  ğŸ’¡ ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬\")\n",
    "\n",
    "# âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ê¶Œì¥ì‚¬í•­\n",
    "print(f\"\\nâš ï¸ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­:\")\n",
    "print(f\"  ğŸ”¸ í•­ê³µ/ë“œë¡  ì´¬ì˜ ì´ë¯¸ì§€ì— ìµœì í™”ë¨\")\n",
    "print(f\"  ğŸ”¸ ì†Œë‚˜ë¬´ ìˆ² í™˜ê²½ì— íŠ¹í™”ë¨\")\n",
    "print(f\"  ğŸ”¸ ì¡°ëª… ì¡°ê±´: ë‚® ì‹œê°„ëŒ€ ê¶Œì¥\")\n",
    "print(f\"  ğŸ”¸ í•´ìƒë„: ê³ í•´ìƒë„ ì´ë¯¸ì§€ ê¶Œì¥\")\n",
    "print(f\"  ğŸ”¸ ì‹œì¦Œ: ëª¨ë“  ê³„ì ˆ ê°€ëŠ¥ (í•™ìŠµ ë°ì´í„°ì— ë”°ë¼)\")\n",
    "\n",
    "# ğŸ“ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n",
    "print(f\"\\n\udee0ï¸ ë¬¸ì œ í•´ê²°:\")\n",
    "print(f\"  â“ íƒì§€ ì•ˆë¨: conf ê°’ì„ 0.1~0.2ë¡œ ë‚®ì¶¤\")\n",
    "print(f\"  â“ ì˜¤íƒì§€ ë§ìŒ: conf ê°’ì„ 0.4~0.5ë¡œ ë†’ì„\")\n",
    "print(f\"  â“ ì†ë„ ëŠë¦¼: ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ (480x480)\")\n",
    "print(f\"  â“ ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° ì¤„ì„\")\n",
    "print(f\"  â“ GPU ì˜¤ë¥˜: device='cpu'ë¡œ ë³€ê²½\")\n",
    "\n",
    "# ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ë°©ë²•\n",
    "print(f\"\\nğŸ“ˆ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ:\")\n",
    "print(f\"  ğŸ¯ ë” ë§ì€ í•™ìŠµ ë°ì´í„° ì¶”ê°€\")\n",
    "print(f\"  ğŸ¯ Hard negative mining ì ìš©\")\n",
    "print(f\"  ğŸ¯ Test-Time Augmentation (TTA)\")\n",
    "print(f\"  ğŸ¯ ëª¨ë¸ ì•™ìƒë¸” (ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©)\")\n",
    "print(f\"  ğŸ¯ Post-processing ìµœì í™”\")\n",
    "\n",
    "# ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­\n",
    "print(f\"\\nğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­:\")\n",
    "\n",
    "if total_completion >= 80:\n",
    "    print(f\"  ğŸŒŸ ì™„ì„±ë„ ë†’ìŒ! ì‹¤ì œ ì—…ë¬´ì— ì ìš© ê°€ëŠ¥\")\n",
    "    print(f\"  ğŸš€ í”„ë¡œë•ì…˜ í™˜ê²½ êµ¬ì¶• ê¶Œì¥\")\n",
    "    print(f\"  ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•\")\n",
    "elif total_completion >= 60:\n",
    "    print(f\"  âœ… ê¸°ë³¸ ê¸°ëŠ¥ ì™„ì„±! ì¶”ê°€ í…ŒìŠ¤íŠ¸ í›„ ì ìš©\")\n",
    "    print(f\"  ğŸ”§ ì„±ëŠ¥ ê°œì„  ì‘ì—… ê¶Œì¥\")\n",
    "    print(f\"  ğŸ“ ë” ë§ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ë³´\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ ì¶”ê°€ ì‘ì—… í•„ìš”\")\n",
    "    print(f\"  ğŸ”„ ë¯¸ì™„ë£Œ ë‹¨ê³„ ì¬ì‹¤í–‰\")\n",
    "    print(f\"  ğŸ“‹ í™˜ê²½ ì„¤ì • ì¬ì ê²€\")\n",
    "\n",
    "# ğŸ“ ì§€ì› ì •ë³´\n",
    "print(f\"\\nğŸ“ ì¶”ê°€ ì§€ì›:\")\n",
    "print(f\"  ğŸ“š YOLOv11 ê³µì‹ ë¬¸ì„œ: https://docs.ultralytics.com/\")\n",
    "print(f\"  ğŸ™ GitHub ì €ì¥ì†Œ: https://github.com/ultralytics/ultralytics\")\n",
    "print(f\"  ğŸ’¬ ì»¤ë®¤ë‹ˆí‹°: https://community.ultralytics.com/\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ‰ YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!\")\n",
    "print(f\"ğŸŒ² ì§€ì† ê°€ëŠ¥í•œ ì‚°ë¦¼ ê´€ë¦¬ì— ê¸°ì—¬í•˜ì„¸ìš”!\")\n",
    "print(f\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
