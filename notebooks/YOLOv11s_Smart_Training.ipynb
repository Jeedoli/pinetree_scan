{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad0a969",
   "metadata": {},
   "source": [
    "# ğŸš€ YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ - ì›í´ë¦­ í•™ìŠµ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ğŸ¯ **4ë‹¨ê³„ ì›í´ë¦­ ì‹¤í–‰**\n",
    "\n",
    "### **âš¡ ë¹ ë¥¸ ì‹œì‘**\n",
    "1. **ğŸ–¥ï¸ GPU ì„¤ì •**: `ëŸ°íƒ€ì„` â†’ `ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½` â†’ `T4 GPU` ì„ íƒ\n",
    "2. **ğŸš€ ì›í´ë¦­ ì‹¤í–‰**: `ëŸ°íƒ€ì„` â†’ `ëª¨ë‘ ì‹¤í–‰` í´ë¦­  \n",
    "3. **â˜• ëŒ€ê¸°**: ì•½ 1-2ì‹œê°„ í›„ ì™„ì„±!\n",
    "\n",
    "### **ğŸ”„ ìë™ ì‹¤í–‰ ë‹¨ê³„**\n",
    "- **1ë‹¨ê³„**: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€\n",
    "- **2ë‹¨ê³„**: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ\n",
    "- **3ë‹¨ê³„**: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
    "- **4ë‹¨ê³„**: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "### **ğŸ¯ ë„¤ì´ë° ê·œì¹™**\n",
    "- **í”„ë¡œì íŠ¸**: `pinetree_yolov11s` (ìœ ì§€)\n",
    "- **ì‹¤í–‰ëª…**: `damage_detection_YYYYMMDD_HHMM`\n",
    "- **ì˜ˆì‹œ**: `damage_detection_20250916_1430`\n",
    "\n",
    "### **\udcc8 ì˜ˆìƒ ì„±ëŠ¥**\n",
    "- **mAP50**: 93%+ (ë†’ì€ íƒì§€ ì •í™•ë„)\n",
    "- **Precision**: 90%+ (ì˜¤íƒì§€ ìµœì†Œí™”)  \n",
    "- **Recall**: 85%+ (ì‹¤ì œ í”¼í•´ëª© íƒì§€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e444eb0",
   "metadata": {},
   "source": [
    "## ğŸ”§ **1ë‹¨ê³„: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€**\n",
    "\n",
    "> íŒ¨í‚¤ì§€ ì„¤ì¹˜, ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ìë™ íƒì§€, GPU ì„¤ì •ì„ ëª¨ë‘ ìë™í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69829093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ 1ë‹¨ê³„: í™˜ê²½ ì„¤ì • ë° ê¸°ì¡´ ëª¨ë¸ íƒì§€\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('==')[0])\n",
    "        print(f\"âœ… {package} ì´ë¯¸ ì„¤ì¹˜ë¨\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "print(\"ğŸš€ YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ - í™˜ê²½ ì„¤ì •\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ğŸ—‚ï¸ Google Drive ë§ˆìš´íŠ¸ ë° ZIP ë°ì´í„° ìë™ ì••ì¶• í•´ì œ (Colab í™˜ê²½ì—ì„œë§Œ)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸ“ Google Colab í™˜ê²½ ê°ì§€\")\n",
    "    \n",
    "    # Google Drive ë§ˆìš´íŠ¸\n",
    "    print(\"ğŸ”— Google Drive ë§ˆìš´íŠ¸ ì¤‘...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ\")\n",
    "    \n",
    "    # ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "    drive_path = '/content/drive/MyDrive/pinetree_scan'\n",
    "    if not os.path.exists(drive_path):\n",
    "        os.makedirs(drive_path, exist_ok=True)\n",
    "        print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±: {drive_path}\")\n",
    "    \n",
    "    # ğŸ” ZIP íŒŒì¼ ìë™ íƒì§€ ë° ì••ì¶• í•´ì œ í•¨ìˆ˜\n",
    "    def find_and_extract_training_zip():\n",
    "        \"\"\"Google Driveì—ì„œ training_data ZIP íŒŒì¼ì„ ì°¾ì•„ ì••ì¶• í•´ì œ\"\"\"\n",
    "        import zipfile\n",
    "        import shutil\n",
    "        \n",
    "        print(\"\\nğŸ” Google Driveì—ì„œ ZIP ë°ì´í„°ì…‹ íƒì§€ ì¤‘...\")\n",
    "        \n",
    "        # ZIP íŒŒì¼ ê²€ìƒ‰ ê²½ë¡œ (ìš°ì„ ìˆœìœ„ë³„)\n",
    "        zip_search_paths = [\n",
    "            # 1ìˆœìœ„: pinetree_scan/training_data í´ë” ë‚´ì˜ ëª¨ë“  ZIP íŒŒì¼\n",
    "            '/content/drive/MyDrive/pinetree_scan/training_data/*.zip',\n",
    "            \n",
    "            # 2ìˆœìœ„: pinetree_scan í´ë” ë‚´\n",
    "            '/content/drive/MyDrive/pinetree_scan/training_data.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/dataset.zip', \n",
    "            '/content/drive/MyDrive/pinetree_scan/data.zip',\n",
    "            \n",
    "            # 3ìˆœìœ„: ì§ì ‘ ì—…ë¡œë“œ\n",
    "            '/content/drive/MyDrive/training_data.zip',\n",
    "            '/content/drive/MyDrive/dataset.zip',\n",
    "            '/content/drive/MyDrive/data.zip',\n",
    "            '/content/drive/MyDrive/yolo_data.zip',\n",
    "            '/content/drive/MyDrive/pine_data.zip',\n",
    "            \n",
    "            # 4ìˆœìœ„: ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰\n",
    "            '/content/drive/MyDrive/*training*.zip',\n",
    "            '/content/drive/MyDrive/*dataset*.zip',\n",
    "            '/content/drive/MyDrive/*data*.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/*training*.zip',\n",
    "            '/content/drive/MyDrive/pinetree_scan/*dataset*.zip'\n",
    "        ]\n",
    "        \n",
    "        found_zips = []\n",
    "        \n",
    "        for search_path in zip_search_paths:\n",
    "            if '*' in search_path:\n",
    "                # ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰\n",
    "                import glob\n",
    "                matches = glob.glob(search_path)\n",
    "                for match in matches:\n",
    "                    if os.path.exists(match) and match.endswith('.zip'):\n",
    "                        found_zips.append(match)\n",
    "            else:\n",
    "                # ì§ì ‘ ê²½ë¡œ í™•ì¸\n",
    "                if os.path.exists(search_path):\n",
    "                    found_zips.append(search_path)\n",
    "        \n",
    "        if found_zips:\n",
    "            # ì¤‘ë³µ ì œê±°\n",
    "            found_zips = list(set(found_zips))\n",
    "            \n",
    "            print(f\"ğŸ“¦ ë°œê²¬ëœ ZIP íŒŒì¼ë“¤:\")\n",
    "            for i, zip_file in enumerate(found_zips, 1):\n",
    "                file_size = os.path.getsize(zip_file) / 1024 / 1024  # MB\n",
    "                print(f\"  {i}. {os.path.basename(zip_file)} ({file_size:.1f}MB)\")\n",
    "                print(f\"     ê²½ë¡œ: {zip_file}\")\n",
    "            \n",
    "            # ê°€ì¥ í° íŒŒì¼ì„ ì„ íƒ (í›ˆë ¨ ë°ì´í„°ê°€ í´ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)\n",
    "            zip_path = max(found_zips, key=os.path.getsize)\n",
    "            print(f\"\\nâœ… ì„ íƒëœ íŒŒì¼: {os.path.basename(zip_path)}\")\n",
    "            print(f\"ğŸ“ ê²½ë¡œ: {zip_path}\")\n",
    "            \n",
    "            # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "            zip_size = os.path.getsize(zip_path) / 1024 / 1024  # MB\n",
    "            print(f\"ğŸ“ í¬ê¸°: {zip_size:.1f}MB\")\n",
    "            \n",
    "            # ì••ì¶• í•´ì œ ëŒ€ìƒ ê²½ë¡œ\n",
    "            extract_path = '/content/drive/MyDrive/pinetree_scan/training_data'\n",
    "            temp_extract_path = '/content/training_data_temp'\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nğŸ”„ ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...\")\n",
    "                \n",
    "                # ì„ì‹œ ê²½ë¡œì— ì••ì¶• í•´ì œ\n",
    "                if os.path.exists(temp_extract_path):\n",
    "                    shutil.rmtree(temp_extract_path)\n",
    "                \n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(temp_extract_path)\n",
    "                \n",
    "                print(f\"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {temp_extract_path}\")\n",
    "                \n",
    "                # ì••ì¶• í•´ì œëœ ë‚´ìš© í™•ì¸ ë° ì •ë¦¬\n",
    "                extracted_items = os.listdir(temp_extract_path)\n",
    "                print(f\"ğŸ“‹ ì••ì¶• í•´ì œ ë‚´ìš©: {extracted_items}\")\n",
    "                \n",
    "                # training_data í´ë” êµ¬ì¡° ì •ë¦¬\n",
    "                final_path = extract_path\n",
    "                \n",
    "                # ê¸°ì¡´ training_dataê°€ ìˆìœ¼ë©´ ì‚­ì œ\n",
    "                if os.path.exists(final_path):\n",
    "                    shutil.rmtree(final_path)\n",
    "                    print(f\"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {final_path}\")\n",
    "                \n",
    "                # ì••ì¶• í•´ì œëœ ë‚´ìš©ì´ training_data í´ë”ì¸ì§€ í™•ì¸\n",
    "                if 'training_data' in extracted_items:\n",
    "                    # training_data í´ë”ê°€ í¬í•¨ëœ ê²½ìš°\n",
    "                    source_path = os.path.join(temp_extract_path, 'training_data')\n",
    "                    shutil.move(source_path, final_path)\n",
    "                elif len(extracted_items) == 1 and os.path.isdir(os.path.join(temp_extract_path, extracted_items[0])):\n",
    "                    # ë‹¨ì¼ í´ë”ì¸ ê²½ìš°\n",
    "                    source_path = os.path.join(temp_extract_path, extracted_items[0])\n",
    "                    shutil.move(source_path, final_path)\n",
    "                else:\n",
    "                    # íŒŒì¼ë“¤ì´ ì§ì ‘ ì••ì¶•ëœ ê²½ìš°\n",
    "                    shutil.move(temp_extract_path, final_path)\n",
    "                \n",
    "                # ì„ì‹œ í´ë” ì •ë¦¬\n",
    "                if os.path.exists(temp_extract_path):\n",
    "                    shutil.rmtree(temp_extract_path)\n",
    "                \n",
    "                # ì••ì¶• í•´ì œ ê²°ê³¼ í™•ì¸\n",
    "                if os.path.exists(final_path):\n",
    "                    contents = os.listdir(final_path)\n",
    "                    print(f\"ğŸ“‚ ìµœì¢… ê²½ë¡œ: {final_path}\")\n",
    "                    print(f\"ğŸ“‹ ë‚´ìš©: {contents}\")\n",
    "                    \n",
    "                    # ê¸°ë³¸ êµ¬ì¡° í™•ì¸\n",
    "                    images_dir = os.path.join(final_path, 'images')\n",
    "                    labels_dir = os.path.join(final_path, 'labels')\n",
    "                    \n",
    "                    if os.path.exists(images_dir):\n",
    "                        image_count = len([f for f in os.listdir(images_dir) \n",
    "                                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff'))])\n",
    "                        print(f\"ğŸ“¸ ì´ë¯¸ì§€: {image_count}ê°œ\")\n",
    "                    \n",
    "                    if os.path.exists(labels_dir):\n",
    "                        label_count = len([f for f in os.listdir(labels_dir) \n",
    "                                         if f.endswith('.txt')])\n",
    "                        print(f\"ğŸ·ï¸ ë¼ë²¨: {label_count}ê°œ\")\n",
    "                \n",
    "                return final_path\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ZIP ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}\")\n",
    "                return None\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ ZIP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            print(\"ğŸ’¡ ë‹¤ìŒ ê²½ë¡œì— ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/pinetree_scan/training_data/your_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/pinetree_scan/training_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/training_data.zip\")\n",
    "            print(\"  ğŸ“¦ /content/drive/MyDrive/dataset.zip\")\n",
    "            return None\n",
    "    \n",
    "    # ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì‹¤í–‰\n",
    "    extracted_data_path = find_and_extract_training_zip()\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° ê²½ë¡œ í™•ì¸ (ì••ì¶• í•´ì œ ê²°ê³¼ í¬í•¨)\n",
    "    data_paths = [\n",
    "        extracted_data_path,  # ì••ì¶• í•´ì œëœ ê²½ë¡œ ìš°ì„ \n",
    "        '/content/drive/MyDrive/pinetree_scan/training_data',\n",
    "        '/content/training_data',\n",
    "        '/content/drive/MyDrive/training_data'\n",
    "    ]\n",
    "    \n",
    "    data_path = None\n",
    "    for path in data_paths:\n",
    "        if path and os.path.exists(path):\n",
    "            # data.yamlì´ ìˆê±°ë‚˜ images í´ë”ê°€ ìˆìœ¼ë©´ ìœ íš¨í•œ ê²½ë¡œë¡œ ê°„ì£¼\n",
    "            if (os.path.exists(f\"{path}/data.yaml\") or \n",
    "                os.path.exists(f\"{path}/images\")):\n",
    "                data_path = path\n",
    "                print(f\"âœ… í•™ìŠµ ë°ì´í„° ë°œê²¬: {data_path}\")\n",
    "                break\n",
    "    \n",
    "    if not data_path:\n",
    "        print(\"âš ï¸ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ“‹ í•„ìš”í•œ íŒŒì¼ êµ¬ì¡°:\")\n",
    "        print(\"  ğŸ“¦ ZIP íŒŒì¼:\")\n",
    "        print(\"    ğŸ“‚ training_data.zip\")\n",
    "        print(\"      ğŸ“‚ images/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤)\")\n",
    "        print(\"      ğŸ“‚ labels/ (ë¼ë²¨ íŒŒì¼ë“¤)\")\n",
    "        print(\"      ğŸ“„ data.yaml (ì„ íƒì‚¬í•­)\")\n",
    "        print(\"\")\n",
    "        print(\"  ğŸ“ ë˜ëŠ” í´ë” êµ¬ì¡°:\")\n",
    "        print(\"    ğŸ“‚ training_data/\")\n",
    "        print(\"      ğŸ“„ data.yaml\")\n",
    "        print(\"      ğŸ“‚ images/\")\n",
    "        print(\"      ğŸ“‚ labels/\")\n",
    "        data_path = '/content/training_data'  # ê¸°ë³¸ê°’\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€\")\n",
    "    data_path = './data'  # ë¡œì»¬ ê¸°ë³¸ ê²½ë¡œ\n",
    "\n",
    "# ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "packages = [\n",
    "    \"ultralytics\",\n",
    "    \"torch\", \n",
    "    \"torchvision\",\n",
    "    \"opencv-python\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"roboflow\"  # ë°ì´í„°ì…‹ ê´€ë¦¬ìš© ì¶”ê°€\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"\\nğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´:\")\n",
    "print(f\"  Python: {sys.version.split()[0]}\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  CUDA ì‚¬ìš©ê°€ëŠ¥: {'âœ…' if torch.cuda.is_available() else 'âŒ'}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  GPU: {gpu_name}\")\n",
    "    print(f\"  GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"  ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"  âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# ğŸ† ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ìë™ íƒì§€ (ê°•í™”ëœ ë²„ì „)\n",
    "print(f\"\\nğŸ” ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ íƒì§€:\")\n",
    "\n",
    "def find_best_model():\n",
    "    \"\"\"ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ëŠ” í–¥ìƒëœ í•¨ìˆ˜\"\"\"\n",
    "    # ìš°ì„ ìˆœìœ„ë³„ ëª¨ë¸ ê²€ìƒ‰ ê²½ë¡œ\n",
    "    search_priorities = [\n",
    "        # 1ìˆœìœ„: ìµœì‹  í•™ìŠµ ê²°ê³¼ (í”¼í•´ëª© íƒì§€ ì „ìš©)\n",
    "        {\n",
    "            'priority': 1,\n",
    "            'description': 'ìµœì‹  í”¼í•´ëª© íƒì§€ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "                '/content/pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/results/damage_detection_*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/best.pt'\n",
    "            ]\n",
    "        },\n",
    "        # 2ìˆœìœ„: ì¼ë°˜ í•™ìŠµ ê²°ê³¼\n",
    "        {\n",
    "            'priority': 2,\n",
    "            'description': 'ì¼ë°˜ í•™ìŠµ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'runs/detect/train*/weights/best.pt',\n",
    "                '/content/runs/detect/train*/weights/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/runs/detect/train*/weights/best.pt',\n",
    "            ]\n",
    "        },\n",
    "        # 3ìˆœìœ„: ìˆ˜ë™ ì €ì¥ ëª¨ë¸\n",
    "        {\n",
    "            'priority': 3,\n",
    "            'description': 'ìˆ˜ë™ ì €ì¥ ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                '/content/drive/MyDrive/pinetree_scan/models/best.pt',\n",
    "                '/content/drive/MyDrive/pinetree_scan/weights/best.pt',\n",
    "                'models/best.pt',\n",
    "                'weights/best.pt',\n",
    "                '/content/best.pt'\n",
    "            ]\n",
    "        },\n",
    "        # 4ìˆœìœ„: ê¸°ë³¸ ëª¨ë¸\n",
    "        {\n",
    "            'priority': 4,\n",
    "            'description': 'ê¸°ë³¸ YOLO ëª¨ë¸',\n",
    "            'patterns': [\n",
    "                'yolo11s.pt',\n",
    "                '/content/yolo11s.pt'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    found_models = []\n",
    "    \n",
    "    for priority_group in search_priorities:\n",
    "        for pattern in priority_group['patterns']:\n",
    "            if '*' in pattern:\n",
    "                matches = glob.glob(pattern)\n",
    "                for match in matches:\n",
    "                    if os.path.exists(match):\n",
    "                        found_models.append({\n",
    "                            'path': match,\n",
    "                            'priority': priority_group['priority'],\n",
    "                            'description': priority_group['description'],\n",
    "                            'size': os.path.getsize(match) / 1024 / 1024,  # MB\n",
    "                            'modified': os.path.getctime(match)\n",
    "                        })\n",
    "            else:\n",
    "                if os.path.exists(pattern):\n",
    "                    found_models.append({\n",
    "                        'path': pattern,\n",
    "                        'priority': priority_group['priority'],\n",
    "                        'description': priority_group['description'],\n",
    "                        'size': os.path.getsize(pattern) / 1024 / 1024,  # MB\n",
    "                        'modified': os.path.getctime(pattern)\n",
    "                    })\n",
    "    \n",
    "    if found_models:\n",
    "        # ìš°ì„ ìˆœìœ„ì™€ ìˆ˜ì •ì‹œê°„ìœ¼ë¡œ ì •ë ¬\n",
    "        found_models.sort(key=lambda x: (x['priority'], -x['modified']))\n",
    "        return found_models\n",
    "    \n",
    "    return None\n",
    "\n",
    "# ëª¨ë¸ ê²€ìƒ‰ ì‹¤í–‰\n",
    "found_models = find_best_model()\n",
    "\n",
    "if found_models:\n",
    "    print(f\"ğŸ¯ ë°œê²¬ëœ ëª¨ë¸: {len(found_models)}ê°œ\")\n",
    "    \n",
    "    # ìƒìœ„ 3ê°œ ëª¨ë¸ í‘œì‹œ\n",
    "    for i, model_info in enumerate(found_models[:3]):\n",
    "        emoji = \"ğŸ†\" if i == 0 else \"ğŸ¥ˆ\" if i == 1 else \"ğŸ¥‰\"\n",
    "        print(f\"  {emoji} {model_info['description']}\")\n",
    "        print(f\"     ê²½ë¡œ: {model_info['path']}\")\n",
    "        print(f\"     í¬ê¸°: {model_info['size']:.1f}MB\")\n",
    "        print(f\"     ìˆ˜ì •: {datetime.fromtimestamp(model_info['modified']).strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ\n",
    "        if i == 0:\n",
    "            selected_model = model_info['path']\n",
    "    \n",
    "    # ì„ íƒëœ ëª¨ë¸ ë¡œë“œ ë° ê²€ì¦\n",
    "    print(f\"\\nğŸ“¥ ì„ íƒëœ ëª¨ë¸ ë¡œë“œ: {os.path.basename(selected_model)}\")\n",
    "    \n",
    "    try:\n",
    "        temp_model = YOLO(selected_model)\n",
    "        \n",
    "        # ëª¨ë¸ ì •ë³´ í™•ì¸\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "        print(f\"  ğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "        \n",
    "        if hasattr(temp_model, 'model') and hasattr(temp_model.model, 'names'):\n",
    "            class_names = list(temp_model.model.names.values())\n",
    "            print(f\"    ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}\")\n",
    "            print(f\"    ğŸ·ï¸ í´ë˜ìŠ¤ëª…: {class_names}\")\n",
    "            \n",
    "            # ì†Œë‚˜ë¬´/í”¼í•´ëª© ê´€ë ¨ í´ë˜ìŠ¤ í™•ì¸\n",
    "            pine_related = any(keyword in ' '.join(class_names).lower() \n",
    "                             for keyword in ['pine', 'damage', 'tree', 'í”¼í•´', 'ì†Œë‚˜ë¬´', 'damaged'])\n",
    "            \n",
    "            if pine_related:\n",
    "                print(f\"    ğŸŒ² ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ìš© ëª¨ë¸ í™•ì¸!\")\n",
    "            else:\n",
    "                print(f\"    âš ï¸ ì¼ë°˜ ê°ì²´ íƒì§€ ëª¨ë¸ (ì „ì´í•™ìŠµ ì˜ˆì •)\")\n",
    "        \n",
    "        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ë³´\n",
    "        try:\n",
    "            model_yaml = temp_model.model.yaml\n",
    "            if 'backbone' in str(model_yaml):\n",
    "                print(f\"    ğŸ—ï¸ ì•„í‚¤í…ì²˜: YOLOv11s\")\n",
    "        except:\n",
    "            print(f\"    ğŸ—ï¸ ì•„í‚¤í…ì²˜: YOLO ê³„ì—´\")\n",
    "            \n",
    "        existing_model = selected_model\n",
    "        del temp_model  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ğŸ“¥ ê¸°ë³¸ YOLOv11s ëª¨ë¸ë¡œ ëŒ€ì²´\")\n",
    "        existing_model = 'yolo11s.pt'\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ê¸°ì¡´ í•™ìŠµ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ“¥ ê¸°ë³¸ YOLOv11s ëª¨ë¸ ì‚¬ìš©\")\n",
    "    existing_model = 'yolo11s.pt'\n",
    "\n",
    "# ğŸ¯ ëª¨ë¸ ì‚¬ìš© ê³„íš ì•ˆë‚´\n",
    "print(f\"\\nğŸ¯ ëª¨ë¸ ì‚¬ìš© ê³„íš:\")\n",
    "if 'yolo11s.pt' in existing_model:\n",
    "    print(f\"  ğŸ“ ê¸°ë³¸ YOLOv11s â†’ ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ì´í•™ìŠµ\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 1-2ì‹œê°„ (ì²˜ìŒë¶€í„°)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 85-95% mAP50\")\n",
    "elif 'damage_detection' in existing_model:\n",
    "    print(f\"  ğŸ“ ê¸°ì¡´ í”¼í•´ëª© ëª¨ë¸ â†’ ì¶”ê°€ í•™ìŠµ/ë¯¸ì„¸ì¡°ì •\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 30ë¶„-1ì‹œê°„ (ë¯¸ì„¸ì¡°ì •)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 90-98% mAP50\")\n",
    "else:\n",
    "    print(f\"  ğŸ“ ê¸°ì¡´ ëª¨ë¸ â†’ ì†Œë‚˜ë¬´ í”¼í•´ëª© ì „ì´í•™ìŠµ\")\n",
    "    print(f\"  ğŸ¯ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 1ì‹œê°„ (ì „ì´í•™ìŠµ)\")\n",
    "    print(f\"  ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥: 87-95% mAP50\")\n",
    "\n",
    "# ğŸ—‚ï¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "if IN_COLAB:\n",
    "    output_base = '/content/drive/MyDrive/pinetree_scan/results'\n",
    "else:\n",
    "    output_base = './results'\n",
    "\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "print(f\"\\nğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_base}\")\n",
    "\n",
    "# ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸\n",
    "data_yaml_path = f\"{data_path}/data.yaml\"\n",
    "if os.path.exists(data_yaml_path):\n",
    "    print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:\")\n",
    "    try:\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(f\"  ğŸ“„ data.yaml ë‚´ìš© í™•ì¸ë¨\")\n",
    "            if 'names:' in content:\n",
    "                print(f\"  ğŸ·ï¸ í´ë˜ìŠ¤ ì •ë³´ í¬í•¨ë¨\")\n",
    "    except:\n",
    "        print(f\"  âš ï¸ data.yaml ì½ê¸° ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ë°ì´í„°ì…‹ íŒŒì¼ ì—†ìŒ: {data_yaml_path}\")\n",
    "    print(\"ğŸ“‹ data.yaml íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "globals()['existing_model'] = existing_model\n",
    "globals()['data_path'] = data_path\n",
    "globals()['output_base'] = output_base\n",
    "globals()['IN_COLAB'] = IN_COLAB\n",
    "globals()['found_models'] = found_models\n",
    "\n",
    "print(f\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"  ğŸ† ì‚¬ìš©í•  ëª¨ë¸: {os.path.basename(existing_model)}\")\n",
    "print(f\"  ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {existing_model}\")\n",
    "print(f\"  ğŸ“Š ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "print(f\"  ğŸ“ ê²°ê³¼ ê²½ë¡œ: {output_base}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3021b",
   "metadata": {},
   "source": [
    "## ğŸš€ **2ë‹¨ê³„: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ**\n",
    "\n",
    "> **FastAPI ì „ì²˜ë¦¬ ì™„ë£Œëœ 32px ìµœì í™” ë°ì´í„°ë¡œ ë°”ë¡œ í•™ìŠµ ì§„í–‰**  \n",
    "> ê¸°ì¡´ ëª¨ë¸ì„ í™œìš©í•œ ì „ì´í•™ìŠµìœ¼ë¡œ ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.  \n",
    "> **ë„¤ì´ë°**: `damage_detection_YYYYMMDD_HHMM` í˜•ì‹ìœ¼ë¡œ ìë™ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ 2ë‹¨ê³„: YOLOv11s ì†Œë‚˜ë¬´ ì „ìš© í•™ìŠµ ì¤€ë¹„ (T4 GPU ìµœì í™”)\n",
    "print(\"ğŸŒ² YOLOv11s ì†Œë‚˜ë¬´ í”¼í•´ëª© íƒì§€ í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"ğŸ¯ T4 GPU ìµœì í™” + FastAPI ì „ì²˜ë¦¬ 32px ë°”ìš´ë”© ë°•ìŠ¤\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# \udd04 ë©”ëª¨ë¦¬ ì‚¬ì „ ì •ë¦¬ (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# ğŸ” 1ë‹¨ê³„ ì—°ê²° í™•ì¸ (ì•ˆì „í•œ ê¸°ë³¸ê°’)\n",
    "existing_model = globals().get('existing_model', 'yolo11s.pt')\n",
    "data_path = globals().get('data_path', '/content/drive/MyDrive/pinetree_scan/training_data')\n",
    "\n",
    "print(f\"ğŸ“¦ ì‚¬ìš©í•  ëª¨ë¸: {existing_model}\")\n",
    "print(f\"ğŸ“‚ ë°ì´í„° ê¸°ë³¸ ê²½ë¡œ: {data_path}\")\n",
    "\n",
    "# ğŸ“Š ë°ì´í„°ì…‹ ë‹¨ê³„ë³„ íƒì§€ (ë³‘ëª© ë°©ì§€)\n",
    "print(\"\\nğŸ” FastAPI ì „ì²˜ë¦¬ ë°ì´í„°ì…‹ íƒì§€ ì¤‘...\")\n",
    "\n",
    "# T4 GPU ìµœì í™” ê²½ë¡œ ìˆœì„œ (ë¹ ë¥¸ ì ‘ê·¼ë¶€í„°)\n",
    "data_search_paths = [\n",
    "    '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml',\n",
    "    f\"{data_path}/data.yaml\",\n",
    "    '/content/training_data/data.yaml',\n",
    "    '/content/drive/MyDrive/training_data/data.yaml',\n",
    "    './data/data.yaml'\n",
    "]\n",
    "\n",
    "data_yaml_path = None\n",
    "for i, path in enumerate(data_search_paths, 1):\n",
    "    print(f\"  {i}. ê²½ë¡œ í™•ì¸: {path}\")\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            data_yaml_path = path\n",
    "            print(f\"âœ… ë°ì´í„°ì…‹ ë°œê²¬: {path}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"âŒ ì—†ìŒ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì ‘ê·¼ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "if not data_yaml_path:\n",
    "    print(\"\\nâš ï¸ data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ Google Driveì— FastAPI ì „ì²˜ë¦¬ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # ì•ˆì „í•œ ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    data_yaml_path = '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml'\n",
    "    print(f\"ğŸ”§ ê¸°ë³¸ ê²½ë¡œë¡œ ì„¤ì •: {data_yaml_path}\")\n",
    "\n",
    "# ğŸ“Š ë°ì´í„°ì…‹ ê°„ë‹¨ ê²€ì¦ (ë³‘ëª© ë°©ì§€)\n",
    "data_valid = False\n",
    "if data_yaml_path and os.path.exists(data_yaml_path):\n",
    "    try:\n",
    "        print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸ ì¤‘...\")\n",
    "        \n",
    "        # YAML íŒŒì¼ ë¹ ë¥¸ ê²€ì¦\n",
    "        import yaml\n",
    "        with open(data_yaml_path, 'r', encoding='utf-8') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        print(f\"  \udcc2 ë°ì´í„° ê²½ë¡œ: {data_config.get('path', 'ë¯¸ì„¤ì •')}\")\n",
    "        print(f\"  ğŸ·ï¸ í´ë˜ìŠ¤: {data_config.get('names', ['í”¼í•´ëª©'])}\")\n",
    "        \n",
    "        # í´ë” ì¡´ì¬ í™•ì¸ (ê°œìˆ˜ëŠ” ë‚˜ì¤‘ì—)\n",
    "        data_dir = os.path.dirname(data_yaml_path)\n",
    "        train_dir = os.path.join(data_dir, 'train', 'images')\n",
    "        val_dir = os.path.join(data_dir, 'val', 'images')\n",
    "        \n",
    "        if os.path.exists(train_dir) and os.path.exists(val_dir):\n",
    "            print(f\"  âœ… train/val í´ë” í™•ì¸ ì™„ë£Œ\")\n",
    "            data_valid = True\n",
    "        else:\n",
    "            print(f\"  âŒ train/val í´ë” ì—†ìŒ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ¤– ëª¨ë¸ ë‹¨ê³„ë³„ ë¡œë“œ (ì•ˆì „í•œ ë¡œë”©)\n",
    "print(f\"\\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì‹œì‘...\")\n",
    "model_ready = False\n",
    "\n",
    "try:\n",
    "    print(f\"  ğŸ“¥ {existing_model} ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    # T4 GPUìš© ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ\n",
    "    model = YOLO(existing_model)\n",
    "    \n",
    "    # ëª¨ë¸ ê²€ì¦ (ê°„ë‹¨íˆ)\n",
    "    if hasattr(model, 'model'):\n",
    "        print(f\"  âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "        model_ready = True\n",
    "    else:\n",
    "        print(f\"  âš ï¸ ëª¨ë¸ êµ¬ì¡° ì´ìƒ\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(f\"  \udd04 ê¸°ë³¸ YOLOv11s ëª¨ë¸ë¡œ ì¬ì‹œë„...\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO('yolo11s.pt')\n",
    "        existing_model = 'yolo11s.pt'\n",
    "        model_ready = True\n",
    "        print(f\"  âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"  âŒ ê¸°ë³¸ ëª¨ë¸ë§ˆì € ì‹¤íŒ¨: {e2}\")\n",
    "\n",
    "# ğŸ–¥ï¸ T4 GPU ìµœì í™” ì„¤ì •\n",
    "if model_ready:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"\\nğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device.upper()}\")\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        # T4 GPU ë©”ëª¨ë¦¬ ì •ë³´\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        total_memory = gpu_props.total_memory / 1024**3\n",
    "        current_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        free_memory = total_memory - current_memory\n",
    "        \n",
    "        print(f\"ğŸ’¾ T4 GPU ë©”ëª¨ë¦¬: {total_memory:.1f}GB ì´ / {free_memory:.1f}GB ì‚¬ìš©ê°€ëŠ¥\")\n",
    "        \n",
    "        # T4 GPU ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° (ì•ˆì •ì„± ìš°ì„ )\n",
    "        batch_size = 8  # T4 GPU + YOLOv11s + 640px ê¸°ë³¸ê°’\n",
    "        \n",
    "        print(f\"ğŸ¯ T4 GPU ê¸°ë³¸ ì„¤ì •:\")\n",
    "        print(f\"  ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size} (ì•ˆì •ì„± ìš°ì„ )\")\n",
    "        print(f\"  ğŸ¯ ì´ìœ : ë©”ëª¨ë¦¬ ì•ˆì „ + ì•ˆì •ì  í•™ìŠµ\")\n",
    "        print(f\"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~10GB (T4 15GB ê¸°ì¤€)\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •\n",
    "        if free_memory < 10:\n",
    "            if free_memory >= 8:\n",
    "                batch_size = 6\n",
    "                print(f\"  âš ï¸ ë©”ëª¨ë¦¬ ì¡°ì •: ë°°ì¹˜ í¬ê¸° 6ìœ¼ë¡œ ë³€ê²½\")\n",
    "            elif free_memory >= 6:\n",
    "                batch_size = 4\n",
    "                print(f\"  âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° 4ë¡œ ì•ˆì „ ëª¨ë“œ\")\n",
    "            else:\n",
    "                batch_size = 2\n",
    "                print(f\"  âŒ ë©”ëª¨ë¦¬ ì‹¬ê° ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° 2ë¡œ ìµœì†Œ ëª¨ë“œ\")\n",
    "        else:\n",
    "            print(f\"  âœ… ë©”ëª¨ë¦¬ ì¶©ë¶„: ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ì•ˆì •ì  í•™ìŠµ\")\n",
    "        \n",
    "        # ì¶”ê°€ ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "        torch.backends.cudnn.benchmark = False  # ì•ˆì •ì„± ìš°ì„ \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "    else:\n",
    "        batch_size = 2  # CPU ëª¨ë“œ\n",
    "        print(f\"ğŸ“¦ CPU ëª¨ë“œ ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "    \n",
    "    # ğŸŒ ì „ì—­ ë³€ìˆ˜ ì„¤ì • (ë‹¤ìŒ ë‹¨ê³„ ì—°ê²°)\n",
    "    globals().update({\n",
    "        'model': model,\n",
    "        'data_yaml_path': data_yaml_path,\n",
    "        'batch_size': batch_size,\n",
    "        'device': device,\n",
    "        'model_ready': True,\n",
    "        'data_valid': data_valid,\n",
    "        'existing_model': existing_model\n",
    "    })\n",
    "    \n",
    "    # âœ… ì¤€ë¹„ ì™„ë£Œ ìƒíƒœ ì¶œë ¥\n",
    "    print(f\"\\nâœ… 2ë‹¨ê³„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(f\"  ğŸ¤– ëª¨ë¸: {existing_model}\")\n",
    "    print(f\"  ğŸ“Š ë°ì´í„°: {'ìœ íš¨' if data_valid else 'í™•ì¸í•„ìš”'}\")\n",
    "    print(f\"  ğŸ¯ ë°°ì¹˜ í¬ê¸°: {batch_size} (T4 ìµœì í™”)\")\n",
    "    print(f\"  ğŸ’¾ ë©”ëª¨ë¦¬: {'ì•ˆì „' if device == 'cuda' and free_memory >= 8 else 'ì£¼ì˜'}\")\n",
    "    \n",
    "    if not data_valid:\n",
    "        print(f\"\\nâš ï¸ ë°ì´í„° í™•ì¸ í•„ìš”:\")\n",
    "        print(f\"  1. Google Driveì— training_data í´ë” ì—…ë¡œë“œ í™•ì¸\")\n",
    "        print(f\"  2. data.yaml, train/, val/ í´ë” êµ¬ì¡° í™•ì¸\")\n",
    "        print(f\"  3. FastAPI ì „ì²˜ë¦¬ ì™„ë£Œ í™•ì¸\")\n",
    "\n",
    "else:\n",
    "    globals()['model_ready'] = False\n",
    "    print(f\"\\nâŒ 2ë‹¨ê³„ ì¤€ë¹„ ì‹¤íŒ¨!\")\n",
    "    print(f\"ğŸ’¡ í•´ê²°ë°©ë²•:\")\n",
    "    print(f\"  1. ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ë‹¤ì‹œ ì‹œë„\")\n",
    "    print(f\"  2. 1ë‹¨ê³„ë¶€í„° ìˆœì°¨ ì‹¤í–‰\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”„ ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ì…€(í•™ìŠµ ì‹¤í–‰)ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ 2ë‹¨ê³„: YOLOv11s 32px ìµœì í™” í•™ìŠµ ì‹¤í–‰ (T4 GPU ì•ˆì „ ëª¨ë“œ)\n",
    "print(\"ğŸš€ 2ë‹¨ê³„: YOLOv11s 32px ìµœì í™” í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"ğŸ¯ T4 GPU ì•ˆì „ ìµœì í™” + ê°œë³„ ë‚˜ë¬´ íƒì§€ë¥¼ ìœ„í•œ 32px ë°”ìš´ë”©ë°•ìŠ¤\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ§¹ ë©”ëª¨ë¦¬ ì‚¬ì „ ì •ë¦¬ (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë¸ í™•ì¸ (ì¤€ë¹„ ë‹¨ê³„ì—ì„œ ì„¤ì •ë¨)\n",
    "existing_model = globals().get('existing_model', 'yolo11s.pt')\n",
    "data_yaml_path = globals().get('data_yaml_path', '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml')\n",
    "device = globals().get('device', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_ready = globals().get('model_ready', False)\n",
    "\n",
    "print(f\"ğŸ“¦ ì‚¬ìš© ëª¨ë¸: {existing_model}\")\n",
    "print(f\"ğŸ“Š ë°ì´í„° ê²½ë¡œ: {data_yaml_path}\")\n",
    "print(f\"ğŸ–¥ï¸ ì‹¤í–‰ ì¥ì¹˜: {device}\")\n",
    "print(f\"âœ… ëª¨ë¸ ì¤€ë¹„: {'ì™„ë£Œ' if model_ready else 'ë¯¸ì™„ë£Œ'}\")\n",
    "\n",
    "# 2ë‹¨ê³„ ì¤€ë¹„ ìƒíƒœ í™•ì¸\n",
    "if not model_ready:\n",
    "    print(\"âŒ 2ë‹¨ê³„ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ì´ì „ ì…€(2ë‹¨ê³„ ì¤€ë¹„)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    # ê°•ì œ ì¢…ë£Œí•˜ì§€ ì•Šê³  ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰\n",
    "    model_ready = True\n",
    "\n",
    "# ğŸ“Š ë°ì´í„° íŒŒì¼ ìµœì¢… í™•ì¸ ë° ê²½ë¡œ ìˆ˜ì •\n",
    "data_exists = os.path.exists(data_yaml_path)\n",
    "print(f\"\\nğŸ“Š ë°ì´í„° íŒŒì¼ ìƒíƒœ: {'âœ… ì¡´ì¬' if data_exists else 'âŒ ì—†ìŒ'}\")\n",
    "\n",
    "if not data_exists:\n",
    "    print(\"âš ï¸ FastAPI ì „ì²˜ë¦¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ëŒ€ì²´ ê²½ë¡œ ìë™ íƒì§€\n",
    "    alternative_paths = [\n",
    "        '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml',\n",
    "        '/content/drive/MyDrive/training_data/data.yaml', \n",
    "        '/content/training_data/data.yaml',\n",
    "        './data/data.yaml'\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ” ëŒ€ì²´ ê²½ë¡œ íƒìƒ‰ ì¤‘...\")\n",
    "    for i, alt_path in enumerate(alternative_paths, 1):\n",
    "        print(f\"  {i}. {alt_path}: {'âœ…' if os.path.exists(alt_path) else 'âŒ'}\")\n",
    "        if os.path.exists(alt_path):\n",
    "            data_yaml_path = alt_path\n",
    "            data_exists = True\n",
    "            print(f\"âœ… ëŒ€ì²´ ê²½ë¡œì—ì„œ ë°œê²¬: {alt_path}\")\n",
    "            break\n",
    "    \n",
    "    if not data_exists:\n",
    "        print(\"âŒ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ’¡ í•´ê²°ë°©ë²•:\")\n",
    "        print(\"  1. Google Driveì— training_data í´ë” ì—…ë¡œë“œ\")\n",
    "        print(\"  2. 1ë‹¨ê³„ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "\n",
    "# ğŸ”§ data.yaml ê²½ë¡œ ìˆ˜ì • í•¨ìˆ˜\n",
    "def fix_data_yaml_paths(yaml_path):\n",
    "    \"\"\"data.yaml íŒŒì¼ì˜ ê²½ë¡œë¥¼ í˜„ì¬ ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •\"\"\"\n",
    "    try:\n",
    "        import yaml\n",
    "        \n",
    "        # ì›ë³¸ íŒŒì¼ ì½ê¸°\n",
    "        with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        print(f\"ğŸ“„ ì›ë³¸ data.yaml ë‚´ìš©:\")\n",
    "        print(f\"  path: {data_config.get('path', 'ì—†ìŒ')}\")\n",
    "        print(f\"  train: {data_config.get('train', 'ì—†ìŒ')}\")\n",
    "        print(f\"  val: {data_config.get('val', 'ì—†ìŒ')}\")\n",
    "        \n",
    "        # ë°ì´í„° í´ë” ê²½ë¡œ í™•ì¸\n",
    "        data_dir = os.path.dirname(yaml_path)\n",
    "        print(f\"  ë°ì´í„° í´ë”: {data_dir}\")\n",
    "        \n",
    "        # ì‹¤ì œ í´ë” êµ¬ì¡° í™•ì¸\n",
    "        train_images = os.path.join(data_dir, 'train', 'images')\n",
    "        val_images = os.path.join(data_dir, 'val', 'images')\n",
    "        train_labels = os.path.join(data_dir, 'train', 'labels')\n",
    "        val_labels = os.path.join(data_dir, 'val', 'labels')\n",
    "        \n",
    "        print(f\"ğŸ” í´ë” êµ¬ì¡° í™•ì¸:\")\n",
    "        print(f\"  train/images: {'âœ…' if os.path.exists(train_images) else 'âŒ'}\")\n",
    "        print(f\"  val/images: {'âœ…' if os.path.exists(val_images) else 'âŒ'}\")\n",
    "        print(f\"  train/labels: {'âœ…' if os.path.exists(train_labels) else 'âŒ'}\")  \n",
    "        print(f\"  val/labels: {'âœ…' if os.path.exists(val_labels) else 'âŒ'}\")\n",
    "        \n",
    "        # ê²½ë¡œ ìˆ˜ì •\n",
    "        data_config['path'] = data_dir  # ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •\n",
    "        data_config['train'] = 'train/images'  # ìƒëŒ€ ê²½ë¡œ\n",
    "        data_config['val'] = 'val/images'      # ìƒëŒ€ ê²½ë¡œ\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ì •ë³´ í™•ì¸/ì„¤ì •\n",
    "        if 'names' not in data_config:\n",
    "            data_config['names'] = ['damaged_tree']  # ê¸°ë³¸ í´ë˜ìŠ¤ëª…\n",
    "        \n",
    "        if 'nc' not in data_config:\n",
    "            data_config['nc'] = len(data_config['names'])\n",
    "        \n",
    "        # ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥\n",
    "        fixed_yaml_path = os.path.join(data_dir, 'data_fixed.yaml')\n",
    "        with open(fixed_yaml_path, 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)\n",
    "        \n",
    "        print(f\"âœ… ìˆ˜ì •ëœ data.yaml ìƒì„±: {fixed_yaml_path}\")\n",
    "        print(f\"ğŸ“„ ìˆ˜ì •ëœ ë‚´ìš©:\")\n",
    "        print(f\"  path: {data_config['path']}\")\n",
    "        print(f\"  train: {data_config['train']}\")\n",
    "        print(f\"  val: {data_config['val']}\")\n",
    "        print(f\"  names: {data_config['names']}\")\n",
    "        print(f\"  nc: {data_config['nc']}\")\n",
    "        \n",
    "        return fixed_yaml_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ data.yaml ìˆ˜ì • ì‹¤íŒ¨: {e}\")\n",
    "        return yaml_path\n",
    "\n",
    "# ë°ì´í„° YAML ê²½ë¡œ ìˆ˜ì • ì‹¤í–‰\n",
    "if data_exists:\n",
    "    print(f\"\\nğŸ”§ data.yaml ê²½ë¡œ ìˆ˜ì • ì¤‘...\")\n",
    "    fixed_data_yaml_path = fix_data_yaml_paths(data_yaml_path)\n",
    "    data_yaml_path = fixed_data_yaml_path\n",
    "\n",
    "# ë°°ì¹˜ í¬ê¸° ì„¤ì • (GPU/CPUì— ë”°ë¼)\n",
    "if device == 'cuda':\n",
    "    # T4 GPU ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°\n",
    "    batch_size = 8  # T4 GPU + YOLOv11s + 640px ê¸°ë³¸ê°’\n",
    "    \n",
    "    print(f\"\\nğŸ¯ T4 GPU ê¸°ë³¸ ì„¤ì •:\")\n",
    "    print(f\"  ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size} (ì•ˆì •ì„± ìš°ì„ )\")\n",
    "    print(f\"  ğŸ¯ ì´ìœ : ë©”ëª¨ë¦¬ ì•ˆì „ + ì•ˆì •ì  í•™ìŠµ\")\n",
    "    print(f\"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~10GB (T4 15GB ê¸°ì¤€)\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ë° ìë™ ì¡°ì •\n",
    "    try:\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        total_memory = gpu_props.total_memory / 1024**3\n",
    "        allocated_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        free_memory = total_memory - allocated_memory\n",
    "        \n",
    "        print(f\"  ğŸ’¾ GPU ë©”ëª¨ë¦¬: {free_memory:.1f}GB ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        \n",
    "        if free_memory < 10:\n",
    "            if free_memory >= 8:\n",
    "                batch_size = 6\n",
    "                print(f\"  âš ï¸ ë©”ëª¨ë¦¬ ì¡°ì •: ë°°ì¹˜ í¬ê¸° 6ìœ¼ë¡œ ë³€ê²½\")\n",
    "            elif free_memory >= 6:\n",
    "                batch_size = 4\n",
    "                print(f\"  âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° 4ë¡œ ì•ˆì „ ëª¨ë“œ\")\n",
    "            else:\n",
    "                batch_size = 2\n",
    "                print(f\"  âŒ ë©”ëª¨ë¦¬ ì‹¬ê° ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° 2ë¡œ ìµœì†Œ ëª¨ë“œ\")\n",
    "        else:\n",
    "            print(f\"  âœ… ë©”ëª¨ë¦¬ ì¶©ë¶„: ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ì•ˆì •ì  í•™ìŠµ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ GPU ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"  ğŸ“¦ ë°°ì¹˜ í¬ê¸° {batch_size} ìœ ì§€ (ê¸°ë³¸ê°’)\")\n",
    "        \n",
    "else:\n",
    "    batch_size = 2  # CPU ëª¨ë“œ\n",
    "    print(f\"\\nğŸ“¦ CPU ëª¨ë“œ ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "\n",
    "# í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì‹¤í–‰ëª… ìƒì„±\n",
    "run_name = f\"damage_detection_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "# í”„ë¡œì íŠ¸ í´ë” ìƒì„±\n",
    "project_dir = \"pinetree_yolov11s\"\n",
    "if not os.path.exists(project_dir):\n",
    "    os.makedirs(project_dir)\n",
    "    print(f\"ğŸ“ í”„ë¡œì íŠ¸ í´ë” ìƒì„±: {project_dir}\")\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "globals().update({\n",
    "    'run_name': run_name,\n",
    "    'batch_size': batch_size,\n",
    "    'data_yaml_path': data_yaml_path\n",
    "})\n",
    "\n",
    "# ğŸš€ í•™ìŠµ ì‹¤í–‰ (ë°ì´í„° ì¡´ì¬í•  ë•Œë§Œ)\n",
    "if data_exists and model_ready:\n",
    "    try:\n",
    "        print(f\"\\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ (ì•ˆì „ ëª¨ë“œ)\n",
    "        if 'model' in globals():\n",
    "            print(\"âœ… ê¸°ì¡´ ëª¨ë¸ ì¬ì‚¬ìš©\")\n",
    "        else:\n",
    "            model = YOLO(existing_model)\n",
    "            print(f\"âœ… ìƒˆ ëª¨ë¸ ë¡œë“œ: {existing_model}\")\n",
    "        \n",
    "        # T4 GPU ì•ˆì „ í•™ìŠµ ì„¤ì • (YOLO ê¸°ë³¸ê°’)\n",
    "        training_config = {\n",
    "            # ğŸ¯ ê¸°ë³¸ YOLO ì„¤ì •\n",
    "            'data': data_yaml_path,\n",
    "            'epochs': 200,                  # ê¸°ë³¸ ì—í¬í¬\n",
    "            'patience': 75,                 # ê¸°ë³¸ ì°¸ì„ì„±\n",
    "            'batch': batch_size,\n",
    "            'imgsz': 640,\n",
    "            'save': True,\n",
    "            'save_period': 10,\n",
    "            'cache': False,                 # T4 ì•ˆì „ì„± ìœ ì§€\n",
    "            'device': device,\n",
    "            'workers': 2,\n",
    "            'project': project_dir,\n",
    "            'name': run_name,\n",
    "            'exist_ok': True,\n",
    "            'pretrained': True,\n",
    "            'verbose': True,\n",
    "            \n",
    "            # ğŸ§  ê¸°ë³¸ YOLO ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "            'optimizer': 'SGD',             # ê¸°ë³¸ SGD ì˜µí‹°ë§ˆì´ì €\n",
    "            'lr0': 0.001,                   # ê¸°ë³¸ í•™ìŠµë¥ \n",
    "            'lrf': 0.1,                     # ê¸°ë³¸ ìµœì¢… í•™ìŠµë¥ \n",
    "            'momentum': 0.937,              # YOLO ê¸°ë³¸ê°’\n",
    "            'weight_decay': 0.0005,         # ê¸°ë³¸ ì •ê·œí™”\n",
    "            'warmup_epochs': 3,             # ê¸°ë³¸ ì›Œë°ì—…\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,          # ê¸°ë³¸ í¸í–¥ í•™ìŠµë¥ \n",
    "            \n",
    "            # ğŸ¨ ê¸°ë³¸ ë°ì´í„° ì¦ê°•\n",
    "            'hsv_h': 0.015,                 # ê¸°ë³¸ ìƒ‰ìƒ ë³€í™”\n",
    "            'hsv_s': 0.7,                   # ê¸°ë³¸ ì±„ë„ ë³€í™”\n",
    "            'hsv_v': 0.4,                   # ê¸°ë³¸ ë°ê¸° ë³€í™”\n",
    "            'degrees': 0.0,                 # íšŒì „ ë¹„í™œì„±í™”\n",
    "            'translate': 0.1,               # ê¸°ë³¸ ì´ë™\n",
    "            'scale': 0.5,                   # ê¸°ë³¸ ìŠ¤ì¼€ì¼\n",
    "            'shear': 0.0,                   # ì „ë‹¨ ë¹„í™œì„±í™”\n",
    "            'perspective': 0.0,             # ì›ê·¼ ë¹„í™œì„±í™”\n",
    "            'flipud': 0.0,                  # ìƒí•˜ ë’¤ì§‘ê¸° ë¹„í™œì„±í™”\n",
    "            'fliplr': 0.5,                  # ê¸°ë³¸ ì¢Œìš° ë’¤ì§‘ê¸°\n",
    "            'mosaic': 1.0,                  # ê¸°ë³¸ ëª¨ìì´í¬\n",
    "            'mixup': 0.0,                   # ë¯¹ìŠ¤ì—… ë¹„í™œì„±í™”\n",
    "            'copy_paste': 0.0,              # ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ë¹„í™œì„±í™”\n",
    "            \n",
    "            # ğŸ›¡ï¸ ì•ˆì „í•œ í•™ìŠµ ì„¤ì •\n",
    "            'amp': False,                   # AMP ë¹„í™œì„±í™” ìœ ì§€\n",
    "            'fraction': 1.0,\n",
    "            'profile': False,\n",
    "            'freeze': None,\n",
    "            'dropout': 0.0,\n",
    "            'val': True,\n",
    "            'plots': True,\n",
    "            'save_json': True,\n",
    "            'save_txt': True,\n",
    "            'save_conf': True,\n",
    "            \n",
    "            # ğŸŒ² ê¸°ë³¸ YOLO ì„¤ì •\n",
    "            'rect': False,\n",
    "            'single_cls': True,             # ë‹¨ì¼ í´ë˜ìŠ¤ ìœ ì§€\n",
    "            'cos_lr': False,                # ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ë§ ë¹„í™œì„±í™”\n",
    "            'close_mosaic': 10,             # ê¸°ë³¸ ëª¨ìì´í¬ ì¢…ë£Œ\n",
    "            'label_smoothing': 0.0,         # ë¼ë²¨ ìŠ¤ë¬´ë”© ë¹„í™œì„±í™”\n",
    "            'nbs': 64,                      # ëª…ëª© ë°°ì¹˜ í¬ê¸°\n",
    "            \n",
    "            # ğŸ¯ ê¸°ë³¸ íƒì§€ ì„¤ì •\n",
    "            'conf': 0.25,                   # ê¸°ë³¸ ì‹ ë¢°ë„\n",
    "            'iou': 0.45,                    # ê¸°ë³¸ IoU\n",
    "            'max_det': 300,                 # ê¸°ë³¸ íƒì§€ ìˆ˜\n",
    "            \n",
    "            # ğŸ”¬ ê¸°ë³¸ ì†ì‹¤ í•¨ìˆ˜\n",
    "            'box': 7.5,                     # ê¸°ë³¸ ë°•ìŠ¤ ì†ì‹¤\n",
    "            'cls': 0.5,                     # ê¸°ë³¸ ë¶„ë¥˜ ì†ì‹¤\n",
    "            'dfl': 1.5,                     # ê¸°ë³¸ DFL ì†ì‹¤\n",
    "        }\n",
    "        \n",
    "        # ì„¤ì • ìš”ì•½ ì¶œë ¥\n",
    "        print(f\"\\nğŸ¯ YOLO ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µì›:\")\n",
    "        print(f\"  ğŸ“‚ í”„ë¡œì íŠ¸: pinetree_yolov11s\")\n",
    "        print(f\"  ğŸ“… ì‹¤í–‰ëª…: {run_name}\")\n",
    "        print(f\"  ğŸ† ëª¨ë¸: {existing_model}\")\n",
    "        print(f\"  ğŸ“Š ë°ì´í„°: {os.path.basename(data_yaml_path)}\")\n",
    "        print(f\"  ğŸ“ ë°”ìš´ë”©ë°•ìŠ¤: 32px (ê°œë³„ ë‚˜ë¬´ ìµœì í™”)\")\n",
    "        print(f\"  ğŸ¯ ë°°ì¹˜ í¬ê¸°: {batch_size} (T4 ì•ˆì „)\")\n",
    "        print(f\"  ğŸ§  ì˜µí‹°ë§ˆì´ì €: SGD (ê¸°ë³¸)\")\n",
    "        print(f\"  ğŸ“š ì—í¬í¬: 200 (ê¸°ë³¸)\")\n",
    "        print(f\"  ğŸ¨ ì¦ê°•: ê¸°ë³¸ ì„¤ì • (ì•ˆì •ì„± ìš°ì„ )\")\n",
    "        print(f\"  ğŸ” íƒì§€: ê¸°ë³¸ ì„ê³„ê°’\")\n",
    "        print(f\"  ğŸ’¾ ì›Œì»¤: 2ê°œ (ë³‘ëª© ë°©ì§€)\")\n",
    "        print(f\"  ğŸ”§ ê²½ë¡œ ìˆ˜ì •: data.yaml ì ˆëŒ€ê²½ë¡œë¡œ ìˆ˜ì • ì™„ë£Œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ”¥ YOLO ê¸°ë³¸ ì„¤ì • í•™ìŠµ ì‹œì‘!\")\n",
    "        print(f\"â° ì˜ˆìƒ ì‹œê°„: 1-2ì‹œê°„ (ê¸°ë³¸ í•™ìŠµ)\")\n",
    "        print(f\"ğŸ¯ ëª©í‘œ: ì•ˆì •ì  í•™ìŠµ, ì˜¤íƒì§€ ìµœì†Œí™”!\")\n",
    "        \n",
    "        # ğŸš€ í•™ìŠµ ì‹¤í–‰\n",
    "        results = model.train(**training_config)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ YOLO ê¸°ë³¸ ì„¤ì • í•™ìŠµ ì™„ë£Œ!\")\n",
    "        \n",
    "        # ê²°ê³¼ ë¶„ì„\n",
    "        if hasattr(results, 'box') and results.box is not None:\n",
    "            try:\n",
    "                map50 = float(results.box.map50)\n",
    "                map50_95 = float(results.box.map)\n",
    "                precision = float(results.box.mp)  \n",
    "                recall = float(results.box.mr)\n",
    "                \n",
    "                print(f\"ğŸ“ˆ ìµœì¢… ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "                print(f\"  ğŸ“ˆ mAP50: {map50:.4f} ({map50*100:.1f}%)\")\n",
    "                print(f\"  ğŸ“ˆ mAP50-95: {map50_95:.4f} ({map50_95*100:.1f}%)\")\n",
    "                print(f\"  ğŸ¯ Precision: {precision:.4f} ({precision*100:.1f}%)\")\n",
    "                print(f\"  ğŸ” Recall: {recall:.4f} ({recall*100:.1f}%)\")\n",
    "                \n",
    "                # ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€\n",
    "                print(f\"\\nğŸ¯ ê¸°ë³¸ ì„±ëŠ¥ ë¶„ì„:\")\n",
    "                if map50 > 0.7:\n",
    "                    print(\"âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥! ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œë„ ì¢‹ì€ ê²°ê³¼!\")\n",
    "                elif map50 > 0.6:\n",
    "                    print(\"âœ… ì–‘í˜¸í•œ ì„±ëŠ¥! ì‹¤ìš©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥!\")\n",
    "                elif map50 > 0.5:\n",
    "                    print(\"âš ï¸ ì ì ˆí•œ ì„±ëŠ¥. ì¶”ê°€ í•™ìŠµ ê³ ë ¤\")\n",
    "                else:\n",
    "                    print(\"âŒ ì„±ëŠ¥ ë¶€ì¡±. ë°ì´í„° í™•ì¸ í•„ìš”\")\n",
    "                \n",
    "                if precision > 0.7:\n",
    "                    print(\"ğŸ¯ ì •ë°€ë„: ìš°ìˆ˜ (ì˜¤íƒì§€ ë‚®ìŒ)\")\n",
    "                elif precision > 0.6:\n",
    "                    print(\"ğŸ¯ ì •ë°€ë„: ì–‘í˜¸\")\n",
    "                else:\n",
    "                    print(\"ğŸ¯ ì •ë°€ë„: ê°œì„  í•„ìš”\")\n",
    "                \n",
    "                if recall > 0.7:\n",
    "                    print(\"ğŸ” íƒì§€ìœ¨: ìš°ìˆ˜\")\n",
    "                elif recall > 0.6:\n",
    "                    print(\"ğŸ” íƒì§€ìœ¨: ì–‘í˜¸\")\n",
    "                else:\n",
    "                    print(\"ğŸ” íƒì§€ìœ¨: ê°œì„  í•„ìš”\")\n",
    "                \n",
    "                # ì„±ëŠ¥ ë°ì´í„° ì €ì¥\n",
    "                globals()['model_performance'] = {\n",
    "                    'mAP50': map50,\n",
    "                    'mAP50_95': map50_95,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ì„±ëŠ¥ ì§€í‘œ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # ëª¨ë¸ ê²½ë¡œ ì €ì¥\n",
    "        best_model_path = f\"{project_dir}/{run_name}/weights/best.pt\"\n",
    "        globals().update({\n",
    "            'best_model_path': best_model_path,\n",
    "            'model': model,\n",
    "            'training_completed': True\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ í•™ìŠµ ì™„ë£Œ íŒŒì¼:\")\n",
    "        print(f\"  ğŸ† ìµœê³  ëª¨ë¸: {best_model_path}\")\n",
    "        print(f\"  ğŸ“Š í•™ìŠµ ê²°ê³¼: {project_dir}/{run_name}/results.csv\")\n",
    "        print(f\"  ğŸ“ˆ ì„±ëŠ¥ ê·¸ë˜í”„: {project_dir}/{run_name}/results.png\")\n",
    "        \n",
    "        print(f\"\\nâœ… T4 GPU 32px ìµœì í™” í•™ìŠµ ì„±ê³µ!\")\n",
    "        print(f\"ğŸ¯ ë‹¤ìŒ: 3ë‹¨ê³„(ê²€ì¦) â†’ 4ë‹¨ê³„(ë°±ì—… ë° í…ŒìŠ¤íŠ¸) ì‹¤í–‰!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ğŸ’¡ í•´ê²°ë°©ë²•:\")\n",
    "        print(f\"  1. ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "        print(f\"  2. GPU ë©”ëª¨ë¦¬ í™•ì¸\") \n",
    "        print(f\"  3. ë°ì´í„° ê²½ë¡œ í™•ì¸\")\n",
    "        print(f\"  4. data.yaml íŒŒì¼ ë‚´ìš© í™•ì¸\")\n",
    "        globals()['training_completed'] = False\n",
    "\n",
    "else:\n",
    "    print(\"âŒ í•™ìŠµ ì‹¤í–‰ ì¡°ê±´ ë¯¸ì¶©ì¡±!\")\n",
    "    if not data_exists:\n",
    "        print(\"  ğŸ“Š ë°ì´í„° íŒŒì¼ ì—†ìŒ\")\n",
    "    if not model_ready:\n",
    "        print(\"  ğŸ¤– ëª¨ë¸ ì¤€ë¹„ ë¯¸ì™„ë£Œ\")\n",
    "    print(\"ğŸ’¡ ì´ì „ ë‹¨ê³„ë“¤ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "    globals()['training_completed'] = False\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” ì‹¤ì‹œê°„ mAP ëª¨ë‹ˆí„°ë§ ë„êµ¬ (í•™ìŠµ ì¤‘ ë³€ë™ ë¶„ì„)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def monitor_training_progress():\n",
    "    \"\"\"í•™ìŠµ ì§„í–‰ìƒí™©ê³¼ mAP ë³€ë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š ì‹¤ì‹œê°„ mAP ëª¨ë‹ˆí„°ë§ ë„êµ¬\")\n",
    "    print(\"ğŸ¯ í•™ìŠµ ì¤‘ mAP ë³€ë™ ì›ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ íƒì§€\n",
    "    results_paths = []\n",
    "    \n",
    "    # ê°€ëŠ¥í•œ ê²°ê³¼ íŒŒì¼ ê²½ë¡œë“¤\n",
    "    search_patterns = [\n",
    "        'pinetree_yolov11s/damage_detection_*/results.csv',\n",
    "        'runs/train/damage_detection_*/results.csv',\n",
    "        'runs/train/train*/results.csv'\n",
    "    ]\n",
    "    \n",
    "    import glob\n",
    "    for pattern in search_patterns:\n",
    "        matches = glob.glob(pattern)\n",
    "        results_paths.extend(matches)\n",
    "    \n",
    "    if not results_paths:\n",
    "        print(\"âš ï¸ ì•„ì§ í•™ìŠµ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        print(\"ğŸ’¡ í•™ìŠµì´ ì‹œì‘ë˜ë©´ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë©ë‹ˆë‹¤\")\n",
    "        return\n",
    "    \n",
    "    # ê°€ì¥ ìµœì‹  ê²°ê³¼ íŒŒì¼ ì„ íƒ\n",
    "    latest_results = max(results_paths, key=lambda x: Path(x).stat().st_mtime)\n",
    "    print(f\"ğŸ“„ ëª¨ë‹ˆí„°ë§ íŒŒì¼: {latest_results}\")\n",
    "    \n",
    "    try:\n",
    "        # ê²°ê³¼ ë°ì´í„° ë¡œë“œ\n",
    "        df = pd.read_csv(latest_results)\n",
    "        \n",
    "        if len(df) < 2:\n",
    "            print(\"âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ì—í­ 2ê°œ ì´ìƒ í•„ìš”)\")\n",
    "            return\n",
    "        \n",
    "        # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ\n",
    "        epochs = df['epoch'].values\n",
    "        \n",
    "        # mAP ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°\n",
    "        map_cols = [col for col in df.columns if 'mAP' in col or 'map' in col]\n",
    "        if not map_cols:\n",
    "            map_cols = [col for col in df.columns if 'val' in col and 'map' in col.lower()]\n",
    "        \n",
    "        if map_cols:\n",
    "            map_values = df[map_cols[0]].values\n",
    "            \n",
    "            print(f\"\\nğŸ“ˆ mAP ë³€ë™ ë¶„ì„ (ì´ {len(epochs)}ê°œ ì—í­):\")\n",
    "            print(f\"  ğŸ¯ í˜„ì¬ mAP: {map_values[-1]:.4f}\")\n",
    "            print(f\"  ğŸ“Š ìµœê³  mAP: {np.max(map_values):.4f} (ì—í­ {epochs[np.argmax(map_values)]})\")\n",
    "            print(f\"  ğŸ“‰ ìµœì € mAP: {np.min(map_values):.4f} (ì—í­ {epochs[np.argmin(map_values)]})\")\n",
    "            print(f\"  ğŸ“Š í‰ê·  mAP: {np.mean(map_values):.4f}\")\n",
    "            print(f\"  ğŸ“Š í‘œì¤€í¸ì°¨: {np.std(map_values):.4f}\")\n",
    "            \n",
    "            # mAP ë³€ë™ì„± ë¶„ì„\n",
    "            volatility = np.std(map_values) / np.mean(map_values) if np.mean(map_values) > 0 else 0\n",
    "            \n",
    "            if volatility > 0.5:\n",
    "                print(f\"  ğŸš¨ ë†’ì€ ë³€ë™ì„± ({volatility:.2f}): í•™ìŠµ ë¶ˆì•ˆì •\")\n",
    "                print(f\"     ğŸ’¡ í•´ê²°ë°©ì•ˆ: í•™ìŠµë¥  ê°ì†Œ, ë°°ì¹˜ í¬ê¸° ì¦ê°€\")\n",
    "            elif volatility > 0.3:\n",
    "                print(f\"  âš ï¸ ë³´í†µ ë³€ë™ì„± ({volatility:.2f}): ì¶”ê°€ ëª¨ë‹ˆí„°ë§ í•„ìš”\")\n",
    "            else:\n",
    "                print(f\"  âœ… ë‚®ì€ ë³€ë™ì„± ({volatility:.2f}): ì•ˆì •ì  í•™ìŠµ\")\n",
    "            \n",
    "            # ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„ (ë§ˆì§€ë§‰ 10ê°œ ì—í­)\n",
    "            if len(map_values) >= 10:\n",
    "                recent_values = map_values[-10:]\n",
    "                trend = np.polyfit(range(len(recent_values)), recent_values, 1)[0]\n",
    "                \n",
    "                if trend > 0.001:\n",
    "                    print(f\"  ğŸ“ˆ ìƒìŠ¹ íŠ¸ë Œë“œ: +{trend:.4f}/ì—í­\")\n",
    "                elif trend < -0.001:\n",
    "                    print(f\"  ğŸ“‰ í•˜ë½ íŠ¸ë Œë“œ: {trend:.4f}/ì—í­\")\n",
    "                else:\n",
    "                    print(f\"  â¡ï¸ í‰í‰í•œ íŠ¸ë Œë“œ: ìˆ˜ë ´ ìƒíƒœ\")\n",
    "        \n",
    "        # ì†ì‹¤ í•¨ìˆ˜ ë¶„ì„\n",
    "        loss_cols = [col for col in df.columns if 'loss' in col.lower()]\n",
    "        if loss_cols:\n",
    "            train_loss = df[loss_cols[0]].values\n",
    "            \n",
    "            print(f\"\\nğŸ“‰ ì†ì‹¤ í•¨ìˆ˜ ë¶„ì„:\")\n",
    "            print(f\"  ğŸ¯ í˜„ì¬ ì†ì‹¤: {train_loss[-1]:.4f}\")\n",
    "            print(f\"  ğŸ“Š ìµœì € ì†ì‹¤: {np.min(train_loss):.4f}\")\n",
    "            \n",
    "            # ì†ì‹¤ê³¼ mAP ìƒê´€ê´€ê³„\n",
    "            if map_cols and len(train_loss) == len(map_values):\n",
    "                correlation = np.corrcoef(train_loss, map_values)[0, 1]\n",
    "                print(f\"  ğŸ”— ì†ì‹¤-mAP ìƒê´€ê´€ê³„: {correlation:.3f}\")\n",
    "                \n",
    "                if correlation < -0.7:\n",
    "                    print(f\"     âœ… ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„: ì •ìƒì  í•™ìŠµ\")\n",
    "                elif correlation < -0.3:\n",
    "                    print(f\"     âš ï¸ ì•½í•œ ìƒê´€ê´€ê³„: ê³¼ì í•© ê°€ëŠ¥ì„±\")\n",
    "                else:\n",
    "                    print(f\"     ğŸš¨ ë¹„ì •ìƒì  ìƒê´€ê´€ê³„: í•™ìŠµ ë¬¸ì œ ìˆìŒ\")\n",
    "        \n",
    "        # í•™ìŠµë¥  ë¶„ì„ (ìˆëŠ” ê²½ìš°)\n",
    "        lr_cols = [col for col in df.columns if 'lr' in col.lower()]\n",
    "        if lr_cols:\n",
    "            lr_values = df[lr_cols[0]].values\n",
    "            print(f\"\\nğŸ“š í•™ìŠµë¥  ë¶„ì„:\")\n",
    "            print(f\"  ğŸ¯ í˜„ì¬ í•™ìŠµë¥ : {lr_values[-1]:.6f}\")\n",
    "            print(f\"  ğŸ“Š ì´ˆê¸° í•™ìŠµë¥ : {lr_values[0]:.6f}\")\n",
    "            \n",
    "            # í•™ìŠµë¥  ë³€í™”ê°€ ê¸‰ê²©í•œì§€ í™•ì¸\n",
    "            lr_changes = np.diff(lr_values)\n",
    "            max_change = np.max(np.abs(lr_changes))\n",
    "            \n",
    "            if max_change > lr_values[0] * 0.1:\n",
    "                print(f\"  âš ï¸ ê¸‰ê²©í•œ í•™ìŠµë¥  ë³€í™” ê°ì§€: ìµœëŒ€ {max_change:.6f}\")\n",
    "                print(f\"     ğŸ’¡ ì´ê²ƒì´ mAP ë³€ë™ì˜ ì›ì¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ mAP ì•ˆì •í™” ê¶Œì¥ì‚¬í•­:\")\n",
    "        print(f\"  1. ë°°ì¹˜ í¬ê¸°ë¥¼ 8-16ìœ¼ë¡œ ì¦ê°€\")\n",
    "        print(f\"  2. í•™ìŠµë¥ ì„ 0.005-0.008ë¡œ ê°ì†Œ\")\n",
    "        print(f\"  3. ì›Œë°ì—… ì—í­ì„ 5-10ìœ¼ë¡œ ì¦ê°€\")\n",
    "        print(f\"  4. ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ë§ ë¹„í™œì„±í™”\")\n",
    "        print(f\"  5. ê²€ì¦ ë°ì´í„° í’ˆì§ˆ ì ê²€\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²°ê³¼ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ğŸ’¡ í•™ìŠµì´ ì§„í–‰ ì¤‘ì´ê±°ë‚˜ íŒŒì¼ í˜•ì‹ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "\n",
    "# ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì‹¤í–‰\n",
    "monitor_training_progress()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ”„ í•™ìŠµ ì¤‘ì—ëŠ” ì´ ì…€ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬\")\n",
    "print(\"ğŸ“Š mAP ë³€ë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2dafa",
   "metadata": {},
   "source": [
    "## ğŸ“Š **3ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦**\n",
    "\n",
    "> **í•™ìŠµëœ YOLOv11s ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤**  \n",
    "> ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ì •í™•ë„ ì§€í‘œë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ea2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š 3ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì‹¤í–‰ (T4 GPU ì•ˆì „ ëª¨ë“œ)\n",
    "print(\"ğŸ“Š 3ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì‹œì‘! (T4 GPU ìµœì í™”)\")\n",
    "print(\"ğŸ¯ í•™ìŠµëœ ëª¨ë¸ì˜ ì •í™•ë„ì™€ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
    "print(\"âš¡ T4 GPU ì•ˆì „ ëª¨ë“œ: ë©”ëª¨ë¦¬ ìµœì í™” + ë¬´í•œë¡œë”© ë°©ì§€\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# T4 GPU ë©”ëª¨ë¦¬ ì„ ì œ ì •ë¦¬ (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "import torch\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ ì‚¬ì „ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# í•™ìŠµ ì™„ë£Œ ìƒíƒœ í™•ì¸\n",
    "training_completed = globals().get('training_completed', False)\n",
    "training_results = globals().get('training_results', None)\n",
    "best_model_path = globals().get('best_model_path', None)\n",
    "\n",
    "print(\"ğŸ” í•™ìŠµ ìƒíƒœ í™•ì¸:\")\n",
    "print(f\"  \udcc8 í•™ìŠµ ì™„ë£Œ: {'âœ… ì™„ë£Œ' if training_completed else 'âŒ ë¯¸ì™„ë£Œ'}\")\n",
    "print(f\"  ğŸ“Š í•™ìŠµ ê²°ê³¼: {'âœ… ìˆìŒ' if training_results else 'âŒ ì—†ìŒ'}\")\n",
    "print(f\"  ğŸ¤– ëª¨ë¸ ê²½ë¡œ: {best_model_path if best_model_path else 'âŒ ì—†ìŒ'}\")\n",
    "\n",
    "if not training_completed:\n",
    "    print(\"\\nâŒ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ê¸°ì¡´ ëª¨ë¸ ìë™ íƒì§€ ì‹œë„\n",
    "    print(\"ğŸ” ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ìë™ íƒì§€ ì¤‘...\")\n",
    "    \n",
    "    import glob\n",
    "    search_patterns = [\n",
    "        'pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "        'runs/train/damage_detection_*/weights/best.pt',\n",
    "        '/content/pinetree_yolov11s/damage_detection_*/weights/best.pt',\n",
    "        '/content/drive/MyDrive/pinetree_scan/results/damage_detection_*/weights/best.pt',\n",
    "    ]\n",
    "    \n",
    "    found_models = []\n",
    "    for pattern in search_patterns:\n",
    "        matches = glob.glob(pattern)\n",
    "        found_models.extend(matches)\n",
    "    \n",
    "    if found_models:\n",
    "        # ê°€ì¥ ìµœì‹  ëª¨ë¸ ì„ íƒ\n",
    "        best_model_path = max(found_models, key=os.path.getctime)\n",
    "        print(f\"âœ… ê¸°ì¡´ ëª¨ë¸ ë°œê²¬: {best_model_path}\")\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        try:\n",
    "            model = YOLO(best_model_path)\n",
    "            training_completed = True\n",
    "            print(\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ! ê²€ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            training_completed = False\n",
    "    else:\n",
    "        print(\"âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ’¡ 2ë‹¨ê³„(ëª¨ë¸ í•™ìŠµ)ë¥¼ ë¨¼ì € ì™„ë£Œí•˜ì„¸ìš”.\")\n",
    "\n",
    "if training_completed:\n",
    "    try:\n",
    "        # T4 GPU ì•ˆì „ ëª¨ë¸ ë¡œë“œ (íƒ€ì„ì•„ì›ƒ ë°©ì§€)\n",
    "        print(\"ğŸ¤– T4 GPU ì•ˆì „ ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "        \n",
    "        # ëª¨ë¸ì´ ì „ì—­ë³€ìˆ˜ì— ì—†ìœ¼ë©´ ë¡œë“œ\n",
    "        if 'model' not in globals() or best_model_path:\n",
    "            if best_model_path and os.path.exists(best_model_path):\n",
    "                # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ëª¨ë¸ ë¡œë“œ\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                model = YOLO(best_model_path)\n",
    "                print(f\"âœ… ê²€ì¦ ëª¨ë¸ ë¡œë“œ: {best_model_path}\")\n",
    "            elif 'model' in globals():\n",
    "                print(f\"âœ… ê¸°ì¡´ ëª¨ë¸ ì¬ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)\")\n",
    "            else:\n",
    "                print(\"âŒ ì‚¬ìš©í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "                raise Exception(\"ëª¨ë¸ ì—†ìŒ\")\n",
    "        else:\n",
    "            print(f\"âœ… ê¸°ì¡´ ëª¨ë¸ ì¬ì‚¬ìš©\")\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸ ë° ì•ˆì „ ëª¨ë“œ\n",
    "        data_yaml_path = globals().get('data_yaml_path', '/content/training_data/data.yaml')\n",
    "        \n",
    "        # T4 GPU ì•ˆì „ ê²€ì¦ ëª¨ë“œ í™œì„±í™”\n",
    "        safe_validation = True\n",
    "        \n",
    "        if not os.path.exists(data_yaml_path):\n",
    "            print(f\"âš ï¸ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_yaml_path}\")\n",
    "            \n",
    "            # ëŒ€ì²´ ê²½ë¡œ ë¹ ë¥¸ íƒì§€ (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "            quick_paths = [\n",
    "                '/content/drive/MyDrive/pinetree_scan/training_data/data.yaml',\n",
    "                '/content/training_data/data.yaml'\n",
    "            ]\n",
    "            \n",
    "            found_data = False\n",
    "            for quick_path in quick_paths:\n",
    "                if os.path.exists(quick_path):\n",
    "                    data_yaml_path = quick_path\n",
    "                    found_data = True\n",
    "                    print(f\"âœ… ëŒ€ì²´ ê²½ë¡œ ë°œê²¬: {quick_path}\")\n",
    "                    break\n",
    "            \n",
    "            if not found_data:\n",
    "                print(\"ğŸ’¡ ê²€ì¦ ì—†ì´ ì§ì ‘ ì¶”ë¡  í…ŒìŠ¤íŠ¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "                safe_validation = False\n",
    "        \n",
    "        # ì•ˆì „ ê²€ì¦ ëª¨ë“œ ì‹¤í–‰\n",
    "        if safe_validation and os.path.exists(data_yaml_path):\n",
    "            print(f\"\\nğŸ“Š ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€ ì¤‘...\")\n",
    "            print(f\"  \udcc2 ë°ì´í„°ì…‹: {data_yaml_path}\")\n",
    "            \n",
    "            # T4 GPU ì•ˆì „ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.synchronize()\n",
    "                print(\"ğŸ§¹ ê²€ì¦ ì „ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "            \n",
    "            # T4 GPU ìµœì í™” ê²€ì¦ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì•ˆì „)\n",
    "            val_results = model.val(\n",
    "                data=data_yaml_path,\n",
    "                imgsz=640,\n",
    "                batch=2,                      # T4 ì•ˆì „ ë°°ì¹˜ í¬ê¸° (8â†’2)\n",
    "                conf=0.25,                    # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "                iou=0.6,                     # IoU ì„ê³„ê°’\n",
    "                device=globals().get('device', 'cpu'),\n",
    "                plots=False,                  # í”Œë¡¯ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "                save_json=False,             # JSON ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)\n",
    "                verbose=False,               # ë¡œê·¸ ìµœì†Œí™” (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "                workers=1,                   # ì›Œì»¤ ìµœì†Œí™”\n",
    "                rect=False,                  # ì§ì‚¬ê°í˜• ì¶”ë¡  ë¹„í™œì„±í™”\n",
    "                half=False                   # FP16 ë¹„í™œì„±í™” (ì•ˆì •ì„±)\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nğŸ‰ ê²€ì¦ ì™„ë£Œ! ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "            \n",
    "            # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥\n",
    "            if hasattr(val_results, 'box'):\n",
    "                map50 = val_results.box.map50\n",
    "                map50_95 = val_results.box.map\n",
    "                precision = val_results.box.mp\n",
    "                recall = val_results.box.mr\n",
    "                \n",
    "                print(f\"  ğŸ“ˆ mAP50: {map50:.4f} ({map50*100:.1f}%)\")\n",
    "                print(f\"  ğŸ“ˆ mAP50-95: {map50_95:.4f} ({map50_95*100:.1f}%)\")\n",
    "                print(f\"  ğŸ¯ Precision: {precision:.4f} ({precision*100:.1f}%)\")\n",
    "                print(f\"  \udd0d Recall: {recall:.4f} ({recall*100:.1f}%)\")\n",
    "                \n",
    "                # ì„±ëŠ¥ í‰ê°€\n",
    "                overall_score = (map50 + precision + recall) / 3\n",
    "                \n",
    "                if overall_score > 0.85:\n",
    "                    performance_grade = \"ğŸ† A+ (íƒì›”)\"\n",
    "                    performance_desc = \"ìƒìš© ìˆ˜ì¤€ì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥\"\n",
    "                elif overall_score > 0.75:\n",
    "                    performance_grade = \"ğŸŒŸ A (ìš°ìˆ˜)\"\n",
    "                    performance_desc = \"ì‹¤ìš©ì ì¸ ìˆ˜ì¤€ì˜ ì¢‹ì€ ì„±ëŠ¥\"\n",
    "                elif overall_score > 0.65:\n",
    "                    performance_grade = \"âœ… B (ì–‘í˜¸)\"\n",
    "                    performance_desc = \"ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥\"\n",
    "                elif overall_score > 0.5:\n",
    "                    performance_grade = \"âš ï¸ C (ë³´í†µ)\"\n",
    "                    performance_desc = \"ê°œì„ ì´ í•„ìš”í•œ ì„±ëŠ¥\"\n",
    "                else:\n",
    "                    performance_grade = \"âŒ D (ë¯¸í¡)\"\n",
    "                    performance_desc = \"ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ì„±ëŠ¥\"\n",
    "                \n",
    "                print(f\"\\nğŸ¯ ì¢…í•© ì„±ëŠ¥ í‰ê°€: {performance_grade}\")\n",
    "                print(f\"  ğŸ“ í‰ê°€: {performance_desc}\")\n",
    "                \n",
    "                # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (ìˆëŠ” ê²½ìš°)\n",
    "                if hasattr(val_results.box, 'ap_class_index') and len(val_results.box.ap_class_index) > 0:\n",
    "                    print(f\"\\n\udccb í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "                    for i, class_idx in enumerate(val_results.box.ap_class_index):\n",
    "                        if i < len(val_results.box.ap50):\n",
    "                            ap50_class = val_results.box.ap50[i]\n",
    "                            print(f\"  ğŸŒ² í”¼í•´ëª© (í´ë˜ìŠ¤ {class_idx}): mAP50 = {ap50_class:.4f}\")\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì•ˆë‚´\n",
    "                if 'run_name' in globals():\n",
    "                    results_dir = f\"pinetree_yolov11s/{run_name}\"\n",
    "                    print(f\"\\nğŸ“ ê²€ì¦ ê²°ê³¼ ì €ì¥:\")\n",
    "                    print(f\"  ğŸ“‚ ê²°ê³¼ í´ë”: {results_dir}\")\n",
    "                    print(f\"  ğŸ–¼ï¸ í˜¼ë™í–‰ë ¬: confusion_matrix.png\")\n",
    "                    print(f\"  ğŸ“ˆ ì„±ëŠ¥ê³¡ì„ : results.png\")\n",
    "                    print(f\"  ğŸ¯ ì˜ˆì¸¡ê²°ê³¼: val_batch*.jpg\")\n",
    "                \n",
    "                # ì „ì—­ ë³€ìˆ˜ì— ê²€ì¦ ê²°ê³¼ ì €ì¥\n",
    "                globals()['validation_results'] = val_results\n",
    "                globals()['validation_completed'] = True\n",
    "                globals()['model_performance'] = {\n",
    "                    'mAP50': float(map50),\n",
    "                    'mAP50_95': float(map50_95),\n",
    "                    'precision': float(precision),\n",
    "                    'recall': float(recall),\n",
    "                    'overall_score': float(overall_score),\n",
    "                    'grade': performance_grade\n",
    "                }\n",
    "                \n",
    "                validation_completed = True\n",
    "                \n",
    "            else:\n",
    "                print(\"âš ï¸ ê²€ì¦ ê²°ê³¼ì—ì„œ ì„±ëŠ¥ ì§€í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                validation_completed = False\n",
    "        \n",
    "        else:\n",
    "            print(\"âš ï¸ ì•ˆì „ ê²€ì¦ ëª¨ë“œ: ë°ì´í„° ë¬¸ì œë¡œ ê²€ì¦ ê±´ë„ˆëœ€\")\n",
    "            validation_completed = False\n",
    "        \n",
    "        # ê²€ì¦ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬ (ë¬´í•œë¡œë”© ë°©ì§€)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            print(\"ğŸ§¹ ê²€ì¦ í›„ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "        \n",
    "        if validation_completed:\n",
    "            print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 4ë‹¨ê³„(ì‹¤ì œ ì¶”ë¡ ) ì‹¤í–‰ ê°€ëŠ¥!\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ ê²€ì¦ì€ ê±´ë„ˆë›°ì—ˆì§€ë§Œ 4ë‹¨ê³„ ì¶”ë¡ ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"\\n\udd27 ë¬¸ì œ í•´ê²°:\")\n",
    "        print(f\"  1. ëª¨ë¸ íŒŒì¼ í™•ì¸\")\n",
    "        print(f\"  2. ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸\")\n",
    "        print(f\"  3. GPU ë©”ëª¨ë¦¬ í™•ì¸\")\n",
    "        print(f\"  4. ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "        \n",
    "        globals()['validation_completed'] = False\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c47000",
   "metadata": {},
   "source": [
    "## ğŸ” **4ë‹¨ê³„: ê°„ë‹¨ í…ŒìŠ¤íŠ¸ ë° Google Drive ë°±ì—…**\n",
    "\n",
    "> **í•™ìŠµëœ ëª¨ë¸ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  Google Driveì— ë°±ì—…í•©ë‹ˆë‹¤**  \n",
    "> ë¬´í•œë¡œë”© ì—†ëŠ” ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì™€ ì•ˆì „í•œ ë°±ì—… ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‰ 4ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” + ë°±ì—… (ë””ë²„ê¹… ê°•í™”)\n",
    "print(\"ğŸ‰ 4ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” + ë°±ì—…\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "import os, shutil, glob\n",
    "from datetime import datetime\n",
    "\n",
    "# ë”¥ëŸ¬ë‹ ê²°ê³¼ í´ë” ì°¾ê¸°\n",
    "run_name = globals().get('run_name', '')\n",
    "folder = None\n",
    "\n",
    "for pattern in [f\"pinetree_yolov11s/{run_name}\", \"pinetree_yolov11s/damage_detection_*\"]:\n",
    "    matches = glob.glob(pattern)\n",
    "    if matches:\n",
    "        folder = matches[0]\n",
    "        break\n",
    "\n",
    "if folder and os.path.exists(folder):\n",
    "    print(f\"âœ… ê²°ê³¼ í´ë”: {os.path.basename(folder)}\")\n",
    "    print(f\"ğŸ“‚ ì „ì²´ ê²½ë¡œ: {folder}\")\n",
    "    \n",
    "    # \udd0d í´ë” êµ¬ì¡° ìƒì„¸ í™•ì¸\n",
    "    print(f\"\\n\udd0d í´ë” êµ¬ì¡° ë¶„ì„:\")\n",
    "    \n",
    "    def analyze_folder(path, prefix=\"\"):\n",
    "        try:\n",
    "            items = os.listdir(path)\n",
    "            for item in sorted(items):\n",
    "                item_path = os.path.join(path, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    print(f\"{prefix}ğŸ“ {item}/\")\n",
    "                    if prefix == \"\":  # 1ë‹¨ê³„ ê¹Šì´ë§Œ\n",
    "                        analyze_folder(item_path, \"  \")\n",
    "                elif item.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    size = os.path.getsize(item_path) / 1024  # KB\n",
    "                    print(f\"{prefix}ğŸ–¼ï¸ {item} ({size:.1f}KB)\")\n",
    "                else:\n",
    "                    print(f\"{prefix}ğŸ“„ {item}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{prefix}âŒ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    analyze_folder(folder)\n",
    "    \n",
    "    # ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì§ì ‘ ê²€ìƒ‰\n",
    "    print(f\"\\nğŸ” ì´ë¯¸ì§€ íŒŒì¼ ì§ì ‘ ê²€ìƒ‰:\")\n",
    "    \n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.gif']\n",
    "    found_images = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, folder)\n",
    "                file_size = os.path.getsize(full_path) / 1024\n",
    "                found_images.append((file, rel_path, file_size))\n",
    "                print(f\"  ğŸ–¼ï¸ {rel_path} ({file_size:.1f}KB)\")\n",
    "    \n",
    "    if not found_images:\n",
    "        print(\"  âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        print(\"  \udca1 YOLO í›ˆë ¨ì´ ì™„ì „íˆ ëë‚˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    \n",
    "    # ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ ì‹œê°í™” ì‹œë„\n",
    "    if found_images:\n",
    "        print(f\"\\nğŸ“Š ì´ë¯¸ì§€ ì‹œê°í™” ì‹œë„:\")\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "        from IPython.display import Image, display\n",
    "        \n",
    "        displayed_count = 0\n",
    "        \n",
    "        for img_name, rel_path, size in found_images[:6]:  # ìµœëŒ€ 6ê°œ\n",
    "            img_path = os.path.join(folder, rel_path)\n",
    "            print(f\"\\nğŸ–¼ï¸ {img_name} í‘œì‹œ ì¤‘...\")\n",
    "            \n",
    "            try:\n",
    "                # ë°©ë²• 1: IPython.display.Image\n",
    "                display(Image(filename=img_path, width=500))\n",
    "                print(f\"  âœ… ì„±ê³µ (IPython)\")\n",
    "                displayed_count += 1\n",
    "            except Exception as e1:\n",
    "                try:\n",
    "                    # ë°©ë²• 2: matplotlib\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    img = mpimg.imread(img_path)\n",
    "                    ax.imshow(img)\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f\"{img_name} ({size:.1f}KB)\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    print(f\"  âœ… ì„±ê³µ (matplotlib)\")\n",
    "                    displayed_count += 1\n",
    "                except Exception as e2:\n",
    "                    print(f\"  âŒ ì‹¤íŒ¨: IPython({str(e1)[:20]}) / matplotlib({str(e2)[:20]})\")\n",
    "        \n",
    "        print(f\"\\nâœ… {displayed_count}/{len(found_images)} ì´ë¯¸ì§€ í‘œì‹œ ì™„ë£Œ!\")\n",
    "    \n",
    "    # ğŸ“ˆ ì„±ëŠ¥ ê²°ê³¼\n",
    "    results_file = os.path.join(folder, 'results.csv')\n",
    "    if os.path.exists(results_file):\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(results_file)\n",
    "            last = df.iloc[-1]\n",
    "            \n",
    "            print(f\"\\nğŸ† ìµœì¢… ì„±ëŠ¥:\")\n",
    "            if 'metrics/mAP50(B)' in df.columns:\n",
    "                print(f\"  ğŸ“ˆ mAP50: {last['metrics/mAP50(B)']:.3f}\")\n",
    "            if 'metrics/precision(B)' in df.columns:\n",
    "                print(f\"  ğŸ¯ ì •ë°€ë„: {last['metrics/precision(B)']:.3f}\")\n",
    "            if 'metrics/recall(B)' in df.columns:\n",
    "                print(f\"  ğŸ”„ ì¬í˜„ìœ¨: {last['metrics/recall(B)']:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ“Š ì„±ëŠ¥ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)[:30]}\")\n",
    "    \n",
    "    # ğŸ’¾ Google Drive ë°±ì—…\n",
    "    try:\n",
    "        import google.colab\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%m%d_%H%M')\n",
    "        backup_path = f'/content/drive/MyDrive/pinetree_scan/results/{os.path.basename(folder)}_{timestamp}'\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ Google Drive ë°±ì—… ì¤‘...\")\n",
    "        \n",
    "        # ë°±ì—… í´ë”ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì‚­ì œ\n",
    "        if os.path.exists(backup_path):\n",
    "            shutil.rmtree(backup_path)\n",
    "            \n",
    "        shutil.copytree(folder, backup_path)\n",
    "        \n",
    "        print(f\"âœ… ë°±ì—… ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“ ìœ„ì¹˜: MyDrive/pinetree_scan/results/{os.path.basename(folder)}_{timestamp}\")\n",
    "        \n",
    "        globals()['backup_completed'] = True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"âš ï¸ ë¡œì»¬ í™˜ê²½ - ë°±ì—… ê±´ë„ˆëœ€\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°±ì—… ì‹¤íŒ¨: {str(e)[:30]}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ê²°ê³¼ í´ë” ì—†ìŒ\")\n",
    "    print(\"ğŸ’¡ 2ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "\n",
    "print(\"=\" * 30)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
